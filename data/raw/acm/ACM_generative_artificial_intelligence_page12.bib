@inproceedings{10.1145/3613905.3650732,
author = {Yan, Lixiang and Echeverria, Vanessa and Fernandez-Nieto, Gloria Milena and Jin, Yueqiao and Swiecki, Zachari and Zhao, Linxuan and Ga\v{s}evi\'{c}, Dragan and Martinez-Maldonado, Roberto},
title = {Human-AI Collaboration in Thematic Analysis using ChatGPT: A User Study and Design Recommendations},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650732},
doi = {10.1145/3613905.3650732},
abstract = {Generative artificial intelligence (GenAI) offers promising potential for advancing human-AI collaboration in qualitative research. However, existing works focused on conventional machine-learning and pattern-based AI systems, and little is known about how researchers interact with GenAI in qualitative research. This work delves into researchers’ perceptions of their collaboration with GenAI, specifically ChatGPT. Through a user study involving ten qualitative researchers, we found ChatGPT to be a valuable collaborator for thematic analysis, enhancing coding efficiency, aiding initial data exploration, offering granular quantitative insights, and assisting comprehension for non-native speakers and non-experts. Yet, concerns about its trustworthiness and accuracy, reliability and consistency, limited contextual understanding, and broader acceptance within the research community persist. We contribute five actionable design recommendations to foster effective human-AI collaboration. These include incorporating transparent explanatory mechanisms, enhancing interface and integration capabilities, prioritising contextual understanding and customisation, embedding human-AI feedback loops and iterative functionality, and strengthening trust through validation mechanisms.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {191},
numpages = {7},
keywords = {ChatGPT, Generative Artificial Intelligence, Human-AI Collaboration, Qualitative Research, Thematic Analysis},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3726302.3731957,
author = {Shen, Lei and Zhao, Kang and Jin, Zhipeng and Tao, Wen and Yang, Yi and Han, Cong and Li, Shuanglong and Cai, Zhongmin and Liu, Lin},
title = {Retrieval-Augmented Image Captioning and Generation with Entity Concepts Enhancement for Baidu Multimodal Advertising},
year = {2025},
isbn = {9798400715921},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726302.3731957},
doi = {10.1145/3726302.3731957},
abstract = {Recent advancements in generative artificial intelligence are driving a significant transformation in information retrieval and content generation, creating substantial opportunities for online advertising. Text-to-image generation technology has become increasingly prevalent in advertising content production, demonstrating promising performance improvements in terms of semantic relevance and visual appeal. However, existing models often suffer from inadequate representation of entity concepts, such as prominent product brands and recognizable landmarks. This inherent limitation subsequently leads to notable deficiencies in brand tonality, industry-specific relevance, and market adaptability of the generated advertising content. To address this challenge, we propose a multimodal ad content generation framework specifically engineered for online advertising system, particularly focused on resolving the deficiency in entity concepts. Our framework is comprised of two phases: first, an image captioning module with entity-aware learning based on multimodal large language model, leveraging retrieval-augmented techniques to incorporate entity concepts into image descriptions; second, a text-to-image diffusion model refined on image-text pairs enriched with entity concepts to facilitate entity-grounded image generation. Extensive experiments validate the effectiveness of our framework, demonstrating superior performance in both image captioning and image generation compared to existing methods, particularly in the accuracy of depiction of relevant entities in advertising images. Moreover, the deployment of the framework in the system primary traffic of Baidu Search Ads, has brought significant enhancements to advertisement revenue for both advertisers and the platform.},
booktitle = {Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {4324–4328},
numpages = {5},
keywords = {image captioning, multimodal large language model, search advertising, text-to-image generation},
location = {Padua, Italy},
series = {SIGIR '25}
}

@inproceedings{10.1145/3674399.3674436,
author = {Ni, Wei and Zhang, Kaihang and Miao, Xiaoye and Zhao, Xiangyu and Wu, Yangyang and Yin, Jianwei},
title = {IterClean: An Iterative Data Cleaning Framework with Large Language Models},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674399.3674436},
doi = {10.1145/3674399.3674436},
abstract = {In the era of generative artificial intelligence, the accuracy of data is paramount. Erroneous data often leads to faulty outcomes and economic detriments. Previous cleaning methods employ a sequential detect-repair paradigm, leaving over half of the errors unsolved in real scenarios. We introduce IterClean, an iterative data cleaning framework leveraging large language models (LLMs). Utilizing an iterative mechanism, the framework employs a two-step process: data labeling and iterative data cleaning. With few labeled data, IterClean leverages an iterative cleaning process involving an error detector, an error verifier, and an error repairer to significantly enhance the cleaning performance. Extensive experiments across four datasets demonstrate that, IterClean achieves an F1 score that is up to three times higher than the best state-of-the-art approaches requiring only 5 labeled tuples.},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2024},
pages = {100–105},
numpages = {6},
keywords = {Data cleaning, error detection, error repair, large language models},
location = {Changsha, China},
series = {ACM-TURC '24}
}

@inproceedings{10.1145/3686424.3686477,
author = {Liang, Jian and Li, XiaoJie},
title = {Construction of Emergency Rescue Virtual Exercise Platform Based on AIGC Perspective},
year = {2024},
isbn = {9798400710360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686424.3686477},
doi = {10.1145/3686424.3686477},
abstract = {In order to address the suddenness of emergency events and the phenomenon that the rescue process contains too many behavioural uncertainties, an emergency rescue virtual exercise platform framework has been designed from the perspective of generative artificial intelligence (AIGC). This framework analyses human behaviour during the simulated emergency rescue process and collects relevant data. The module function is determined by the parallel emergency management method. The system comprises three data processing modules: the behavioural input module, the emergency event feedback module, and the data classification and processing module. The logic of AI data processing is employed to establish a data cycle evolution system, which assists rescue personnel in enhancing their professional abilities, increasing the success rate of rescue operations, and optimising the role of AI technology and computer simulation methodology in the design of the practice.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Education Digitalization and Computer Science},
pages = {312–316},
numpages = {5},
location = {Shenzhen, China},
series = {EDCS '24}
}

@article{10.1145/3734189,
author = {Oppenlaender, Jonas and Johnston, Hannah and Silvennoinen, Johanna Maria and Barranha, Helena},
title = {Artworks Reimagined: Exploring Human-AI Co-Creation through Body Prompting},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {4},
url = {https://doi.org/10.1145/3734189},
doi = {10.1145/3734189},
abstract = {Image generation using generative artificial intelligence has become a popular activity. However, text-to-image generation—where images are produced from typed prompts—can be less engaging in public settings since the act of typing tends to limit interactive audience participation, thereby reducing its suitability for designing dynamic public installations. In this article, we explore body prompting as input modality for image generation in the context of public event settings. Body prompting extends interaction with generative AI beyond textual inputs to reconnect the creative act of image generation with the physical act of creating artworks. We implement this concept in an interactive art installation, Artworks Reimagined, designed to transform existing artworks via body prompting. We deployed the installation at an event with hundreds of visitors in a public and private setting. Our semi-structured interviews with a sample of visitors (N = 79) show that body prompting was well-received and provides an engaging and fun experience. We present insights into participants’ experience of body prompting and AI co-creation and identify three distinct strategies of embodied interaction focused on re-creating, reimagining, or casual interaction. We provide valuable recommendations for practitioners seeking to design interactive generative AI experiences in museums, galleries, and public event spaces.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {EICS012},
numpages = {34},
keywords = {generative AI, human-AI interaction, embodied interaction, image generation, co-creation, public displays, art installation}
}

@inproceedings{10.14236/ewic/BCSHCI2023.13,
author = {Widjaya, Michael A. and Berm\'{u}dez, Juan P. and Moradbakhti, Laura and Calvo, Rafael A.},
title = {Drivers of Trust in Generative AI-powered Voice Assistants: The Role of References},
year = {2024},
isbn = {1234567891011},
publisher = {BCS Learning \&amp; Development Ltd},
address = {Swindon, GBR},
url = {https://doi.org/10.14236/ewic/BCSHCI2023.13},
doi = {10.14236/ewic/BCSHCI2023.13},
abstract = {The boom in generative artificial intelligence (AI) and continuing growth of Voice Assistants (VAs) suggests their trajectories will converge. This conjecture aligns with the development of AI-driven conversational agents, aiming to utilise advance natural language processing (NLP) methods to enhance the capabilities of voice assistants. However, design guidelines for VAs prioritise maximum efficiency by advocating for the use of concise answers. This poses a conflict with the challenges around generative AI, such as inaccuracies and misinterpretation, as shorter responses may not adequately provide users with meaningful information. AI-VA systems can adapt drivers of trust formation, such as references and authorship, to improve credibility. A better understanding of user behaviour when using the system is needed to develop revised design recommendations for AI-powered VA systems. This paper reports an online survey of 256 participants residing in the U.K. and nine follow-up interviews, where user behaviour is investigated to identify drivers of trust in the context of obtaining digital information from a generative AI-based VA system. Adding references is promising as a tool for increasing trust in systems producing text, yet we found no evidence that the inclusion of references in a VA response contributed towards the perceived reliability or trust towards the system. We examine further variables driving user trust in AI-powered VA systems.},
booktitle = {Proceedings of the 36th International BCS Human-Computer Interaction Conference},
pages = {110–119},
numpages = {10},
keywords = {Generative AI, Voice Assistants, Trust Drivers, Large language models (LLMs)},
location = {University of York, UK},
series = {BCS HCI '23}
}

@inproceedings{10.1145/3544549.3573794,
author = {Muller, Michael and Chilton, Lydia B and Kantosalo, Anna and Liao, Q. Vera and Maher, Mary Lou and Martin, Charles Patrick and Walsh, Greg},
title = {GenAICHI 2023: Generative AI and HCI at CHI 2023},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3573794},
doi = {10.1145/3544549.3573794},
abstract = {This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together. Following a successful workshop in 2022, we convene the interdisciplinary research domain of generative AI and HCI. Participation in this invitational workshop is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {350},
numpages = {7},
keywords = {Bias, Design, Generative AI, Uncertainty.},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@inbook{10.1145/3745238.3745494,
author = {Wang, Shihao and Huang, Jiasheng and Wang, Shichang},
title = {Research on Clustering Analysis of Generative AI Tool Usage Behaviors Among College Students},
year = {2025},
isbn = {9798400712791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3745238.3745494},
abstract = {This study investigates how university students use generative AI tools by applying the K-means clustering algorithm to analyse their usage frequency, scenarios and purposes. Based on virtual questionnaire data, students were effectively grouped into different behavioural categories. The results show clear differences between high and low frequency users in terms of time spent, motivations and learning outcomes - differences that are largely influenced by students' learning goals and the specific tools they use. A key innovation of this research is the use of clustering analysis to map the diversity of AI tool usage behaviours, providing valuable insights for personalised educational strategies. The findings also provide a solid data base for universities to refine the use of AI tools in learning, with the ultimate goal of improving student performance and guiding the future integration of AI in educational contexts.},
booktitle = {Proceedings of the 2nd Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {1629–1633},
numpages = {5}
}

@inbook{10.1109/ICSE55347.2025.00206,
author = {Baresi, Luciano and Hu, Davide Yi Xian and Stocco, Andrea and Tonella, Paolo},
title = {Efficient Domain Augmentation for Autonomous Driving Testing Using Diffusion Models},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00206},
abstract = {Simulation-based testing is widely used to assess the reliability of Autonomous Driving Systems (ADS), but its effectiveness is limited by the operational design domain (ODD) conditions available in such simulators. To address this limitation, in this work, we explore the integration of generative artificial intelligence techniques with physics-based simulators to enhance ADS system-level testing. Our study evaluates the effectiveness and computational overhead of three generative strategies based on diffusion models, namely instruction-editing, inpainting, and inpainting with refinement. Specifically, we assess these techniques' capabilities to produce augmented simulator-generated images of driving scenarios representing new ODDs. We employ a novel automated detector for invalid inputs based on semantic segmentation to ensure semantic preservation and realism of the neural generated images. We then performed system-level testing to evaluate the ability of the ADS to generalize to newly synthesized ODDs. Our findings show that diffusion models help to increase the coverage of ODD for system-level ADS testing. Our automated semantic validator achieved a percentage of false positives as low as 3\%, retaining the correctness and quality of the images generated for testing. Our approach successfully identified new ADS system failures before real-world testing.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {398–410},
numpages = {13}
}

@inproceedings{10.1145/3613905.3650750,
author = {El Ali, Abdallah and Venkatraj, Karthikeya Puttur and Morosoli, Sophie and Naudts, Laurens and Helberger, Natali and Cesar, Pablo},
title = {Transparent AI Disclosure Obligations: Who, What, When, Where, Why, How},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650750},
doi = {10.1145/3613905.3650750},
abstract = {Advances in Generative Artificial Intelligence (AI) are resulting in AI-generated media output that is (nearly) indistinguishable from human-created content. This can drastically impact users and the media sector, especially given global risks of misinformation. While the currently discussed European AI Act aims at addressing these risks through Article 52’s AI transparency obligations, its interpretation and implications remain unclear. In this early work, we adopt a participatory AI approach to derive key questions based on Article 52’s disclosure obligations. We ran two workshops with researchers, designers, and engineers across disciplines (N=16), where participants deconstructed Article 52’s relevant clauses using the 5W1H framework. We contribute a set of 149 questions clustered into five themes and 18 sub-themes. We believe these can not only help inform future legal developments and interpretations of Article 52, but also provide a starting point for Human-Computer Interaction research to (re-)examine disclosure transparency from a human-centered AI lens.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {342},
numpages = {11},
keywords = {Article 52, EU AI Act, disclosures, generative artificial intelligence, law, obligations, research questions, transparency},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3699538.3699546,
author = {Keuning, Hieke and Alpizar-Chacon, Isaac and Lykourentzou, Ioanna and Beehler, Lauren and K\"{o}ppe, Christian and de Jong, Imke and Sosnovsky, Sergey},
title = {Students' Perceptions and Use of Generative AI Tools for Programming Across Different Computing Courses},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699546},
doi = {10.1145/3699538.3699546},
abstract = {Investigation of students’ perceptions and opinions on the use of generative artificial intelligence (GenAI) in education is a topic gaining much interest. Studies addressing this are typically conducted with large heterogeneous groups, at one moment in time. However, how students perceive and use GenAI tools can potentially depend on many factors, including their background knowledge, familiarity with the tools, and the learning goals and policies of the courses they are taking. In this study we explore how students following computing courses use GenAI for programming-related tasks across different programs and courses: Bachelor and Master, in courses in which learning programming is the learning goal, courses that require programming as a means to achieve another goal, and in courses in which programming is optional, but can be useful. We are also interested in changes over time, since GenAI capabilities are changing at a fast pace, and users are adopting GenAI increasingly. We conducted three consecutive surveys (fall ‘23, winter ‘23, and spring ‘24) among students of all computing programs of a large European research university. We asked questions on the use in education, ethics, and job prospects, and we included specific questions on the (dis)allowed use of GenAI tools in the courses they were taking at the time. We received 264 responses, which we quantitatively and qualitatively analyzed, to find out how students have employed GenAI tools across 59 different computing courses, and whether the opinion of an average student about these tools evolves over time. Our study contributes to the emerging discussion of how to differentiate GenAI use across different courses, and how to align its use with the learning goals of a computing course.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {14},
numpages = {12},
keywords = {Generative AI, Large Language Models, Computing Education, Programming Courses},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3643834.3661624,
author = {Uusitalo, Severi and Salovaara, Antti and Jokela, Tero and Salmimaa, Marja},
title = {”Clay to Play With”: Generative AI Tools in UX and Industrial Design Practice},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661624},
doi = {10.1145/3643834.3661624},
abstract = {Generative artificial intelligence (GAI) is transforming numerous professions, not least various fields intimately relying on creativity, such as design. To explore GAI’s adoption and appropriation in design, an interview-based study probed 10 specialists in user experience and industrial design, with varying tenure and GAI experience, for their adoption/application of GAI tools, reasons for not using them, problems with ownership and agency, speculations about the future of creative work, and GAI tools’ roles in design sensemaking. Insight from reflexive thematic analysis revealed wide variation in attitudes toward GAI tools – from threat-oriented negative appraisals to identification of empowerment opportunities – which depended on the sense of agency and perceived control. The paper examines this finding in light of the Coping Model of User Adaptation and discusses designers’ metacognitive skills as possible underpinnings for their attitudes. Avenues for further research are identified accordingly.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {1566–1578},
numpages = {13},
keywords = {UX design, coping model of user adaptation, design, generative AI, industrial design, metacognition},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3625007.3627484,
author = {Duncan, Clay and Mcculloh, Ian},
title = {Unmasking Bias in Chat GPT Responses},
year = {2024},
isbn = {9798400704093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625007.3627484},
doi = {10.1145/3625007.3627484},
abstract = {Generative artificial intelligence (AI) has gained a great deal of recent attention with the release of Chat GPT 4. It has been praised for its ability to generate human-like responses but has perhaps faced even more criticism over potential concerns for biased responses, misinformation, and generation of harmful or inappropriate content. Chat GPT utilizes large sources of data to curate responses to all kinds of questions. The generative AI models are designed to be objective and avoid any sort of bias in their output. However, in the age of misinformation, social media, user-generated content and the 24-hour news cycle, biased information has never been more plentiful. This paper investigates the possibility of biased responses produced by Chat GPT 4 utilizing public data from biased media sources through Support Vector Machines. We find Chat GPT tends to have bias in its responses.},
booktitle = {Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {687–691},
numpages = {5},
keywords = {chat GPT, bias, artificial intelligence, generative AI, AI ethics},
location = {Kusadasi, Turkiye},
series = {ASONAM '23}
}

@inproceedings{10.1145/3648188.3676183,
author = {Pigulak, Joanna and Kidziak, Kacper Kajetan and Szymczak, Zuzanna and Walega, Joachim Kaj and Jastrzebska, Klara},
title = {Creative Everyday Life: Various Dimensions of Human-Technological Daily Life},
year = {2024},
isbn = {9798400705953},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3648188.3676183},
doi = {10.1145/3648188.3676183},
abstract = {The exhibition shows the coexistence of humans and technology in everyday life, exploring the topic from various perspectives. It consists of four sections through which participants will navigate using an application that reads QR codes. The application will guide participants to subsequent parts of the exhibition and provide basic information about the thematic context of each section, as well as suggest interpretative clues and insights. Each section presents different aspects of everyday life dominated by technology, bringing out the artistic potential of everyday human activity. The key focus will be the interaction between humans and digital technology, especially generative artificial intelligence, as the basis for considering creative cooperation. The individual sections of the exhibition are titled as follows: [1.1] The Boundaries of Creativity: Dimensions of Human and Non-Human Creativity, [1.2] Humans as Objects of Technological Experiences, [1.3] Technology as a Capsule of Memories, and [1.4] Technology as a Safety Valve.},
booktitle = {Proceedings of the 35th ACM Conference on Hypertext and Social Media},
pages = {285–286},
numpages = {2},
location = {Poznan, Poland},
series = {HT '24}
}

@inproceedings{10.1145/3702653.3744298,
author = {Pang, Ashley and Salloum, Mariam and Knight, Allan},
title = {Encouraging Student Success Through Engagement and Efficient Use of AI},
year = {2025},
isbn = {9798400713415},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702653.3744298},
doi = {10.1145/3702653.3744298},
abstract = {With the rise of Generative Artificial Intelligence (Gen AI) and the increasing availability of online resources, concerns about academic integrity and students’ comprehension have grown. Ensuring student success in computer science is critical for the future of our next generation of computing professionals. In recent years, Pang has worked in developing and conducting research in the field of Computer Science Education to develop and evaluate pedagogical strategies that foster student success. This research description examines the motivation behind Pang’s currently published papers and future ideas and their impact on the CS education community [4, 6, 7, 12, 13, 14, 15, 16, 17, 18, 19].},
booktitle = {Proceedings of the 2025 ACM Conference on International Computing Education Research V.2},
pages = {44–45},
numpages = {2},
keywords = {Computer Science Education, Artificial Intelligence, Engagement, Cheating, Plagiarism, Industry Preparation, CS1},
location = {
},
series = {ICER '25}
}

@inproceedings{10.1145/3704637.3734741,
author = {Sakowicz, Marie},
title = {Exploring AI's Role in Special Education},
year = {2025},
isbn = {9798400706264},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704637.3734741},
doi = {10.1145/3704637.3734741},
abstract = {I am currently pursuing a Ph.D. in Human-Centered Computing at the University of Maryland, Baltimore County, under the advisement of Dr. Foad Hamidi. My research is focused on the use of generative Artificial Intelligence (AI) in Special Education to help create more equitable learning environments for learners with disabilities. I hope to propose my dissertation studies plan by the end of August 2025. I will continue my research and plan to defend my dissertation in 2026. After I defend my dissertation, I would like to transition to a career in academia or work in a research lab. My dissertation is at the intersection of AI, Human-Computer Interaction, and inclusive education through the lens of Universal Design for Learning (UDL) [1]. Specifically, I am investigating how generative AI tools [2], such as large language models, can support special educators in designing accessible and personalized learning experiences for students with disabilities [4]. Previously, I contributed to research on DIY assistive technologies [3]. The first phase of my research included a qualitative interview study examining how K-12 special educators use and perceive AI. Findings highlighted opportunities and challenges of the use of AI. Concerns included lack of professional development, bias in AI, accessibility, and privacy issues. In the second phase, I conducted a focus group with special educators to understand how they have been using generative AI. I also conducted a participatory design session with one participant to discuss the design of an AI-enhanced tool they would like. These sessions provided an understanding of special educator experiences using AI to support neurodiverse learners. In the next phase of my research, I plan to conduct a qualitative study to understand how generative AI can assist parents and students in developing self-advocacy skills and in the creation of goals for their Individualized Education Plan (IEP) [5]. The study aims to understand experiences, perceptions, and needs of parents and students when using generative AI tools for self-advocacy.},
booktitle = {Proceedings of the 2025 Conference on Research on Equitable and Sustained Participation in Engineering, Computing, and Technology},
pages = {372–373},
numpages = {2},
keywords = {accessibility, artificial intelligence, learning, special education},
location = {Newark, NJ, USA},
series = {RESPECT 2025}
}

@inproceedings{10.1145/3712716.3712724,
author = {Thomson, Matthew and McKeown, Sean and Macfarlane, Richard and Leimich, Petra},
title = {Exploring Dataset Diversity for GenAI Image Inpainting Localisation in Digital Forensics},
year = {2025},
isbn = {9798400710766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712716.3712724},
doi = {10.1145/3712716.3712724},
abstract = {Generative Artificial Intelligence (GenAI) has significantly increased the sophistication and ease of image tampering techniques, posing challenges for digital forensics in identifying manipulated images. A lack of dataset standardisation hinders the ability to effectively benchmark and compare GenAI inpainting localisation techniques, reducing their reliability in digital forensic applications. This paper aims to address this gap by exploring the need for standardised criteria for datasets in digital forensics for benchmarking detection techniques through preliminary experiments.To address the limited diversity in existing datasets, a small-scale dataset was developed, consisting of 240 tampered images, 20 masks and 20 authentic images. This dataset includes four subject image classes (animals, objects, persons, scenery) and three inpainting tools (GLIDE, GalaxyAI, Photoshop). The dataset was evaluated against 13 localisation algorithms from the Image Forensics MATLAB Toolbox to determine key components that should be considered in the standardisation of testing environments.The results show that the images in the animals and persons categories achieved the highest F1-Scores and accuracy over the other classes. Among tools, GLIDE inpainted images were consistently shown to be the most challenging to detect, underscoring the importance of further investigating these images. These findings provide foundational insights for identifying a set of criteria to establish robust testing environments, enabling the development of reliable and accurate GenAI inpainting localisation techniques.},
booktitle = {Proceedings of the Digital Forensics Doctoral Symposium},
articleno = {7},
numpages = {7},
keywords = {Digital Forensics, Artificial Intelligence (AI), Generative AI (GenAI), AI Manipulation, Inpainting, Image Forgery Localisation},
location = {
},
series = {DFDS '25}
}

@article{10.1145/3676281,
author = {Wang, Jieshu and Kiran, Elif and Aurora, S.R. and Simeone, Michael and Lobo, Jos\'{e}},
title = {ChatGPT on ChatGPT: An Exploratory Analysis of its Performance in the Public Sector Workplace},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
url = {https://doi.org/10.1145/3676281},
doi = {10.1145/3676281},
abstract = {This study explores the impact of Generative Artificial Intelligence (GenAI), in particular, ChatGPT, on the public sector workforce in the United States, focusing on task replacement, assistance potential, and the evolving landscape of skills. Utilizing GPT-4 to evaluate 1,022 core tasks across 51 public sector occupations, we provide an exploratory analysis of the roles susceptible to ChatGPT automation and those in which ChatGPT can augment human efforts. Our findings reveal that while 63\% of tasks are resistant to ChatGPT replacement, primarily due to their requirement for physical presence, emotional intelligence, and complex decision-making, tasks that are routine, rule-based, and involving basic content generation show a high potential for automation. The study also identifies key skills that will remain vital, those likely to become obsolete, and new skills that will emerge as essential, highlighting the need for a strategic approach to workforce development in the face of AI advancements. In particular, our findings underscore the growing importance of skills in applying AI technologies and the ability to validate and interpret AI-generated content for humans to remain competitive. We offer insights into public-sector-specific impacts and propose a methodological framework for future research, emphasizing the importance of adapting educational curricula and policies to prepare for an AI-integrated future.},
journal = {Digit. Gov.: Res. Pract.},
month = jun,
articleno = {29},
numpages = {28},
keywords = {Public sector, workforce, artificial intelligence, large language models, ChatGPT, future of work}
}

@inproceedings{10.1145/3664646.3664767,
author = {Eskandani, Nafise and Salvaneschi, Guido},
title = {Towards AI for Software Systems},
year = {2024},
isbn = {9798400706851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664646.3664767},
doi = {10.1145/3664646.3664767},
abstract = {Generative Artificial Intelligence (GenAI) is being adopted for a number of Software Engineering activities, mostly centering around coding, such as code generation, code comprehension, code reviews, test generation, and bug fixing. Other phases in the Software Engineering process have been less explored. In this paper, we argue that more investigation is needed on the support that GenAI can provide to the design, and operation of software systems, i.e., a number of crucial activities, beyond coding, that are necessary to successfully deliver and maintain software services. These include reasoning about architectural choices and dealing with third-party platforms.        We discuss crucial aspects of AI for software systems. taking as a use case Function as a Service (FaaS).We present several challenges, including cold start delays, stateless functions, debugging complexities, and vendor lock-in and explore the potential of GenAI tools to mitigate FaaS challenges. Finally, we outline future research into the application of GenAI tools for the development and deployment of software systems.},
booktitle = {Proceedings of the 1st ACM International Conference on AI-Powered Software},
pages = {79–84},
numpages = {6},
keywords = {FaaS, Generative AI, Serverless Computing},
location = {Porto de Galinhas, Brazil},
series = {AIware 2024}
}

@inproceedings{10.1145/3736539.3744927,
author = {Dao, Loc},
title = {Signaling Human Technology interaction in XR and AI},
year = {2025},
isbn = {9798400719462},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3736539.3744927},
doi = {10.1145/3736539.3744927},
abstract = {We're in an era where documenting and reflecting human identity and lived experience is being reframed through the lens of extended reality (XR) and artificial intelligence (AI) that when combined will challenge many assumptions we hold. To get a glimpse into this future, we draw from the curation of interactive and immersive projects featured at Signals Creative Tech Expo and XR Lab from 2022 - 2025, we can learn from how creative technologists utilize immersive and generative artificial intelligence technologies to interrogate our senses, emotions, memories, identity, agency, surveillance, and interconnectedness across physical and virtual domains.},
booktitle = {Proceedings of the Special Interest Group on Computer Graphics and Interactive Techniques Conference Frontiers},
articleno = {10},
numpages = {2},
location = {
},
series = {SIGGRAPH Frontiers '25}
}

@inproceedings{10.1145/3632634.3655849,
author = {Combs, Kara and Bihl, Trevor J and Gadre, Arya and Christopherson, Isaiah},
title = {A Human-factors Approach for Evaluating AI-generated Images},
year = {2024},
isbn = {9798400704772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632634.3655849},
doi = {10.1145/3632634.3655849},
abstract = {As generative artificial intelligence (AI) becomes more common in day-to-day life, AI-generated content (AIGC) needs to be accurate, relevant, and comprehensive. These characteristics typically are determined by subjective, human-based image quality assessment; however, there is limited research on the qualification of AI-generated image quality. Over 9,800 images were generated using Craiyon and OpenAI's DALL-E 2 text-to-image models and evaluated on the three criteria proposed for determining the quality of visual AIGC: (1) the number of objects, (2), resolution (strictly image quality; label/prompt exclusive), and (3) representativeness (consideration for how well the image matches the label/prompt). We observe that the paid, DALL-E 2 model, produced a dataset with fewer objects per image, higher resolution, and higher representativeness compared to Craiyon (free). There is an inverse relationship between the number of objects/images and its resolution and representativeness. This study establishes three subjective metrics for the evaluation of synthetic images to support the creation of more inclusive AIGC.},
booktitle = {Proceedings of the 2024 Computers and People Research Conference},
articleno = {7},
numpages = {9},
keywords = {Analogical reasoning, Computer vision, Generative AI, Human factors},
location = {Murfreesboro, TN, USA},
series = {SIGMIS-CPR '24}
}

@inproceedings{10.1145/3641234.3671061,
author = {Zhou, Aven-Le and Wang, Yu-Ao and Wu, Wei and Zhang, Kang},
title = {Kandinsky As You Preferred},
year = {2024},
isbn = {9798400705168},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641234.3671061},
doi = {10.1145/3641234.3671061},
abstract = {Due to the significant generative capabilities of GenAI (generative artificial intelligence), the art community has actively embraced it to create painterly content. Large text-to-image models can quickly generate aesthetically pleasing outcomes. However, the process can be non-deterministic and often involves tedious trial-and-error as users struggle to formulate effective prompts to achieve their desired results. This paper describes a generative approach that empowers users to easily work with a large text-to-image (TTI) model to create their preferred painterly content. The authors propose a large model personalization method, namely Semantic Injection, to personalize a large TTI model in a given specific artistic style, i.e., Kandinsky’s paintings in Bauhaus era, as the Artist Model. Through working with a Kandinsky expert, the authors first establish a semantic descriptive guideline and a TTI dataset of Kandinsky style and then apply the Semantic Injection method to obtain an Artist Model of Kandinsky, empowering users to create preferred Kandinsky content in a deterministically controllable manner.},
booktitle = {ACM SIGGRAPH 2024 Posters},
articleno = {15},
numpages = {2},
keywords = {GenAI, Large Model Personalization, Semantic Injection},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{10.1145/3639856.3639892,
author = {Soman, Sumit and H. G., Ranjani},
title = {Observations on LLMs for Telecom Domain: Capabilities and Limitations},
year = {2024},
isbn = {9798400716492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639856.3639892},
doi = {10.1145/3639856.3639892},
abstract = {The landscape for building conversational interfaces (chatbots) has witnessed a paradigm shift with recent developments in generative Artificial Intelligence (AI) based Large Language Models (LLMs), such as ChatGPT by OpenAI (GPT3.5 and GPT4), Google’s Bard, Large Language Model Meta AI (LLaMA), among others. In this paper, we analyze capabilities and limitations of incorporating such models in conversational interfaces for the telecommunication domain, specifically for enterprise wireless products and services. Using Cradlepoint’s publicly available data for our experiments, we present a comparative analysis of the responses from such models for multiple use-cases including domain adaptation for terminology and product taxonomy, context continuity, robustness to input perturbations and errors. We believe this evaluation would provide useful insights to data scientists engaged in building customized conversational interfaces for domain-specific requirements.},
booktitle = {Proceedings of the Third International Conference on AI-ML Systems},
articleno = {36},
numpages = {5},
keywords = {Bard, ChatGPT, Chatbot, Enterprise Wireless., GPT3.5, GPT4, Generative AI, LLaMA, Large Language Models, Telecom},
location = {Bangalore, India},
series = {AIMLSystems '23}
}

@inproceedings{10.1145/3699538.3699567,
author = {Amoozadeh, Matin and Nam, Daye and Prol, Daniel and Alfageeh, Ali and Prather, James and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Amin},
title = {Student-AI Interaction: A Case Study of CS1 students},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699567},
doi = {10.1145/3699538.3699567},
abstract = {Generative artificial intelligence tools (Generative AI), such as ChatGPT, allow users to interact with them in intuitive ways (e.g., conversational) and receive (mostly) good-quality answers. In education, such systems can support students’ learning objectives by providing accessible explanations and examples even when students pose vague queries. But, they also encourage undesired help-seeking behaviors, such as by providing solutions to the students’ homework. Therefore, it is important to better understand how students approach such tools and the potential issues such approaches might present for the learners.In this paper, we present a case study for understanding student-AI collaboration to solve programming tasks in the CS1 introductory programming course. To this end, we recruited a gender-balanced majority non-white set of 15 CS1 students at the University of Houston, a large public university in the US. We observed them solving programming tasks. We used a mixed-method approach to study their interactions as they tackled Python programming tasks, focusing on when and why they used ChatGPT for problem-solving. We analyze and classify the questions submitted by the 15 participants to ChatGPT. Additionally, we analyzed user interaction patterns, their reactions to ChatGPT’s responses, and the potential impacts of Generative AI on their perception of self-efficacy.Our results suggest that, in about a third of the cases, the student attempted to complete the task by submitting the full description of the tasks to ChatGPT without making any effort on their own. We also observed that few students verified their solutions. We discuss the potential implications of these results.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {13},
numpages = {13},
keywords = {Generative Artificial Intelligence, Human-AI Interaction, Self-regulation, CS1, User study, Novice programmers},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3637528.3671485,
author = {Yan, Da and Hamed, Ahmed Abdeen and Chen, Jake Y. and Zaki, Mohammed J.},
title = {23rd International Workshop on Data Mining in Bioinformatics (BIOKDD 2024)},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671485},
doi = {10.1145/3637528.3671485},
abstract = {The goal of the 22nd International Workshop on Data Mining in Bioinformatics (BIOKDD 2023) is to encourage KDD researchers to solve the numerous problems and challenges in Bioinformatics using Data Mining technologies. Based on the organizers' expertise and communities, BIOKDD 2023 features the theme "Large-Scale Data-Driven Methods for Bioinformatics". This theme encourages the use of high-performance computing (HPC) to support the training of large machine learning models for problems in Bioinformatics and Computational Biology. The key goal is to accelerate the convergence between Data Mining and Bioinformatics communities to expedite discoveries in basic biology, medicine and healthcare.The goal of the 23rd International Workshop on Data Mining in Bioinformatics (BIOKDD 2024) is to encourage KDD researchers to solve the numerous problems and challenges in Bioinformatics using Data Mining technologies. Based on the organizers' expertise and communities, BIOKDD 2024 features the theme "Advancing Bioinformatics with LLMs and GenAI". This theme encourages the use of large language models and generative artificial intelligence to solve problems in Bioinformatics and Computational Biology. The key goal is to accelerate the convergence between Data Mining and Bioinformatics communities to expedite discoveries in basic biology, medicine and healthcare.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6747–6748},
numpages = {2},
keywords = {AI, bioinformatics, health informatics},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inbook{10.5555/3716662.3716743,
author = {Luna, Jose and Tan, Ivan and Xie, Xiaofei and Jiang, Lingxiao},
title = {Navigating Governance Paradigms: A Cross-Regional Comparative Study of Generative AI Governance Processes \&amp; Principles},
year = {2025},
publisher = {AAAI Press},
abstract = {As Generative Artificial Intelligence (GenAI) technologies evolve at an unprecedented rate, global governance approaches struggle to keep pace with the technology, highlighting a critical issue in the governance adaptation of significant challenges. Depicting the nuances of nascent and diverse governance approaches based on risks, rules, outcomes, principles, or a mix, across different regions around the globe, is fundamental to discern discrepancies and convergences, and to shed light on specific limitations that need to be addressed, thereby facilitating the safe and trustworthy adoption of GenAI. In response to the need and the evolving nature of GenAI, this paper seeks to provide a collective view of different governance approaches around the world. Our research introduces a Harmonized GenAI Framework, "H-GenAIGF", based on the current governance approaches of six regions: (European Union (EU), United States (US), China (CN), Canada (CA), United Kingdom (UK), and Singapore (SG)). We have identified four constituents, fifteen processes, twenty-five sub-processes, and nine principles that aid the governance of GenAI, thus providing a comprehensive perspective on the current state of GenAI governance. In addition, we present a comparative analysis to facilitate identification of common ground and distinctions based on coverage of the processes by each region. The results show that risk-based approaches allow for better coverage of the processes, followed by mixed approaches. Other approaches lag behind, covering less than 50\% of the processes. Most prominently, the analysis demonstrates that amongst the regions, only one process aligns across all approaches, highlighting the lack of consistent and executable provisions. Moreover, our case study on ChatGPT reveals process coverage deficiency, showing that harmonization of approaches is necessary to find alignment for GenAI governance.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {917–931},
numpages = {15}
}

@inproceedings{10.1145/3712255.3726588,
author = {Huang, Yi-Chao and Xu, Xin-Xin and Li, Jian-Yu and Kwong, Sam and Zhan, Zhi-Hui and Zhang, Jun},
title = {Generative Evolutionary Computation: An Automatic Gene Targeting Differential Evolution Via Genetic Programming},
year = {2025},
isbn = {9798400714641},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712255.3726588},
doi = {10.1145/3712255.3726588},
abstract = {Evolutionary computation (EC) is a kind of artificial intelligence (AI) for optimization. However, traditional EC algorithms require the careful design of parameters and/or operators from experts. Designing an operator with generalization ability is a tough task, and the manually design process is often limited by the structures of existing operators, which lacks diversity. In order to explore operators with diverse structures and good generalization ability so as to provide inspiration for the manually design of operators, this paper proposes a generative EC approach for the automatic design of operators by using genetic programming (GP). We apply the generative approach to a typical EC variant named gene targeting differential evolution (GTDE), so as to propose a new automatic GTDE (AGTDE) algorithm. The AGTDE utilizes the advantage of GP in optimizing structural features to automatically generate and refine the targeting vector generation operator within GTDE. This way, the operator of AGTDE is generated automatically rather than manually designed, which is more robust and optimal. The experimental results demonstrate that AGTDE is capable of identifying appropriate and even better operator for solving optimization problems, when compared with GTDE with manually design operator. Moreover, the results show that the operator obtained for one problem can be applied to other problems and obtain promising results, which reflect the robustness and generalization ability of the operator generated by GP. Therefore, this generative approach may provide some novel avenues of thought for the automatically design of EC algorithm operators.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {623–626},
numpages = {4},
keywords = {evolutionary computation, genetic programming, generative artificial intelligence, generative evolutionary computation},
location = {NH Malaga Hotel, Malaga, Spain},
series = {GECCO '25 Companion}
}

@inproceedings{10.1145/3680532.3689592,
author = {Singh, Gurprit and Jakob, Wenzel},
title = {MCMC: Bridging Rendering, Optimization and Generative AI},
year = {2024},
isbn = {9798400711350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680532.3689592},
doi = {10.1145/3680532.3689592},
abstract = {Generative artificial intelligence (AI) has made unprecedented advances in vision language models over the past two years. These advances are largely due to diffusion-based generative models, which are very stable and simple to train. These diffusion models are tasked to learn the underlying unknown distribution of the training data samples. During the generative process, new samples (images) are generated from this unknown high-dimensional distribution. Markov Chain Monte Carlo (MCMC) methods are particularly effective in drawing samples from complex, high-dimensional distributions. This makes MCMC methods an integral component for both the training and sampling phases of these models, ensuring accurate sample generation.Gradient-based optimization is at the core of modern generative models. The update step during the optimization forms a Markov chain where the new update depends only on the current state. This allows exploration of the parameter space in a memoryless manner, thus combining the benefits of gradient-based optimization and MCMC sampling. MCMC methods have shown an equally important role in physically based rendering where complex light paths are otherwise quite challenging to sample from simple importance sampling techniques.A lot of research is dedicated towards bringing physical realism to samples (images) generated from diffusion-based generative models in a data-driven manner, however, a unified framework connecting these techniques is still missing. In this course, we take the first steps toward understanding each of these components and exploring how MCMC could potentially serve as a bridge, linking these closely related areas of research. Our tutorial aims to provide necessary theoretical and practical tools to guide students, researchers and practitioners towards the common goal of generative physically based rendering. All Jupyter notebooks with demonstrations associated to this tutorial can be found on our project webpage https://sinbag.github.io/mcmc/.},
booktitle = {SIGGRAPH Asia 2024 Courses},
articleno = {8},
numpages = {27},
location = {Tokyo, Japan},
series = {SA Courses '24}
}

@inproceedings{10.1145/3491101.3503719,
author = {Muller, Michael and Chilton, Lydia B and Kantosalo, Anna and Martin, Charles Patrick and Walsh, Greg},
title = {GenAICHI: Generative AI and HCI},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3503719},
doi = {10.1145/3491101.3503719},
abstract = {This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together. It is time to convene the interdisciplinary research domain of generative AI and HCI. Participation in this invitational workshop is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {110},
numpages = {7},
keywords = {Bias, Design, Generative AI, Uncertainty.},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@inproceedings{10.1145/3647444.3647910,
author = {Rawat, Swati and Mittal, Sumit and Nehra, Deepa and Sharma, Chandani and Kamboj, Dalip},
title = {Exploring the Potential of ChatGPT to improve experiential learning in Education},
year = {2024},
isbn = {9798400709418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3647444.3647910},
doi = {10.1145/3647444.3647910},
abstract = {Artificial Intelligence (AI) is revolutionizing the field of education by offering new possibilities for personalized and experiential learning along with data-driven insights. The advancement in AI to Generative Artificial Intelligence (GAI) has made the tables turn notably in the field of education. Generative AI application tool ChatGPT is emerging as a game changer offering personalized learning experiences by analyzing huge amounts of student data, generating study materials and pacing to individual needs. Intelligent educational tools powered by AI provide personalized guidance and feedback, adapting to curriculum to address knowledge gaps. GAI also automates the grading process, providing instant feedback and relieving teachers for qualitative assessments. This research paper offers a thorough examination of the potential uses, advantages, difficulties, and moral issues related to implementing ChatGPT in educational contexts. The authors closely analyze how ChatGPT can improve educational experiences, assist personalized learning, and encourage student- teacher interaction, while exploring the drawbacks of using generative AI models in education, such as concerns about bias, data privacy, and over-reliance on technology. This research article intends to offer educators \&amp; academicians useful insights into the usage of ChatGPT in the educational field through a critical analysis of the existing literature and real- world experiences.},
booktitle = {Proceedings of the 5th International Conference on Information Management \&amp; Machine Intelligence},
articleno = {83},
numpages = {8},
keywords = {ChatGPT, Generative Artificial Intelligence (GAI), Natural Language Processing, OpenAI, Teaching \&amp; Learning, Education},
location = {Jaipur, India},
series = {ICIMMI '23}
}

@inproceedings{10.1145/3641554.3701806,
author = {Kannam, Suhas and Yang, Yuri and Dharm, Aarya and Lin, Kevin},
title = {Code Interviews: Design and Evaluation of a More Authentic Assessment for Introductory Programming Assignments},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701806},
doi = {10.1145/3641554.3701806},
abstract = {Generative artificial intelligence poses new challenges around assessment, increasingly driving introductory programming educators to employ invigilated exams. But exams do not afford more authentic programming experiences that involve planning, implementing, and debugging programs with computer interaction. In this experience report, we describe code interviews: a more authentic assessment method for take-home programming assignments. Through action research, we experimented with the number and type of questions as well as whether interviews were conducted individually or with groups of students. To scale the program, we converted most of our weekly teaching assistant (TA) sections to conduct code interviews on 5 major weekly take-home programming assignments. By triangulating data from 5 sources, we identified 4 themes. Code interviews (1) pushed students to discuss their work, motivating more nuanced but sometimes repetitive insights; (2) enabled peer learning, reducing stress in some ways but increasing stress in other ways; (3) scaled with TA-led sections, replacing familiar practice with an unfamiliar assessment; (4) focused on student contributions, limiting opportunities for TAs to give guidance and feedback. We reflect on the design of code interviews for student experience, academic integrity, and teacher workload.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {554–560},
numpages = {7},
keywords = {authentic assessment, introductory programming, oral exams},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3704289.3704302,
author = {Pan, Ruoqi and Chen, Liting and Ma, Shiming},
title = {Exploration of Engineering and Design Fusion in 3E of Digital Media Technology Major Empowered by AIGC},
year = {2025},
isbn = {9798400716980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704289.3704302},
doi = {10.1145/3704289.3704302},
abstract = {With the rapid advancement of generative artificial intelligence, its demonstrated intelligence, cognition, and other abilities have created new opportunities for the reform of education. This paper examines the core curriculum development of digital media technology, the situation of emerging engineering education(3E), and the application of AIGC in education. It concludes that the main bottlenecks in the fusion of engineering and design of digital media technology are curriculum development, assessment, and duration of practical training. Consequently, the study explores the application and facilitation of AIGC within digital media technology and how AIGC alleviates the bottlenecks of major development. Building on this, the paper presents a case study centered on the core curriculum of digital media technology that found AIGC can significantly improve course teaching efficiency. It aims to provide insights and recommendations for teaching practices in core digital media technology courses.},
booktitle = {Proceedings of the 2024 7th International Conference on Big Data and Education},
pages = {36–41},
numpages = {6},
keywords = {AIGC, Curriculum Construction, Digital Media Technology, Engineering and Design Fusion},
location = {
},
series = {ICBDE '24}
}

@inproceedings{10.1145/3675094.3677573,
author = {Wang, Yongfu and Tang, Mingyue and He, Yifan and Tang, Tiffany Y.},
title = {Interactive Design with Autistic Children using LLM and IoT for Personalized Training: The Good, The Bad and The Challenging},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3677573},
doi = {10.1145/3675094.3677573},
abstract = {The advent of generative artificial intelligence technologies, such as Large Language Models (LLMs) and Large Vision Models (LVMs), has shown promising results in both academic and industrial sectors, leading to widespread adoption. However, there has been limited focus on applying these technologies to assist children with special needs like Autism Spectrum Disorder (ASD). Meanwhile, conventional personalized training with interactive design for children with special needs continues to face significant challenges with traditional approaches. This workshop aims to provide a platform for researchers, software developers, medical practitioners, and designers to discuss and evaluate the benefits and drawbacks of using LLMs and the Internet of Things (IoT) for the diagnosis and personalized training of autistic children. Through a series of activities, including oral presentations, demonstrations, and panel discussions, this half-day workshop seeks to foster a network of experts dedicated to improving the lives of children with special needs and to inspire further research on leveraging emerging ubiquitous technologies for these underprivileged users, their caregivers and special education teachers.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1000–1003},
numpages = {4},
keywords = {autism, children, interaction design, large language model (llm), personalized training, ubiquitous computing},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@article{10.1145/3686803,
author = {Li, Jialong and Zhang, Mingyue and Li, Nianyu and Weyns, Danny and Jin, Zhi and Tei, Kenji},
title = {Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1556-4665},
url = {https://doi.org/10.1145/3686803},
doi = {10.1145/3686803},
abstract = {Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this article aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI’s within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.†},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = sep,
articleno = {13},
numpages = {60},
keywords = {Self-Adaptive Systems, MAPE, Generative AI, Large Language Model, diffusion model, survey}
}

@inproceedings{10.1145/3706598.3714253,
author = {Oh, Jeongseok and Kim, SeungJun},
title = {MoWa: An Authoring Tool for Refining AI-Generated Human Avatar Motions Through Latent Waveform Manipulation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714253},
doi = {10.1145/3706598.3714253},
abstract = {Creating expressive and realistic motion animations is a challenging task. Generative artificial intelligence (AI) models have emerged to address this challenge, offering the capability to synthesize human motion animations from text prompts. However, the effective integration of AI-generated motion into professional designer workflows remains uncertain. This study proposes MoWa, an authoring tool designed to refine AI-generated human motions to meet professional standards. A formative study with six professional motion designers identified the strengths and weaknesses of AI-generated motions. To address these weaknesses, MoWa utilizes latent space to enhance the expressiveness of motions, making them suitable for use in professional workflows. A user study involving twelve professional motion designers was conducted to evaluate MoWa’s effectiveness in refining AI-generated motions. The results indicated that MoWa streamlines the motion design process and improves the quality of the outcomes. These findings suggest that incorporating latent space into motion design tasks can improve efficiency.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1240},
numpages = {21},
keywords = {creativity support tool, graphics design, artificial intelligence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3754508.3754519,
author = {Botta, Colton and Robertson, Judy and Mcmellon, Christina and Lawson, Jamie and Ajala, Jedidah and Lugo Gonzalez, Sofia and Hamidi, Amina and Hicks, Nia and McDonald, Kara and Paterson, Ross John and Scott, Peter and Tang, Jessie},
title = {Secondary Students as Co-Researchers on Generative AI in Learning: Empowering Youth to Shape National Education Policy},
year = {2025},
isbn = {9798400720789},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3754508.3754519},
doi = {10.1145/3754508.3754519},
abstract = {As Generative Artificial Intelligence (GenAI) becomes an increasingly significant part of young people’s lives, educators worry about its impact on learning and attainment. However, understanding this impact requires more than simply studying young people’s behaviours or soliciting their opinions. It is essential to involve them actively as co-researchers, allowing their unique perspectives to shape the conversation around GenAI in schools. This project moves beyond seeing young people as research subjects, positioning them instead as co-designers, co-researchers, and potential influencers of national policy on GenAI in education. We recruited eight young people (aged 16–18) from three Scottish high schools to serve as Young People Co-Researchers (YPCR). Together, we explored their perspectives on GenAI at school, including their current usage, views on appropriate tasks for AI, and opinions on teachers’ use of AI. The YPCR organised and conducted semi-structured focus groups with 50 peers and collaboratively analysed the findings with adult researchers. Our results show that young people are cautiously optimistic about GenAI’s potential for learning and do not support outright bans in schools. They clearly distinguish between AI use for learning and in assessments, often expressing confusion over current policies and wishing for clearer guidance. The YPCR stated a strong desire to deepen their understanding of AI’s advantages and risks and for schools to teach responsible, effective use. Their insights are valuable for national policy development and for AI literacy initiatives.},
booktitle = {Proceedings of the 2025 Conference on UK and Ireland Computing Education Research},
articleno = {10},
numpages = {7},
keywords = {AI, secondary school, user consultation},
location = {
},
series = {UKICER '25}
}

@inproceedings{10.1109/SCW63240.2024.00057,
author = {Rafid, Ali Haisam Muhammad and Yin, Junqi and Geng, Yuwei and Liang, Siming and Bao, Feng and Ju, Lili and Zhang, Guannan},
title = {A Scalable Training-Free Diffusion Model for Uncertainty Quantification},
year = {2025},
isbn = {9798350355543},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SCW63240.2024.00057},
doi = {10.1109/SCW63240.2024.00057},
abstract = {Generative artificial intelligence extends beyond its success in image/text synthesis, proving itself a powerful uncertainty quantification (UQ) technique through its capability to sample from complex high-dimensional probability distributions. However, existing methods often require a complicated training process, which greatly hinders their applications to real-world UQ problems, especially in dynamic UQ tasks where the target probability distribution evolves rapidly with time. To alleviate this challenge, we have developed a scalable, training-free score-based diffusion model for high-dimensional sampling. We incorporate a parallel-in-time method into our diffusion model to use a large number of GPUs to solve the backward stochastic differential equation and generate new samples of the target distribution. Moreover, we also distribute the computation of the large matrix subtraction used by the training-free score estimator onto multiple GPUs available across all nodes. Compared to existing methods, our approach completely avoids training the score function, making it capable of adapting to rapid changes in the target probability distribution. We showcase the remarkable strong and weak scaling capabilities of the proposed method on the Frontier supercomputer, as well as its uncertainty reduction capability in hurricane predictions when coupled with AI-based foundation models.},
booktitle = {Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {380–386},
numpages = {7},
location = {Atlanta, GA, USA},
series = {SC-W '24}
}

@inproceedings{10.1145/3746175.3746199,
author = {H\'{e}ron, Robin and Fr\'{e}jus, Myriam},
title = {Bridging the conceptual gap between workers and data-scientists' needs in the design process of a GenAI-based tool: an ergonomics intervention for an ombudsman's team},
year = {2025},
isbn = {9798400720338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746175.3746199},
doi = {10.1145/3746175.3746199},
abstract = {With ‘Generative Artificial Intelligence’ (GenAI), a new momentum has swept public opinion and, as with the Times front page on 27 February 2023, which describes an ‘arms race’ among major companies. While the GenAI in the workplace is new, the few studies suggest several benefits of such systems in work contexts. However, these results focus on the quantitative indicators, and further literature on the implementation of generative AI systems at work is still scarce. In this context, it is important to specify how to integrate a GenAI-based tool into an existing socio-technical organisation, as such integration always deeply transforms the employees’ activity. In this paper, we discuss the human-centred design of GenAI-based tools on the basis of an ergonomics intervention for the Ombudsman's team of an energy utility company. We explore how a participatory design approach – grounded in the preliminary analysis of the work – can help inform the development of a GenAI-based tool. We discuss the relevance of this methodology and the intermediary role of the ergonomists, given the dual challenge that end-users often lack a comprehensive understanding of GenAI's possibilities and potential applications, while data-scientists responsible for developing such tools are not trained to analyse complex work activities, which is a necessary step for selecting and training the appropriate AI models.},
booktitle = {Proceedings of the 36th Annual Conference of the European Association of Cognitive Ergonomics},
articleno = {18},
numpages = {8},
keywords = {GenAI, HCAI},
location = {
},
series = {ECCE '25}
}

@inproceedings{10.1145/3677052.3698645,
author = {Han, Xuewen and Wang, Neng and Che, Shangkun and Yang, Hongyang and Zhang, Kunpeng and Xu, Sean Xin},
title = {Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in Financial Research},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698645},
doi = {10.1145/3677052.3698645},
abstract = {In recent years, the application of generative artificial intelligence (GenAI) in financial analysis and investment decision-making has gained significant attention. However, most existing approaches rely on single-agent systems, which fail to fully utilize the collaborative potential of multiple AI agents. In this paper, we propose a novel multi-agent collaboration system designed to enhance decision-making in financial investment research. The system incorporates agent groups with both configurable group sizes and collaboration structures to leverage the strengths of each agent group type. By utilizing a sub-optimal combination strategy, the system dynamically adapts to varying market conditions and investment scenarios, optimizing performance across different tasks. We focus on three sub-tasks: fundamentals, market sentiment, and risk analysis, by analyzing the 2023 SEC 10-K forms of 30 companies listed on the Dow Jones Index. Our findings reveal significant performance variations based on the configurations of AI agents for different tasks. The results demonstrate that our multi-agent collaboration system outperforms traditional single-agent models, offering improved accuracy, efficiency, and adaptability in complex financial environments. This study highlights the potential of multi-agent systems in transforming financial analysis and investment decision-making by integrating diverse analytical perspectives.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {538–546},
numpages = {9},
keywords = {AI-agent, Financial Report Analysis, Investment Research, Multi-agent Collaboration},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@inproceedings{10.1145/3626253.3633407,
author = {Westerlund, Jill and Czajka, Sandra and Kuemmel, Andrew},
title = {Innovative Strategies for genAI in CS Courses},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633407},
doi = {10.1145/3626253.3633407},
abstract = {Students are using generative artificial intelligence (genAI), organizations are embracing AI and machine learning, tools are emerging almost daily, and addressing these evolving technologies can be overwhelming. Rather than choosing to ignore genAI, instructors of computer science (CS) can find ways to teach with and guide students in the use of genAI in their courses. Teaching about genAI can be incorporated with instruction about effective and appropriate uses of the ever-growing tools.This special session brings together three experienced CS educators who integrate genAI in their work with high school students, college students, and in-service teachers. The session environment allows for participant involvement in three model activities that showcase genAI tools with learner-focused practices. Participants will be provided supporting teaching resources for each guided activity and encouraged to discuss with peers and presenters.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1875–1876},
numpages = {2},
keywords = {ai, assessment, genai, instruction},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3627508.3638293,
author = {Odede, Julius and Frommholz, Ingo},
title = {JayBot -- Aiding University Students and Admission with an LLM-based Chatbot},
year = {2024},
isbn = {9798400704345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627508.3638293},
doi = {10.1145/3627508.3638293},
abstract = {This demo paper presents JayBot, an LLM-based chatbot system aimed at enhancing the user experience of prospective and current students, faculty, and staff at a UK university. The objective of JayBot is to provide information to users on general enquiries regarding course modules, duration, fees, entry requirements, lecturers, internship, career paths, course employability and other related aspects. Leveraging the use cases of generative artificial intelligence (AI), the chatbot application was built using OpenAI’s advanced large language model (GPT-3.5 turbo); to tackle issues such as hallucination as well as focus and timeliness of results, an embedding transformer model has been combined with a vector database and vector search. Prompt engineering techniques were employed to enhance the chatbot’s response abilities. Preliminary user studies indicate JayBot’s effectiveness and efficiency. The demo will showcase JayBot in a university admission use case and discuss further application scenarios.},
booktitle = {Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
pages = {391–395},
numpages = {5},
keywords = {Artificial Intelligence, Chatbot, Interactive Information Retrieval, Large Language Models, Machine Learning, Retrieval Augmented Generation, Vector Database},
location = {Sheffield, United Kingdom},
series = {CHIIR '24}
}

@inproceedings{10.1145/3613904.3642861,
author = {Mahdavi Goloujeh, Atefeh and Sullivan, Anne and Magerko, Brian},
title = {Is It AI or Is It Me? Understanding Users’ Prompt Journey with Text-to-Image Generative AI Tools},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642861},
doi = {10.1145/3613904.3642861},
abstract = {Generative Artificial Intelligence (AI) has witnessed unprecedented growth in text-to-image AI tools. Yet, much remains unknown about users’ prompt journey with such tools in the wild. In this paper, we posit that designing human-centered text-to-image AI tools requires a clear understanding of how individuals intuitively approach crafting prompts, and what challenges they may encounter. To address this, we conducted semi-structured interviews with 19 existing users of a text-to-image AI tool. Our findings (1) offer insights into users’ prompt journey including structures and processes for writing, evaluating, and refining prompts in text-to-image AI tools and (2) indicate that users must overcome barriers to aligning AI to their intents, and mastering prompt crafting knowledge. From the findings, we discuss the prompt journey as an individual yet a social experience and highlight opportunities for aligning text-to-image AI tools and users’ intents.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {183},
numpages = {13},
keywords = {Prompt engineering, generative AI, text-to-image generation, user journey},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3660605.3660941,
author = {Rao, Kunal and Coviello, Giuseppe and Benedetti, Priscilla and Giuseppe De Vita, Ciro and Mellone, Gennaro and Chakradhar, Srimat},
title = {ECO-LLM: LLM-based Edge Cloud Optimization},
year = {2024},
isbn = {9798400706523},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660605.3660941},
doi = {10.1145/3660605.3660941},
abstract = {AI/ML techniques have been used to solve systems problems, but their applicability to customize solutions on-the-fly has been limited. Traditionally, any customization required manually changing the AI/ML model or modifying the code, configuration parameters, application settings, etc. This incurs too much time and effort, and is very painful. In this paper, we propose a novel technique using Generative Artificial Intelligence (GenAI) technology, wherein instructions can be provided in natural language and actual code to handle any customization is automatically generated, integrated and applied on-the-fly. Such capability is extremely powerful since it makes customization of application settings or solution techniques super easy. Specifically, we propose ECO-LLM (LLM-based Edge Cloud Optimization), which leverages Large Language Models (LLM) to dynamically adjust placement of application tasks across edge and cloud computing tiers, in response to changes in application workload, such that insights are delivered quickly with low cost of operation (systems problem). Our experiments with real-world video analytics applications i.e. face recognition, human attributes detection and license plate recognition show that ECO-LLM is able to automatically generate code on-the-fly and adapt placement of application tasks across edge and cloud computing tiers. We note that the trigger workload (to switch between edge and cloud) for ECO-LLM is exactly the same as the baseline (manual) and actual placement performed by ECO-LLM is only slightly different i.e. on average (across 2 days) only 1.45\% difference in human attributes detection and face recognition, and 1.11\% difference in license plate recognition. Although we tackle this specific systems problem in this paper, our proposed GenAI-based technique is applicable to solve other systems problems too.},
booktitle = {Proceedings of the 2024 Workshop on AI For Systems},
pages = {7–12},
numpages = {6},
keywords = {large language models (LLM), generative artificial intelligence (GenAI), machine learning (ML), customization, optimization, edge computing, cloud computing, video analytics},
location = {Pisa, Italy},
series = {AI4Sys '24}
}

@inproceedings{10.1145/3653946.3653952,
author = {Cheng, Weijing},
title = {Prompt Retrieval from Stable Diffusion Generated Images Using the ConvNeXt CLIP Network},
year = {2024},
isbn = {9798400716553},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653946.3653952},
doi = {10.1145/3653946.3653952},
abstract = {Stable Diffusion has recently emerged as a groundbreaking technique in the field of generative artificial intelligence. By utilizing concise text prompts, Stable Diffusion is capable of producing images that are either strikingly realistic or visually stunning, bridging the gap between textual descriptions and visual representations. A notable challenge associated with Stable Diffusion is the retrieval of corresponding prompts from generated images. To tackle this challenge, we employed a strategy that leverages the capabilities of the ConvNeXt model within the OpenCLIP framework. Having trained the model on an extensive dataset of nearly 2.1 million Stable Diffusion generated images, we then subjected our approach to the evaluation of the Kaggle Stable Diffusion - Image to Prompts competition. The effectiveness of our methodology is underscored by a mean cosine similarity score of 0.63032 between the predicted and actual prompt embedding vectors on the private test set, securing a silver medal position. This achievement not only attests to the robustness of our approach but also signifies its potential in diverse sectors where the retrieval of text from images is of great importance.},
booktitle = {Proceedings of the 2024 7th International Conference on Machine Vision and Applications},
pages = {35–40},
numpages = {6},
keywords = {CLIP, ConvNeXt, Kaggle, Prompt Retrieval, Stable Diffusion},
location = {Singapore, Singapore},
series = {ICMVA '24}
}

@inproceedings{10.1145/3678698.3687205,
author = {Pan, Sibo and She, James},
title = {Tanka Heritage Revived: AI-Generated Artworks in Three Chinese Art Styles},
year = {2024},
isbn = {9798400709678},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678698.3687205},
doi = {10.1145/3678698.3687205},
abstract = {This work explores the potential of generative artificial intelligence (GenAI) in creating artworks to represent Tanka culture. By employing Midjourney and ChatGPT, it aims to enhance the preservation and public engagement of Tanka heritage. The approach includes collecting data on Tanka cultural heritage, transforming textual data into prompts with ChatGPT, generating artworks via Midjourney, and filtering the AI-generated artworks to ensure cultural and artistic fidelity. Three distinct Chinese art styles — ink painting, meticulous painting, and photography — were chosen to depict different historical phases of Tanka culture, from early harmonious relationships to contemporary life. This work demonstrates the transformative potential of GenAI in cultural preservation, offering a novel approach to engaging a broader audience and promoting traditional cultural heritage.},
booktitle = {Proceedings of the 17th International Symposium on Visual Information Communication and Interaction},
articleno = {50},
numpages = {2},
keywords = {Tanka Cultural Heritage, Generative AI, AI-generated Artwork, Chinese Art Style, Cultural Preservation},
location = {
},
series = {VINCI '24}
}

@inproceedings{10.1145/3706598.3713528,
author = {Zhang, Hongbo and Chen, Pei and Yang, Jingwen and Wu, Yifei and Jiang, Zhaoqu and Xie, Xuelong and You, Weitao and Sun, Lingyun},
title = {IEDS: Exploring an Intelli-Embodied Design Space Combining Designer, AR, and GAI to Support Industrial Conceptual Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713528},
doi = {10.1145/3706598.3713528},
abstract = {Conceptual design is an important stage in industrial product development, influenced by the design space and materials available to designers. Advancements in human-computer interaction&nbsp;(HCI) and artificial intelligence&nbsp;(AI) technologies have broadened these aspects considerably. On the one hand, augmented reality&nbsp;(AR) technologies merge physical and virtual representations to enhance intuitive interaction and embodied cognition. On the other hand, generative artificial intelligence&nbsp;(GAI) serves as a novel design material, boosting creativity and productivity. Inspired by these technological strides, we proposed an Intelli-Embodied Design Space&nbsp;(IEDS), which integrates designers, AR, and GAI to support industrial conceptual design by combining embodied interaction with generative variability. Within IEDS, designers can interact with the physical prototypes intuitively, while GAI refines these into virtual forms that can be embedded in the physical world through AR technology. In this study, we established the theoretical framework and interaction modes of IEDS through literature reviews and expert interviews. Subsequently, we designed and implemented three GAI+AR tools, GAI + Head-mounted Display&nbsp;(HMD), GAI + Handheld Display&nbsp;(HHD), and GAI + Spatial Augmented Reality&nbsp;(SAR), based on three AR approaches in IEDS to practically examine the benefits and challenges of these interaction modes across industrial conceptual design tasks. We discussed IEDS’s influence on industrial conceptual design and released its application guidelines to the HCI community.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {33},
numpages = {25},
keywords = {conceptual design, augmented reality, generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706594.3727961,
author = {Guibert, Lo\"{\i}c and Reynaud, S\'{e}bastien and Weppe, Olivier and Ciko, Kristjon and Welzl, Michael and Rumley, S\'{e}bastien},
title = {TRAFFIC: Testbed foR Assessing energy eFFiciency In throughput Computing},
year = {2025},
isbn = {9798400713934},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706594.3727961},
doi = {10.1145/3706594.3727961},
abstract = {Information and Communication Technologies (ICT) represent a significant share of global resource usage. Notably, the energy consumption of data centres has emerged as a critical concern, escalating rapidly, especially with the rise of generative Artificial Intelligence (AI) models. This surge in energy demand calls for efforts focused on measuring and reducing the energy and carbon footprints of components used in ICT service delivery. However, the variety and multitude of devices involved in these services make it challenging to accurately measure and evaluate these footprints.In this paper, we propose an alternative approach to assess energy impacts by considering data centres for what they are: throughput computing systems offering ICT services. We define a simple experimental testbed and evaluate several machines with different hardware capacities. These machines serve two ICT services: a loop incrementing a counter until a defined limit, and an AI inference predicting the next token based on an input.Our experiment highlights three main take-aways: (a) the CPU usage is a poor predictor of the power consumption, (b) the energy or CO2 quantity associated with a service visit highly depends on the total load the service is facing, and (c) modern machines do not yield better energy figures compared to older ones in all circumstances.},
booktitle = {Proceedings of the 22nd ACM International Conference on Computing Frontiers: Workshops and Special Sessions},
pages = {99–107},
numpages = {9},
keywords = {Energy, Throughput computing, ICT carbon footprint},
location = {
},
series = {CF '25 Companion}
}

@inproceedings{10.1145/3678890.3678922,
author = {Ricker, Jonas and Assenmacher, Dennis and Holz, Thorsten and Fischer, Asja and Quiring, Erwin},
title = {AI-Generated Faces in the Real World: A Large-Scale Case Study of Twitter Profile Images},
year = {2024},
isbn = {9798400709593},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678890.3678922},
doi = {10.1145/3678890.3678922},
abstract = {Recent advances in the field of generative artificial intelligence (AI) have blurred the lines between authentic and machine-generated content, making it almost impossible for humans to distinguish between such media. One notable consequence is the use of AI-generated images for fake profiles on social media. While several types of disinformation campaigns and similar incidents have been reported in the past, a systematic analysis has been lacking. In this work, we conduct the first large-scale investigation of the prevalence of AI-generated profile pictures on Twitter. We tackle the challenges of a real-world measurement study by carefully integrating various data sources and designing a multi-stage detection pipeline. Our analysis of nearly 15 million Twitter profile pictures shows that 0.052\% were artificially generated, confirming their notable presence on the platform. We comprehensively examine the characteristics of these accounts and their tweet content, and uncover patterns of coordinated inauthentic behavior. The results also reveal several motives, including spamming and political amplification campaigns. Our research reaffirms the need for effective detection and mitigation strategies to cope with the potential negative effects of generative AI in the future.},
booktitle = {Proceedings of the 27th International Symposium on Research in Attacks, Intrusions and Defenses},
pages = {513–530},
numpages = {18},
keywords = {AI-Generated Content, Fake Image Detection, Social Networks},
location = {Padua, Italy},
series = {RAID '24}
}

@inproceedings{10.1145/3641555.3705278,
author = {Jayaraman, Sharanya and Kolarkar, Ameya},
title = {Using Peer Tutoring to Bolster Retention Rates and Student Performance in CS1 Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705278},
doi = {10.1145/3641555.3705278},
abstract = {Active Learning approaches have found success in CS1 and CS2 courses, consolidating instructional time on the practical, problem-solving aspects of programming. With the increasing availability of generative Artificial Intelligence Assistants, there is a renewed push to focus on higher-order skills beyond syntax and solving programming problems by matching sample outputs.This poster examines the impact of conceptual explanation-based exercises in introductory programming courses through the implementation of a scaffolded semi-flipped classroom. This method is currently in its third semester as a part of an ongoing, iterative, semi-experimental approach to support student resilience in entrance-level courses. This approach aimed to enhance student engagement, retention, and performance by integrating weekly practice sessions and "group-tutoring" sessions facilitated by peer learning assistants. In these sessions, students were encouraged to articulate their problem-solving strategies and the reasoning behind their solutions, fostering a deeper understanding of programming language paradigms and problem-solving techniques.The findings indicate that this method significantly increased classroom engagement, as students became more active participants in their learning journey. Retention rates improved as students became more confident in understanding and applying programming concepts. Overall, student performance saw a notable rise, with students demonstrating a better grasp of programming paradigms and problem-solving approaches beyond rote memorization and matching sample outputs.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1495–1496},
numpages = {2},
keywords = {active learning, cs1/cs2, peer-based learning, self-assessment},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3731763.3731792,
author = {Vu, Khoi Anh and Ngo, Khoa Quoc Anh and Tran, Anh Huy and Nguyen, Phuc Le Hoang and Nguyen, Duong Huu and Tran, Bao Dinh Gia},
title = {AI Tool for Room Decoration: Harnessing Diffusion Model for Interior Design},
year = {2025},
isbn = {9798400710841},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3731763.3731792},
doi = {10.1145/3731763.3731792},
abstract = {Based on the capabilities of generative artificial intelligence (AI) models, particularly diffusion models, this study proposes an effective AI tool for interior design. This tool helps users create personalized and aesthetically pleasing decoration ideas by leveraging diffusion models’ ability to analyze and reconstruct the fundamental distribution of interior design elements, enabling adaptation to diverse styles and trends. The accompanying figure illustrates the tool’s functionality through examples of three key tasks: appearance modulation, object moving and resizing, and object pasting, with clear visualizations of input and output images. By automating repetitive tasks, the tool significantly reduces the time and effort required in the design process while also encouraging creativity by allowing users to explore a broader range of design possibilities. In general, this study presents an innovative application of diffusion models in interior design, providing an AI-powered tool to enhance the user experience and support the creative interior styling process.},
booktitle = {Proceedings of the 2025 10th International Conference on Intelligent Information Technology},
pages = {87–91},
numpages = {5},
keywords = {Stable Diffusion, Image Generation, Neural Networks, Computer Vision, Generative Models, Deep Learning, Rendering, Interior Design, User Interface, Personalization},
location = {
},
series = {ICIIT '25}
}

