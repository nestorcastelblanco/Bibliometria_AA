@article{10.1145/3757620,
author = {Morales-Navarro, Luis and Gan, Michelle A. and Yu, Evelyn and Vogelstein, Lauren and Kafai, Yasmin and Metaxa, Dana\'{e}},
title = {Learning AI Auditing: A Case Study of Teenagers Auditing a Generative AI Model},
year = {2025},
issue_date = {November 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {7},
url = {https://doi.org/10.1145/3757620},
doi = {10.1145/3757620},
abstract = {This study investigates how high school-aged youth engage in algorithm auditing to identify and understand biases in artificial intelligence and machine learning (AI/ML) tools they encounter daily. With AI/ML technologies being increasingly integrated into young people's lives, there is an urgent need to equip teenagers with AI literacies that build both technical knowledge and awareness of social impacts. Algorithm audits (also called AI audits) have traditionally been employed by experts to assess potential harmful biases, but recent research suggests that non-expert users can also participate productively in auditing. We conducted a two-week participatory design workshop with 14 teenagers (ages 14-15), where they audited the generative AI model behind TikTok's Effect House, a tool for creating interactive TikTok filters. We present a case study describing how teenagers approached the audit, from deciding what to audit to analyzing data using diverse strategies and communicating their results. Our findings show that participants were engaged and creative throughout the activities, independently raising and exploring new considerations, such as age-related biases, that are uncommon in professional audits. We drew on our expertise in algorithm auditing to triangulate their findings as a way to examine if the workshop supported participants to reach coherent conclusions in their audit. Although the resulting number of changes in race, gender, and age representation uncovered by the teens were slightly different from ours, we reached similar conclusions. This study highlights the potential for auditing to inspire learning activities to foster AI literacies, empower teenagers to critically examine AI systems, and contribute fresh perspectives to the study of algorithmic harms.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {CSCW439},
numpages = {29},
keywords = {TikTok, algorithm auditing, algorithmic justice, artificial intelligence, child-computer interaction, effect house, generative artificial intelligence, machine learning, participatory design, responsible ai, youth}
}

@inbook{10.1145/3757749.3757785,
author = {Lei, Qiang and Lu, Yao and Li, Qian and Li, Linzhi and Wang, Ye and Qiu, Xin},
title = {Research on Dynamic Video of Qijiang Woodblock Prints Based on AIGC Technology},
year = {2025},
isbn = {9798400713347},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3757749.3757785},
abstract = {As a unique folk art form in Southwest China, Qijiang New Year pictures are facing the dual challenges of static communication limitation and insufficient technical adaptation in the digital transformation. Based on the technology of Generative Artificial Intelligence (AIGC), by constructing a multi-objective loss function that integrates the semantic alignment of text, color constraint and style feature preservation mechanism, the key problems such as color deviation and motion mutation in the dynamic process of traditional woodcut are solved. Combining optical flow-oriented interpolation algorithm and physical simulation post-processing technology, the optimization of time sequence consistency and the accurate expression of cultural symbols are realized. Through the double evaluation system of quantitative indicators and user cognitive experiments, the advantages of the algorithm in sports fluency, style fidelity and narrative consistency are verified. This technology can be applied to cultural heritage communication, educational tourism and video game industry, and its cross-domain application potential needs to be reconstructed by activating young people's immersive experience.},
booktitle = {Proceedings of the 2025 2nd International Conference on Computer and Multimedia Technology},
pages = {224–228},
numpages = {5}
}

@inproceedings{10.1145/3706598.3713467,
author = {Xiao, Tianyi and Chen, Yizi and Zhong, Sailin and Kiefer, Peter and Krukar, Jakub and Kim, Kevin Gonyop and Hurni, Lorenz and Schwering, Angela and Raubal, Martin},
title = {Sketch2Terrain: AI-Driven Real-Time Terrain Sketch Mapping in Augmented Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713467},
doi = {10.1145/3706598.3713467},
abstract = {Sketch mapping is an effective technique to externalize and communicate spatial information. However, it has been limited to 2D mediums, making it difficult to represent 3D information, particularly for terrains with elevation changes. We present Sketch2Terrain, an intuitive generative-3D-sketch-mapping system combining freehand sketching with generative Artificial Intelligence that radically changes sketch map creation and representation using Augmented Reality. Sketch2Terrain empowers non-experts to create unambiguous sketch maps of natural environments and provides a homogeneous interface for researchers to collect data and conduct experiments. A between-subject study (N=36) revealed that generative-3D-sketch-mapping improved efficiency by 38.4\%, terrain-topology accuracy by 12.5\%, and landmark accuracy by up to 12.1\%, with only a 4.7\% trade-off in terrain-elevation accuracy compared to freehand 3D-sketch-mapping. Additionally, generative-3D-sketch-mapping reduced perceived strain by 60.5\% and stress by 39.5\% over 2D-sketch-mapping. These findings underscore potential applications of generative-3D-sketch-mapping for in-depth understanding and accurate representation of vertically complex environments. The implementation is publicly available.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {553},
numpages = {24},
keywords = {Generative 3D sketch mapping, augmented reality, generative AI, terrain generation, spatial cognition},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3563703.3596652,
author = {El-Zanfaly, Dina and Huang, Yiwei and Dong, Yanwen},
title = {Sand-in-the-loop: Investigating embodied co-creation for shared understandings of generative AI},
year = {2023},
isbn = {9781450398985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563703.3596652},
doi = {10.1145/3563703.3596652},
abstract = {Generative Artificial Intelligence (AI) applications in creative practices have grown tremendously over the past few years. However, these generative AI applications lack clarity on how they work and operate for their users. Revealing how generative AI tools work enables designers to understand these tools’ limitations and capabilities. We developed a tangible interface with sand as a medium for human-AI co-creation, Sand Playground. It extends the work in human-AI drawing practices beyond two-dimensional digital surfaces. Sand playground has three co-drawing modes, artistic mimicry, zen garden and doodling. We conducted a user study with ten designers. One of our findings is that the interface enabled users to predict the AI agent’s actions. Our research introduces novel insights into the role of tangible interactions and physical interfaces in generative AI literacy and explainability in design tools.},
booktitle = {Companion Publication of the 2023 ACM Designing Interactive Systems Conference},
pages = {256–260},
numpages = {5},
keywords = {Explainable AI, Graspable AI, human-AI co-creation},
location = {Pittsburgh, PA, USA},
series = {DIS '23 Companion}
}

@inbook{10.1145/3711129.3711250,
author = {Wei, Xueling and Lin, Tao},
title = {A Risk Prediction System for Business Management Decisions Based on Artificial Intelligence Generated Content},
year = {2025},
isbn = {9798400710094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711129.3711250},
abstract = {In response to the influencing factors and technical issues of enterprise operational decision-making risk prediction, a risk prediction system for enterprise operational decision-making is designed based on Artificial Intelligence Generated Content, focusing on risk prediction and control methods. The system utilizes tools and technologies such as large AI models and machine learning to conduct risk assessment model training, decision support model construction, and predictive compliance governance, forming a data source module along with risk identification, analysis, and evaluation modules. Through the training set, empirical risk is calculated, ultimately leading to targeted decision-making regarding enterprise operational risks. System simulation experiments were conducted using MATLAB, yielding a predicted value of -0.4419, which is close to the actual value of -0.4426. The results indicate that the enterprise operational decision-making risk prediction system is feasible.},
booktitle = {Proceedings of the 2024 8th International Conference on Electronic Information Technology and Computer Engineering},
pages = {711–716},
numpages = {6}
}

@inproceedings{10.1145/3617072.3617121,
author = {Zheng, Sarah Ying and Becker, Ingolf},
title = {Phishing to improve detection},
year = {2023},
isbn = {9798400708145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617072.3617121},
doi = {10.1145/3617072.3617121},
abstract = {Phishing e-mail scams continue to threaten organisations around the world. With generative artificial intelligence, conventional phishing detection advice such as looking out for linguistic errors and bad layouts will become obsolete. New approaches to improve people’s ability to detect phishing are essential. We report on promising results from two experiments (total N = 183) that engaging people with an adversarial mindset improves their ability to detect phishing e-mails compared to those who received conventional or no training. Participants who completed conventional training were nearly three times as likely to fall for a simulated phishing attack compared to those who completed the adversarial training, in which they watched a fictitious cybercriminal explain how to devise a targeted phishing e-mail, and then wrote targeted phishing e-mails themselves. Although further research is needed to examine the training’s long-term efficacy with larger sample sizes, the present findings show an encouraging alternative to conventional phishing training approaches.},
booktitle = {Proceedings of the 2023 European Symposium on Usable Security},
pages = {334–343},
numpages = {10},
keywords = {adversarial mindset, cybersecurity training, phishing detection},
location = {Copenhagen, Denmark},
series = {EuroUSEC '23}
}

@article{10.1145/3747356,
author = {Denning, Peter J.},
title = {Artificial Intelligence: Generative AI},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2025},
number = {July},
url = {https://doi.org/10.1145/3747356},
doi = {10.1145/3747356},
abstract = {Large language models (LLMs) are the first neural network machines capable of carrying on conversations with humans. They are trained on billions of words of text scraped from the internet. They generate text responses to text inputs. They have transformed the public awareness of artificial intelligence, bringing on reactions ranging from astonishment and awe to trepidation and horror. They have spurred massive investments in new tools for drafting texts, summarizing conversations, summarizing literature, generating images, coding simple programs, supporting education, and amusing humans. Experience with them has shown them likely to respond with fabrications (called "hallucinations") that severely undermine their trustworthiness and make them unsafe for critical applications. Here, we will examine the limitations of LLMs imposed by their design and function. These are not bugs but are inherent limitations of the technology. The same limitations make it unlikely that LLM machines will ever be capable of performing all human tasks at the skill levels of humans.},
journal = {Ubiquity},
month = jul,
articleno = {3},
numpages = {19}
}

@article{10.1145/3678172,
author = {Storey, Margaret-Anne and Russo, Daniel and Novielli, Nicole and Kobayashi, Takashi and Wang, Dong},
title = {A Disruptive Research Playbook for Studying Disruptive Innovations},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {8},
issn = {1049-331X},
url = {https://doi.org/10.1145/3678172},
doi = {10.1145/3678172},
abstract = {As researchers today, we are witnessing a fundamental change in our technologically-enabled world due to the advent and diffusion of highly disruptive technologies such as generative Artificial Intelligence (AI), Augmented Reality (AR) and Virtual Reality (VR). In particular, software engineering has been profoundly affected by the transformative power of disruptive innovations for decades, with a significant impact of technical advancements on social dynamics due to its socio-technical nature. In this article, we reflect on the importance of formulating and addressing research problems in software engineering through a socio-technical lens, thus ensuring a holistic understanding of the complex phenomena in this field. We propose a research playbook with the aim of providing a guide to formulate compelling and socially relevant research questions and to identify the appropriate research strategies for empirical investigations, with an eye on the long-term implications of technologies or their use. We showcase how to apply the research playbook. Firstly, we show how it can be used retrospectively to reflect on a prior disruptive technology, Stack Overflow, and its impact on software development. Secondly, we show how it can be used to question the impact of two current disruptive technologies: AI and AR/VR. Finally, we introduce a specialized GPT model to support the researcher in framing future investigations. We conclude by discussing the broader implications of adopting the playbook for both researchers and practitioners in software engineering and beyond.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
articleno = {195},
numpages = {29},
keywords = {Socio-technical Integration, Disruptive Innovation Evaluation, Empirical Software Engineering, AI-driven Code Generation, AR/VR Collaboration Tools}
}

@inproceedings{10.1145/3702653.3744330,
author = {Payne, Chandler C. and Hackney, Kai A. and Zangari, Lucas Guarenti and Munoz, Emmanuel and Kalogeras, Sterling R. and S\'{a}nchez-G\'{o}mez, Juan Sebasti\'{a}n and Omojokun, Olufisayo and Feij\'{o}o-Garc\'{\i}a, Pedro Guillermo},
title = {Exploring Community Perceptions and Experiences Towards Academic Dishonesty in Computing Education},
year = {2025},
isbn = {9798400713415},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702653.3744330},
doi = {10.1145/3702653.3744330},
abstract = {This poster reports on the differences in perceptions concerning academic dishonesty and the misuse of resources in college from the perspectives of students, teaching assistants (TAs), and instructors in Computer Science (CS). Dishonesty has been a topic of interest in the CS education community, with efforts addressing how to detect and prevent it [1, 2, 6, 7, 8]. With the presence of generative artificial intelligence (AI) and its increased use in recent years, studying all actors’ perspectives on dishonesty in regard to generative AI becomes critical to promote guidelines and strategies for curricular design in CS [4, 5], aligning those who teach and those who learn towards a common ethical ground. This led us to explore the following research questions with a specific emphasis on artificial intelligence in mind:(1)RQ1: How do students, instructors, and teaching assistants respond to scenarios suggesting academic dishonesty in the CS classroom?(2)RQ2: What reasons do students, instructors, and teaching assistants in CS consider may lead someone toward academic dishonesty in the CS classroom?We surveyed 538 undergraduate students, 21 TAs, and six Computer Science (CS) instructors at a large Southeastern U.S. institution. Students and TAs were part of two undergraduate CS courses. Responses were gathered via an online questionnaire that featured 13 multiple-choice questions on whether the participant thought particular situations fell most closely within “serious cheating,” “trivial cheating,” or “no cheating”–questions adapted from the work by Ozment et al. [3]; one open-ended question on the reasons the participant considered why someone might cheat in the CS classroom; and demographic questions. This poster focuses specifically on participants’ responses to the open-ended question, via a thematic analysis to identify recurring categories (i.e., themes) and assess the affinity of participants’ responses within each theme. Subgroups were participants’ demographics and backgrounds.Our findings suggest that all participants have diverse perspectives. Instructors generally referred to "Grade Pressure" and "Laziness" as the top two reasons behind dishonesty, while TAs and students emphasized "Prerequisite Knowledge" and "Time Management" as the main contributing factors. These findings suggest a dichotomy among actors involved in the learning processes happening in the CS classroom.Our work underscores the need for awareness and support strategies in curricular initiatives within the CS Ed community to help prevent dishonesty and promote student success in their computing disciplines. A clear disconnect between instructor expectations and student perceptions encourages clearer communication in the classroom and is a ripe avenue for further study.},
booktitle = {Proceedings of the 2025 ACM Conference on International Computing Education Research V.2},
pages = {13–14},
numpages = {2},
keywords = {Student Integrity, Computing Education, Community Perceptions},
location = {
},
series = {ICER '25}
}

@article{10.1145/3665333,
author = {von Lucke, J\"{o}rn and Frank, Sander},
title = {A few Thoughts on the Use of ChatGPT, GPT 3.5, GPT-4 and LLMs in Parliaments: Reflecting on the results of experimenting with LLMs in the parliamentarian context},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
url = {https://doi.org/10.1145/3665333},
doi = {10.1145/3665333},
abstract = {Starting in November 2022 with the free provision of ChatGPT, large language models (LLM) are now publicly available. This has significantly increased the number of publications that scope potential changes caused by the application of generative artificial intelligence (AI) in various societal domains. The private use of AI and the economic integration of generative LLMs have increased significantly. However, for parliamentarians and parliamentary professionals, the technology often remains abstract, impacting everyday work only peripherally. Due to the special responsibility of parliaments, governments, and administrations as the organizational instances of society, and through the inherent legitimations by society itself, there is a necessity to examine the implications of the use of generative LLMs within these institutions and traditional structures as well as their influence on political system logic. The article analyzes the responses that the generative LLMs GPT 3.5 and GPT 4 have provided via ChatGPT, based on the same input command (prompt) over different times. The responses help to assess how LLMs can be used in the parliamentary context, to reflect what dangers exist as well as to respond to the question on how a business model of an AI department in parliament might look like. Furthermore, it shall be explored whether there are fluctuations in the quality of the responses and how these should be evaluated against the backdrop of the need for accurate and precise workflows in parliamentary operations. Ultimately, the article aims to provide an answer as to whether the application of ChatGPT together with the LLMs GPT-3.5 and GPT-4 could already deliver this necessary quality and consistency for the parliamentarian working environment today.},
journal = {Digit. Gov.: Res. Pract.},
month = jun,
articleno = {27},
numpages = {21},
keywords = {Large language model, ChatGPT, GPT 3.5, GPT-4, parliament}
}

@inproceedings{10.1145/3723010.3723036,
author = {B\"{o}hm, Karsten},
title = {Towards a Semantic Representation of Framework Recommendations for Curricular Specifications in Higher Education},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723036},
doi = {10.1145/3723010.3723036},
abstract = {Curricular specifications play an important role in the Higher Education sector and the domain of Computer Science and Software Engineering is characterized by a wide range of education programs with a broad range of topic. Therefore, recommendation frameworks play an important role and their usage is beneficial for a unification of education profiles in a systematic way. This  research is contributing to this development by exploring how a recommendation for the domain of Business Informatics in German speaking countries can be improved by formalizing the recommendations in a semantic model that relies on sophisticated European ontologies in the domain like the European Learning Model (ELM) and related data models. It employs Generative Artificial Intelligence Systems to create semantic models in an experimental way and evaluates the resulting model quality. The results show that a formalization using GenAI has a high potential, but currently also shows deficits in the correctness of the resulting models, requiring human oversight during the model creation.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {154–160},
numpages = {7},
keywords = {Business Informatics, Competence Specification, European Learning Model, Higher Education, Learning Framework, Semantic Web},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3706599.3720027,
author = {Schirra, Steven and Volkov, Sasha G and Bentley, Frank},
title = {"It's Something to Polish Your Own Thoughts, Rather than Create Thoughts for You": Understanding Participants' Use of Chatbots and LLMs During Online Research Participation},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720027},
doi = {10.1145/3706599.3720027},
abstract = {There are growing discussions within the research community about how to adapt study design given the widespread availability of Generative Artificial Intelligence (GenAI), including Large Language Models (LLMs). While much prior research has focused on LLM use from a researcher perspective (e.g. detecting and screening for LLM use) we present a complementary study from the perspective of participants who use LLMs during their research participation. In this exploratory interview study with 17 participants, we found a range of LLM use cases, from sourcing studies, to generating or modifying responses, to asking clarification questions about studies. We also explored participants’ ethical considerations, finding that participants considered researchers’ needs for authentic data when setting ethical boundaries. Participants also discussed how attempts to thwart their LLM use have negatively impacted their everyday participant experience. We propose a set of recommendations that researchers can incorporate into their studies to proactively address participant LLM use.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {20},
numpages = {6},
keywords = {participant experience, LLMs, GenAI, data quality, participant ethics, chatbots},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3701047.3701074,
author = {Wei, Xueling},
title = {KPI-based enterprise management decision-making system Artificial Intelligence Generated Content modeling},
year = {2025},
isbn = {9798400711688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701047.3701074},
doi = {10.1145/3701047.3701074},
abstract = {In terms of business decision-making, there are still issues to be resolved regarding the intelligence of key performance indicators. To address this technical problem, from the perspective of Artificial Intelligence Generated Content, modeling methods such as support vector machines, random search, and machine learning for key performance indicators (KPI) in business decision-making systems have been proposed. The system integrates with large language models, driving the generative efficiency and accuracy of KPI data cleaning, feature extraction, and model optimization training. Using MATLAB to conduct predictive simulation experiments on the integrated system, compared to general information systems for KPIs that do not utilize large language models or Artificial Intelligence Generated Content, the volume of reference data for business decision-making based on large language models increased by 93.61 times, and decision-making efficiency improved by 36.59\%, indicating that the Artificial Intelligence Generated Content modeling scheme for business decision-making systems based on operational KPIs is feasible.},
booktitle = {Proceedings of the 2024 2nd International Conference on Communication Networks and Machine Learning},
pages = {147–151},
numpages = {5},
keywords = {Artificial Intelligence Generated Content, KPI, business decision-making},
location = {
},
series = {CNML '24}
}

@inproceedings{10.1145/3702386.3702400,
author = {Wang, Xianchuang and Fang, Haiguang and Shu, Lili and Li, Zeyu},
title = {Creative Accessibility in the Era of Artificial Intelligence and Its Applied Technology Research},
year = {2025},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702386.3702400},
doi = {10.1145/3702386.3702400},
abstract = {In the era of artificial intelligence, an AI dual-teacher classroom environment constructed using technologies such as knowledge graphs, large models, and educational robots will facilitate students in achieving the cognitive goals related to creativity in Bloom's Taxonomy of educational objectives. The use of artificial intelligence technology, especially large model technology, can promote students' inclination towards creativity and creative thinking. However, it is essential to guide students to engage in deep thinking before designing prompts based on their ideas, thereby fostering their creative and critical thinking through human-machine collaboration. This study takes a certain experimental school as a case to explore the effectiveness of creative accessibility in the AI dual-teacher classroom environment and its application technology in primary and secondary schools.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
pages = {50–56},
numpages = {7},
keywords = {AI Dual-Teacher Classroom, Artificial Intelligence Education, Creative Accessibility, Educational Prompt Engineering, Large Models},
location = {
},
series = {ICAITE '24}
}

@inproceedings{10.1145/3706599.3720227,
author = {Scarlatos, Alexander and Wu, Yusong and Simon, Ian and Roberts, Adam and Cooijmans, Tim and Jaques, Natasha and Tarakajian, Cassie and Huang, Anna},
title = {ReaLJam: Real-Time Human-AI Music Jamming with Reinforcement Learning-Tuned Transformers},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720227},
doi = {10.1145/3706599.3720227},
abstract = {Recent advances in generative artificial intelligence (AI) have created models capable of high-quality musical content generation. However, little consideration is given to how to use these models for real-time or cooperative jamming musical applications because of crucial required features: low latency, the ability to communicate planned actions, and the ability to adapt to user input in real-time. To support these needs, we introduce ReaLJam, an interface and protocol for live musical jamming sessions between a human and a Transformer-based AI agent trained with reinforcement learning. We enable real-time interactions using the concept of anticipation, where the agent continually predicts how the performance will unfold and visually conveys its plan to the user. We conduct a user study where experienced musicians jam in real-time with the agent through ReaLJam. Our results demonstrate that ReaLJam enables enjoyable and musically interesting sessions, and we uncover important takeaways for future work.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {453},
numpages = {9},
keywords = {Anticipation, Human-AI collaboration, Jamming, Music generation, Synchronization},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706598.3713532,
author = {Chung, Joon Gi and Hong, Soongi and Choi, Junho and Oh, Changhoon},
title = {Understanding the Dynamics in Deploying AI-Based Content Creation Support Tools in Broadcasting Systems - Benefits, Challenges, and Directions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713532},
doi = {10.1145/3706598.3713532},
abstract = {Recent advancements in generative artificial intelligence (AI) are profoundly impacting the broadcasting industry. While generative AI shows promise in supporting broadcasting professionals, its practical workflow integration remains underexplored. In this study, we conducted a user-focused investigation to understand how AI-based content creation support tools are being adopted and perceived in South Korean broadcasting stations. We used the AI Editing Assistant, an AI-powered post-production support tool, as a research probe. Through in-depth interviews with 37 diverse participants—including directors, editors, producers, developers, and executives—we discovered that generative AI significantly enhances production efficiency and unlocks new creative possibilities. However, we identified challenges such as lack of user-centered approach, demanding nature of broadcasting workflows, and professionals’ low trust in AI technologies hinders widespread adoption. Based on our findings, we propose implications, considerations, and guidelines for integrating generative AI into broadcasting practices, emphasizing improved multi-stakeholder communication and collaboration for effective and sustainable AI adoption.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {27},
numpages = {28},
keywords = {AI-based content creation support tools, Human-AI collaboration, Broadcasting systems, User-centered approach, Domain-specific AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3698322.3698340,
author = {Noble, James and Weir, Charles},
title = {The Faultless Way of Programming},
year = {2024},
isbn = {9798400716836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698322.3698340},
doi = {10.1145/3698322.3698340},
abstract = {There is one faultless way of programming. It uses computer intelligence to validate computer code: formal verification. Yet for developers this faultless approach has remained alien, incomprehensible, and many miss out on its proven benefits. This set of patterns introduces Dafny to developers. Dafny provides a powerful way to incorporate formal verification into software that is integrated with languages like Java and C#, generating code that is provably free from defects and problems. The patterns range from the Dafny design philosophy to concepts like ghost variables and implementation details such as the use of generative artificial intelligence. By offering an accessible approach to a difficult subject, they support developers in producing faultless code.},
booktitle = {Proceedings of the 29th European Conference on Pattern Languages of Programs, People, and Practices},
articleno = {32},
numpages = {7},
keywords = {Patterns, Dafny, Correctness, Verification},
location = {
},
series = {EuroPLoP '24}
}

@inproceedings{10.1145/3613904.3642574,
author = {Young, Jordyn and Jawara, Laala M and Nguyen, Diep N and Daly, Brian and Huh-Yoo, Jina and Razi, Afsaneh},
title = {The Role of AI in Peer Support for Young People: A Study of Preferences for Human- and AI-Generated Responses},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642574},
doi = {10.1145/3613904.3642574},
abstract = {Generative Artificial Intelligence (AI) is integrated into everyday technology, including news, education, and social media. AI has further pervaded private conversations as conversational partners, auto-completion, and response suggestions. As social media becomes young people’s main method of peer support exchange, we need to understand when and how AI can facilitate and assist in such exchanges in a beneficial, safe, and socially appropriate way. We asked 622 young people to complete an online survey and evaluate blinded human- and AI-generated responses to help-seeking messages. We found that participants preferred the AI-generated response to situations about relationships, self-expression, and physical health. However, when addressing a sensitive topic, like suicidal thoughts, young people preferred the human response. We also discuss the role of training in online peer support exchange and its implications for supporting young people’s well-being. Disclaimer: This paper includes sensitive topics, including suicide ideation. Reader discretion is advised.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1006},
numpages = {18},
keywords = {AI-Mediated Communication (AI-MC), Artificial Intelligence (AI), Chatbot, Human-AI Interaction (HAII), LLM, Mental Health, Peer Support, Social Support, Youth},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3702138.3702145,
author = {Blancaflor, Eric B. and Abaleta, Raphael M. and Achacoso, Luke Martin D.L. and Amper, Alden Christian C. and Ampiloquio, Pfrancis Isaiah R.},
title = {Emerging Threat: The Use of AI Voice Cloning Software and Services to Deceive Victims Through Phone Conversations and its Potential Effects on the Filipino Population},
year = {2025},
isbn = {9798400717543},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702138.3702145},
doi = {10.1145/3702138.3702145},
abstract = {Generative Artificial Intelligence (AI) tools have become increasingly advanced and accessible via the Internet. These advancements and upgraded accessibility of access have resulted in the usage of generative AI in phishing, which has increased the incidences&nbsp;of these attacks. The researchers explore AI voice phishing, or vishing, and its possible implications on the Filipino community by analyzing and reviewing existing literature on AI voice cloning and its application in vishing schemes. The review covers the definition of vishing and AI voice cloning, the methods malicious actors use to clone voices, the Philippines' cybersecurity posture and its current laws on AI vishing, real-life examples of AI vishing, how to protect against it, and the future of AI vishing, as well as the future direction of the study. The researchers ended the study by demanding and advocating additional research on AI detection and recognition, as well as the establishment and stronger implementation of developing legislation in the Philippines and other nations that prohibit the use of generative AI for illegal purposes.},
booktitle = {Proceeding of the 2024 5th Asia Service Sciences and Software Engineering Conference},
pages = {137–146},
numpages = {10},
keywords = {AI Vishing, AI Voice Cloning, Artificial Intelligence, Cybersecurity, Generative AI, Philippines, Voice Phishing},
location = {
},
series = {ASSE '24}
}

@inproceedings{10.1145/3613904.3642191,
author = {Kotturi, Yasmine and Anderson, Angel and Ford, Glenn and Skirpan, Michael and Bigham, Jeffrey P},
title = {Deconstructing the Veneer of Simplicity: Co-Designing Introductory Generative AI Workshops with Local Entrepreneurs},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642191},
doi = {10.1145/3613904.3642191},
abstract = {Generative AI platforms and features are permeating many aspects of work. Entrepreneurs from lean economies in particular are well positioned to outsource tasks to generative AI given limited resources. In this paper, we work to address a growing disparity in use of these technologies by building on a four-year partnership with a local entrepreneurial hub dedicated to equity in tech and entrepreneurship. Together, we co-designed an interactive workshops series aimed to onboard local entrepreneurs to generative AI platforms. Alongside four community-driven and iterative workshops with entrepreneurs across five months, we conducted interviews with 15 local entrepreneurs and community providers. We detail the importance of communal and supportive exposure to generative AI tools for local entrepreneurs, scaffolding actionable use (and supporting non-use), demystifying generative AI technologies by emphasizing entrepreneurial power, while simultaneously deconstructing the veneer of simplicity to address the many operational skills needed for successful application.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1014},
numpages = {16},
keywords = {community-based research, entrepreneurship, generative artificial intelligence},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3664476.3670943,
author = {Zhao, Hanning and Silverajan, Bilhanan},
title = {Evaluating Cyber Security Dashboards for Smart Cities and Buildings: Enhancing User Modeling with LLMs},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3670943},
doi = {10.1145/3664476.3670943},
abstract = {Designing effective cybersecurity visualization has become a crucial component of cyber defense strategies in many domains and industrial environments. Human behaviour, modeling and input are major aspects of designing visualization systems. Yet, the task of evaluating these developed visualization systems is both time-consuming and challenging, and it is often prone to cases where user evaluation is limited owing to a lack of different stakeholders and end users during the design process. Recognizing the potential of advanced Generative Artificial Intelligence and Large Language Models (LLMs), our study aims to explore their capabilities in evaluating web-based security visualization tools and dashboards, particularly in the context of smart cities and buildings. We study and compare the feasibility of using various LLMs available today, for conducting usability testing, serving as an additional resource given the limited availability of human participants. In particular, we focus on three different LLMs: Bing Chat, ChatGPT-4 and ChatGPT-4o. While each had its strengths and drawbacks, our findings revealed that the results obtained had a strong correlation with human test subjects. LLMs can be a valuable aid during evaluation, by offering in-depth insights and evaluations, tailored to the specific requirements of smart buildings, cities and automation cybersecurity. Moreover, our research and findings also reveal that LLMs can similarly be used for the evaluation of a wide range of other visual systems for industrial environments.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {47},
numpages = {10},
keywords = {LLM, Security Visualization, Smart City, Usability Testing},
location = {Vienna, Austria},
series = {ARES '24}
}

@article{10.1145/3593230,
author = {Brie, Paul and Burny, Nicolas and Slu\"{y}ters, Arthur and Vanderdonckt, Jean},
title = {Evaluating a Large Language Model on Searching for GUI Layouts},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {EICS},
url = {https://doi.org/10.1145/3593230},
doi = {10.1145/3593230},
abstract = {The field of generative artificial intelligence has seen significant advancements in recent years with the advent of large language models, which have shown impressive results in software engineering tasks but not yet in engineering user interfaces. Thus, we raise a specific research question: would an LLM-based system be able to search for relevant GUI layouts? To address this question, we conducted a controlled study evaluating how Instigator, an LLM-based system for searching GUI layouts of web pages by generative pre-trained training, would return GUI layouts that are relevant to a given instruction and what would be the user experience of (N =34) practitioners interacting with Instigator. Our results identify a very high similarity and a moderate correlation between the rankings of the GUI layouts generated by Instigator and the rankings of the practitioners with respect to their relevance to a given design instruction. We highlight the results obtained through thirteen UEQ+ scales that characterize the user experience of the practitioner with Instigator, which we use to discuss perspectives for improving such future tools.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {178},
numpages = {37},
keywords = {generative pre-training, gui design, gui layout, large language model, web pages}
}

@inproceedings{10.1145/3746709.3746934,
author = {Guo, Yi},
title = {Research and Design of a Chinese-French Consecutive Interpreting Assessment System Based on Artificial Intelligence Technology},
year = {2025},
isbn = {9798400713163},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746709.3746934},
doi = {10.1145/3746709.3746934},
abstract = {In today's era, artificial intelligence technology is developing rapidly. Under such a background, translation quality evaluation system relying on deep learning has gradually become a hot research topic in the field of translation research. Traditional manual evaluation methods have their own shortcomings, which are relatively subjective and low evaluation efficiency. The existing automatic assessment indicators such as BLEU and METEOR, which have deficiencies in cultural adaptability and logical coherence, cannot meet the complex needs of Sino-French alternating interpretation. This evaluation system combines multi-modal analysis with cross-language and cultural feature database. Based on the improvement of Transformer model architecture, a hierarchical evaluation mechanism is designed, which significantly improves the objectivity of evaluation and makes the evaluation more comprehensive. The experimental results show that this system has more advantages than the traditional method in the three core indicators of accuracy, fluency and cultural adaptability. The Pearson correlation coefficient between the score of this system and the human score reaches 0.87, which proves that it is effective in cross-language and cultural adaptation scenarios. This study provides an extensible technical framework for the assessment of translation quality, and provides innovative solutions to the challenges of linguistic structural differences and cultural metaphor translation.},
booktitle = {Proceedings of the 2025 6th International Conference on Computer Information and Big Data Applications},
pages = {1330–1335},
numpages = {6},
keywords = {Artificial Intelligence, Assessment System, Chinese-French Consecutive Interpreting, Cultural Adaptability, Deep Learning},
location = {
},
series = {CIBDA '25}
}

@inproceedings{10.1145/3702879.3702888,
author = {Zheng, Yubao and Xue, Shituan and Long, Anlin and Jia, Fengjuan and Guo, Huazhan and Ge, Jingwei},
title = {Research and Development Practice of Intelligent Reservoir Dynamic Analysis in Qinghai Oilfield},
year = {2024},
isbn = {9798400710148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702879.3702888},
doi = {10.1145/3702879.3702888},
abstract = {With the rapid development of generative artificial intelligence, data-driven intelligent computation and analysis methods have been massively applied in the field of petroleum exploration and development. Qinghai Oilfield has accumulated a large amount of reservoir dynamic analysis data in long-term exploration and development, but the comprehensive use of data and intelligent application is not deep enough, which seriously affects the efficiency of reservoir dynamic analysis. In order to improve the efficiency of reservoir dynamics analysis and decision-making, an intelligent reservoir dynamics analysis platform based on a cloud platform and artificial intelligence analysis methods was established in Qinghai Oilfield. The intelligent reservoir dynamic analysis platform integrates heterogeneous data from multiple sources, establishes scenario-based reservoir dynamic analysis topics, forms a four-level dynamic analysis structure of well-well group-layer-reservoir, and implements functions such as reservoir evaluation indicators calculation, reservoir dynamic early warning analysis, reservoir development parameters optimization, and reservoir development evaluation. Based on this platform, Qinghai Oilfield has achieved the intelligent practice of reservoir dynamic analysis with integrated geological engineering technology. Through the intelligent practice of reservoir dynamic analysis, Qinghai Oilfield has greatly improved the efficiency of reservoir development and production, and the digital and intelligent development has been promoted.},
booktitle = {Proceedings of the 2024 2nd International Conference on Internet of Things and Cloud Computing Technology},
pages = {47–53},
numpages = {7},
keywords = {artificial intelligence, data-driven, intelligent oilfield, reservoir dynamics analysis},
location = {
},
series = {IoTCCT '24}
}

@article{10.1145/3718102.3690392,
author = {Attri, Raman K.},
title = {Modeling Consumer GenAI for Enterprise L&amp;D Applications: Demonstration of typical use cases},
year = {2025},
issue_date = {02-01-2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2025},
number = {2},
url = {https://doi.org/10.1145/3718102.3690392},
doi = {10.1145/3718102.3690392},
abstract = {This article explores the application of generative artificial intelligence (GenAI) in learning and development (L&amp;D) processes, specifically for enterprise training. The author discusses how L&amp;D practitioners can use GenAI tools to drive a complete instructional design process, including training content development and the creation of typical L&amp;D deliverables such as training documentation development, training need analysis, course outline, and lesson plan generation as well as training material development such as presentation slides, case scenarios, assessments, and self-learning content. The article also details how to leverage the power of GenAI tools as a trainer, assessor, and expert mentor. The author also shares a nine-step approach for L&amp;D practitioners to achieve potential time-saving benefits using GenAI to create diverse training content. However, he cautions L&amp;D leaders to consider broader implications, such as technology evolution, security and intellectual property risks, job impacts, and the need for careful implementation to ensure information and IP security.},
journal = {ELearn},
month = feb,
articleno = {3}
}

@inproceedings{10.1145/3640794.3665538,
author = {S\'{a}nchez Cuadrado, Jes\'{u}s and P\'{e}rez-Soler, Sara and Guerra, Esther and De Lara, Juan},
title = {Automating the Development of Task-oriented LLM-based Chatbots},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640794.3665538},
doi = {10.1145/3640794.3665538},
abstract = {Task-oriented chatbots are increasingly used to access all sorts of services – like booking a flight, or setting a medical appointment – through natural language conversation. There are many technologies for implementing task-oriented chatbots, including Dialogflow, Watson, and Rasa. They rely on an explicit definition of the user intents, conversation flows, and chatbot outputs, which is costly to specify, and sometimes results in suboptimal user experiences and artificial conversations with limited diversity of chatbot responses. Recently, the advances in generative artificial intelligence fostered by Large Language Models (LLMs) have enabled a new range of open-domain chatbots, like ChatGPT, able to converse fluently on any topic. However, they are general-purpose, and therefore not directly usable to solve specialised tasks reliably. In this paper, we study the power of LLMs to build task-oriented chatbots, resulting in lighter specifications – no intent definition required – and more natural conversations than in intent-based approaches. To this end, we propose a lightweight domain-specific language based on YAML to specify chatbots using modules of different types (e.g., menus, question-answering, data gathering). These specifications are compiled into structured LLM prompts that use the ReAct framework to inform our runtime how to interpret the user input and coordinate the tasks that the chatbot must perform. The paper presents the design and realisation of our framework, and an assessment that encodes a set of existing intent-based chatbots using our approach, showing its benefits in terms of specification size, conversation flexibility and output diversity.},
booktitle = {Proceedings of the 6th ACM Conference on Conversational User Interfaces},
articleno = {11},
numpages = {10},
keywords = {Domain-Specific Languages, Large Language Models, Task-oriented Chatbots},
location = {Luxembourg, Luxembourg},
series = {CUI '24}
}

@article{10.1145/3645057.3645059,
author = {Nithithanatchinnapat, Benyawarath and Maurer, Joshua and Deng, Xuefei (Nancy) and Joshi, K. D.},
title = {Future Business Workforce: Crafting a Generative AI-Centric Curriculum Today for Tomorrow's Business Education},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {1},
issn = {0095-0033},
url = {https://doi.org/10.1145/3645057.3645059},
doi = {10.1145/3645057.3645059},
abstract = {In an era where generative AI is reshaping the landscape of business and technology, this editorial addresses the critical imperative for transformative reform in business education. It emphasizes the dual nature of generative AI as both a formidable disruptor and a catalyst for innovation, necessitating a shift in how we educate the future workforce. The editorial calls for a proactive and comprehensive reevaluation of current educational models, advocating for an integration of AI literacy and ethical considerations into the core of business curricula. We aim to galvanize academia into action, advocating for an educational evolution that not only acknowledges the challenges posed by AI but also harnesses its potential to enrich and advance business education in preparing students for an AI-driven future.},
journal = {SIGMIS Database},
month = feb,
pages = {6–11},
numpages = {6},
keywords = {business education, changing nature of work, chatgpt, curriculum, future workforce., generative ai, generative artificial intelligence, information systems research}
}

@inproceedings{10.1145/3641555.3704765,
author = {Liu, Rongxin and Malan, David J. and Zhukovets, Yuliia and Lloyd, Doug},
title = {Teaching with AI (GPT)},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704765},
doi = {10.1145/3641555.3704765},
abstract = {Teaching computer science at scale can be challenging. From our experience in CS50, Harvard University's introductory course, we've seen firsthand the impactful role that generative artificial intelligence can play in education. Recognizing its potential and stakes, we integrated OpenAI's GPT into our own teaching methodology. The goal was to emulate a 1:1 teacher-to-student ratio, incorporating "pedagogical guardrails" to maintain instructional integrity. The result was a personalized, AI-powered bot in the form of a friendly rubber duck aimed at delivering instructional responses and troubleshooting without giving outright solutions. In this tutorial, we share our journey and offer insights into responsibly harnessing AI in educational settings. Participants will gain hands-on experience working with GPT through OpenAI's latest APIs, understanding and crafting prompts, answering questions using embedding-based search, and finally, collaboratively building their own AI chatbot. Ultimately, we'll not only share lessons learned from our own approach but also equip educators hands-on with the knowledge and tools with which they, too, can implement these technologies in their unique teaching environments.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1773},
numpages = {1},
keywords = {AI, AI ethics, ChatGPT, GPT, generative AI, programming, prompt, prompt engineering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inbook{10.1145/3713043.3731513,
author = {Mar\c{c}al, Carolina and Baptista, Ana Carolina and Nicolau, Hugo and Campos, Pedro F. and Pires, Ana Cristina},
title = {Creat’AI: Using Tangible Storytelling to Teach AI to Children},
year = {2025},
isbn = {9798400714733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713043.3731513},
abstract = {The widespread presence of Artificial Intelligence (AI) and the growing use of AI agents raise concerns about potential biases, privacy risks, and exposure to inappropriate content, underscoring the need to educate children about AI. To address this issue, we organized a collaborative workshop with four experts to brainstorm activities to teach AI to children. As a result, we developed Creat’AI — a GenAI-powered tangible prototype that co-creates original stories with children. We evaluated Creat’AI in a school with 17 children from the 1st grade. Our preliminary findings show that children were engaged in the activities and understood AI’s capability to generate original content, and changed their previous perception of AI and recognized that AI-generated content can be inaccurate. These results highlight the prototype’s potential in promoting AI literacy, contributing to the responsible and informed use of AI by young children.},
booktitle = {Proceedings of the 24th Interaction Design and Children},
pages = {955–960},
numpages = {6}
}

@article{10.1145/3769090,
author = {Wang, Yahui and Guizani, Mohsen and Hossain, M. Shamim},
title = {Artificial Intelligence for Virtual Reality: State of the Art, Challenges, and Future Perspectives},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3769090},
doi = {10.1145/3769090},
abstract = {Artificial Intelligence (AI) has wide applications in virtual reality (VR), especially in analyzing its implementation progress, existing limitations, and future development paths. This study finds that AI's main contributions to VR are in four key areas: creating intelligent virtual characters, advancing education and training, providing medical assistance, and generating dynamic scenes. This interdisciplinary convergence also brings significant opportunities, particularly in sectors such as education, healthcare, gaming, and corporate training. Additionally, the study discusses technical challenges related to computational costs, real-time feedback, user privacy, and algorithmic ethics. Critical challenges persist in data processing bottlenecks, privacy protection issues, and user adaptation. While AI enhances VR's intelligence and interactivity, breakthroughs are still needed in cross-modal integration, privacy, security, and user experience. Future advancements in deep learning and reinforcement learning may unlock unlimited potential for AI-driven VR in personalized adaptation and immersive interaction. Therefore, this study provides a comprehensive analysis of AI–VR integration, providing valuable insights for academic research and technological development.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = sep,
keywords = {Artificial Intelligence, Virtual Reality, Intelligent Interaction, Digital Twins, User Experience, Privacy Security}
}

@inproceedings{10.1145/3701571.3701572,
author = {Rahman, Parinda and Adaji, Ifeoma},
title = {Ethics in Persuasive Technologies: A Systematic Literature Review},
year = {2024},
isbn = {9798400712838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701571.3701572},
doi = {10.1145/3701571.3701572},
abstract = {Persuasive technologies, which are intended to change users’ attitudes or behaviors and encourage specific actions, are widely applied across various domains. However, the fine line between persuasion and coercion raises significant ethical concerns, which current literature only superficially addresses. This paper aims to deepen the understanding of factors influencing the ethical perception of persuasive technologies through a systematic literature review of 17 journal articles. The selected studies were analyzed using content analysis to identify key ethical factors. The findings indicate that factors such as autonomy, consent, data privacy, transparency, and addictive design strategies significantly influence users’ ethical perceptions across multiple application domains. Generative artificial intelligence (AI) technologies or AI agents, particularly applications like argumentative chatbots and storytelling robots, exhibit the highest number of ethical considerations. The study also notes thematic overlaps among many ethical factors, with the context and use case impacting ethical perceptions. Based on these results, this paper offers design recommendations and suggestions for the design of ethical persuasive technology applications.},
booktitle = {Proceedings of the International Conference on Mobile and Ubiquitous Multimedia},
pages = {106–118},
numpages = {13},
keywords = {ethics, persuasion, mobile applications, technologies},
location = {
},
series = {MUM '24}
}

@inproceedings{10.1145/3675585.3675587,
author = {Angeles, Chito Naorbe and Samson, Brylle Dimaano and Mama, Bai Rafsan Zahna Ibad and Luriaga, Ronnie Lucero and Delizo, John Pierre Demata and Ching, Michelle Renee Domingo},
title = {Students'perception of the use of AI Detector System by faculty members in determining the originality of submitted academic requirements},
year = {2024},
isbn = {9798400717659},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675585.3675587},
doi = {10.1145/3675585.3675587},
abstract = {Recent studies revealed an overwhelming concern about the misuse of generative Artificial Intelligence (AI) tools by students in completing academic requirements. The detection of AI-generated content using the naked eye was perceived to be difficult, hence the need for more accurate, reliable, and effective detection methods. As a countermeasure, educators are turning to AI content detectors and plagiarism checkers to ascertain the originality of submitted school requirements, raising concerns from students regarding the accuracy and reliability of these tools and the ethical implications and negative consequences of misclassification of genuinely original works as machine-generated outputs. By employing a holistic case study approach, the authors attempted to determine the perceptions of selected university students on the use of AI detection systems by faculty members in checking the originality and novelty of their academic outputs. Through the lenses of various normative ethical theories, the authors also analyzed the ethical issues and concerns raised by selected students to better understand their sentiments and the factors they believe could influence the faculty members' intention to adopt this emerging technology. The results of the study revealed that students have mixed attitudes and perceptions toward the faculty's intention to use AI detectors. While students perceived it as a means to encourage independent learning and critical thinking, they also expressed valid concerns regarding fairness, accuracy, and reliability, the impact on teacher-student trust, and the responsible use of the technology, among others. The participants also acknowledged the influence of other faculty members and the students' increasing dependence on AI as possible enablers of technology adoption while technological limitations, the teachers’ lack of technological skills, and age as perceived barriers. From an ethical view, the findings of the study highlighted the importance of transparency, fairness, privacy, and the need for a policy to regulate AI use.},
booktitle = {Proceedings of the 2024 8th International Conference on E-Commerce, E-Business, and E-Government},
pages = {56–61},
numpages = {6},
keywords = {AI Detectors, Ethical Theories, Generative AI, TPB},
location = {Ajman, United Arab Emirates},
series = {ICEEG '24}
}

@inproceedings{10.1145/3727166.3727191,
author = {Menezes, Veena Priscilla and Chowdhury, Mohammad Jabed Morshed and Mahmood, Abdun},
title = {An Agentic Framework for Compliant, Ethical and Trustworthy GenAI Applications in Healthcare},
year = {2025},
isbn = {9798400715075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3727166.3727191},
doi = {10.1145/3727166.3727191},
abstract = {Recent progress in generative artificial intelligence (GenAI) has yielded significant advancements in healthcare, affecting radiology, medical imaging, drug development, patient diagnostics, and supply chain optimisation. These innovations promise more improved diagnoses and time-saving cost-effectiveness. However, GenAI’s rapid implementation poses significant challenges for meeting regulatory, ethical, and trustworthiness standards. These challenges include data privacy issues, reproducibility concerns, algorithmic bias in training data causing disparities in outcomes, and a lack of transparency and explainability. Unresolved, these issues could negatively affect the public’s confidence in and perception of GenAI systems. Addressing these challenges, international AI governance frameworks, including the EU AI Act and WHO guidelines, prioritize regulatory adherence, trustworthiness, and the explainability of healthcare AI systems. While such frameworks have expanded, a deficiency remains in translating policy into effective compliance mechanisms. We propose a Compliance Agentic Model (CAM) framework to help organizations comply with GenAI and machine learning (ML)-based solutions. The CAM framework establishes trustworthiness in GenAI applications used in healthcare, ensuring alignment with organizational values and ethical standards to enhance accountability and regulatory adherence.},
booktitle = {Proceedings of the 2025 Australasian Computer Science Week},
pages = {48–54},
numpages = {7},
keywords = {GenAI, Healthcare, Agentic AI, Compliance},
location = {
},
series = {ACSW '25}
}

@inproceedings{10.5555/3721488.3721721,
author = {Rivadeneira, Franco and Carcausto, Daniela and Ore, Clara and Saga, Gabriela and Vilca, Macarena and Arroyo, Dante},
title = {AI-Driven Design of a Robotic Companion with Feline-Inspired Behaviors for Stress Relief},
year = {2025},
publisher = {IEEE Press},
abstract = {The rising levels of stress and anxiety among university students have become increasingly alarming, largely driven by academic pressures, social expectations, and the transition to adulthood. These challenges often result in a decline in mental well-being, necessitating innovative solutions to help ease the burden. This paper presents the design and development process of Purry, a social robot inspired by cat behaviors, created to provide stress relief for university students. Purry was designed to offer emotional comfort in a unique way, harnessing the calming effects of pet-like interactions. The design process focused on achieving both aesthetic appeal and functional efficiency, combining modern and traditional technologies such as generative artificial intelligence and low-cost materials, following the double diamond methodology. The robot mimics feline behaviors like kneading and purring, exploring both active and passive tactile interactions, which have been shown to reduce stress through sensory stimulation. Iterative development cycles, guided by user feedback, led to significant advancements in balancing form and function. The final result is a robotic experience that combines emotional support with innovative design, offering a product that not only addresses students' mental health needs but also fosters an engaging and comforting presence in their environment.},
booktitle = {Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1568–1572},
numpages = {5},
keywords = {active touch, design process, robot-human interaction},
location = {Melbourne, Australia},
series = {HRI '25}
}

@inproceedings{10.1145/3604237.3626838,
author = {Yun, Jiseon and Sohn, Jae Eui and Kyeong, Sunghyon},
title = {Fine-Tuning Pretrained Language Models to Enhance Dialogue Summarization in Customer Service Centers},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626838},
doi = {10.1145/3604237.3626838},
abstract = {The application of pretrained language models in real-world business domains has gained significant attention. However, research on the practical use of generative artificial intelligence (AI) to address real-world downstream tasks is limited. This study aims to enhance the routine tasks of customer service (CS) representatives, particularly in the finance domain, by applying a fine-tuning method to dialogue summarization in CS centers. KakaoBank handles an average of 15,000 CS calls daily. By employing a fine-tuning method using real-world CS dialogue data, we can reduce the time required to summarize CS dialogues and standardize summarization skills. To ensure effective dialogue summarization in the finance domain, pretrained language models should acquire additional knowledge and skills, such as specific knowledge of financial products, problem-solving abilities, and the capacity to handle emotionally charged customers. In this study, we developed a reference fine-tuned model using Polyglot-Ko (5.8B) as the baseline PLM and a dataset containing a wide range of zero-shot instructions and partially containing summarization instructions. We compared this reference model with another model fine-tuned using KakaoBank’s CS dialogues and summarization data as the instruct dataset. The results demonstrated that the fine-tuned model based on KakaoBank’s internal datasets outperformed the reference model, showing a 199\% and 12\% improvement in ROUGE-L and RDASS, respectively. This study emphasizes the significance of task-specific fine-tuning using appropriate instruct datasets for effective performance in specific downstream tasks. Considering its practical use, we suggest that fine-tuning using real-world instruct datasets is a powerful and cost-effective technique for developing generative AI in the business domain.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {365–373},
numpages = {9},
keywords = {Korean language model, dialogue summarization, fine-tuning, instruct tuning},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@inbook{10.1145/3757749.3757836,
author = {Yuan, Xinwei and Han, Rui},
title = {A Bibliometric and Visualization Analysis of Generative AI Research in China: Based on Literature from CNKI Database},
year = {2025},
isbn = {9798400713347},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3757749.3757836},
abstract = {In recent years, generative AI (GenAI) has attracted a wide range of attention from numerous researchers in China. To identify research hotspots and trends in the field of GenAI in China, this study conducts the bibliometric and visualization analysis of published studies on GenAI based on CNKI (China National Knowledge Infrastructure) Database. A total of 1094 GenAI-related articles were obtained from the CNKI database. The CiteSpace 6.3.R1 was used to perform the bibliometric and visualization analysis. Through co-words analysis and cluster analysis of keywords, the research topics and hotspots of GenAI could be summarized into three aspects, namely: Large Language Models (LLMs), the application of GenAI in some fields such as education, press \&amp; media, library \&amp; information science, medicine, finance, law, digital government, metaverse etc., and the challenges brought about by GenAI. Through timeline visualization analysis of keywords, the research trends of GenAI were discussed. The results provide a scientific reference for the research status and trends of GenAI in China.},
booktitle = {Proceedings of the 2025 2nd International Conference on Computer and Multimedia Technology},
pages = {517–524},
numpages = {8}
}

@inproceedings{10.1145/3643834.3661515,
author = {Dangol, Aayushi and Newman, Michele and Wolfe, Robert and Lee, Jin Ha and Kientz, Julie A. and Yip, Jason and Pitt, Caroline},
title = {Mediating Culture: Cultivating Socio-cultural Understanding of AI in Children through Participatory Design},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661515},
doi = {10.1145/3643834.3661515},
abstract = {The surge in access to and awareness of Generative Artificial Intelligence (GenAI) such as ChatGPT has sparked discussion over the necessary technological literacies and competencies needed to effectively engage with these systems. In this context, we explore AI as a tool that mediates cultural understanding and remediates human values – that are often influenced by biases and inequities. Using participatory design for learning with a group of 13 children (ages 8-13), we engaged in five co-design sessions featuring different modalities for socio-cultural approaches to AI literacy. We found that children were more aware of the cultural mediation aspect of AI when the content of the interaction aligned with their cultural background and context. This underscored the significance of aligning the representation of culture in these GenAI systems with people’s socio-cultural ecosystems in modern technological literacies. We conclude with design principles for a more critical and holistic approach to AI literacy.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {1805–1822},
numpages = {18},
keywords = {AI Literacy, Cultural mediation, Generative AI, Participatory design},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3702359.3702365,
author = {Mayana, Ranti Fauza and Yudhya, Thomas Budhyawan and Santika, Tisni and Ramli, Ahmad M. and Suseno, Sigid.},
title = {Economic \&amp; Moral Right for Artificial Intelligence Generated Works: Perspective from Indonesia Copyright Law},
year = {2025},
isbn = {9798400710780},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702359.3702365},
doi = {10.1145/3702359.3702365},
abstract = {The basic purpose of copyright is to protect economic and moral rights. Economic rights allow the rights owners to derive financial rewards from monetizing their works. In contrast, moral rights allow the creators to be acknowledged and to take certain actions to preserve and protect the integrity of their works. Both rights are conventionally granted to human and legal entities. However, the massive advancement of AI challenges the essential presumption that technology is merely a device in the hands of humans in the creation process of Work. This paper examines several legal issues and problems concerning the economic and moral rights of AI-generated works using the juridical normative approach from the perspective of Indonesian Copyright Law. The result shows that the framework of Indonesia's copyright law is based on the principle of human authorship, therefore, moral rights can only be granted to human(s) and economic rights can only be granted to legal subjects acknowledged by Indonesian Law: human and legal entity. Although the authorship and ownership of AI for copyrighted work is contentious under Indonesian Laws, the limited legal personality of AI could potentially artifice as the preventive measures on several problems concerning legal standing by enabling legal subject (human or legal entity) to act behalf of AI to exercise their rights and obligation both based on regulative approach and procedural approach.},
booktitle = {Proceedings of the 2024 5th International Artificial Intelligence and Blockchain Conference},
pages = {39–43},
numpages = {5},
keywords = {Artificial Intelligence, Copyright, Economic Right, Moral Right},
location = {
},
series = {AIBC '24}
}

@inproceedings{10.5555/3615924.3615942,
author = {Alexopoulos, Michelle and Lyons, Kelly and Mahetaji, Kaushar and Barnes, Marcus Emmanuel and Gutwillinger, Rogan},
title = {Gender Inference: Can ChatGPT Outperform Common Commercial Tools?},
year = {2023},
publisher = {IBM Corp.},
address = {USA},
abstract = {An increasing number of studies use gender information to un-derstand phenomena such as gender bias, inequity in access and participation, or the impact of the Covid pandemic response. Un-fortunately, most datasets do not include self-reported gender in-formation, which makes it necessary for researchers to infer gen-der from other information, such as from names or names and country information. In this paper, we compare the performance of the new generative Artificial Intelligence (AI) tool ChatGPT with three traditional commercially available list-based and ma-chine learning-based gender inference tools—Namsor, Gender-API, and genderize.io—on a unique dataset. Specifically, we use a large Olympic athlete dataset and report how variations in the input (e.g., first name and first \&amp; last name, with and without country information) impact the accuracy of their predictions. We find that Namsor is the best traditional commercially available tool. However, ChatGPT performs at least as well as Namsor and often outper-forms it, especially for the female sample when country and/or last name information is available. We conclude ChatGPT may be a cost-effective tool for gender prediction.},
booktitle = {Proceedings of the 33rd Annual International Conference on Computer Science and Software Engineering},
pages = {161–166},
numpages = {6},
keywords = {Name-Based Gender Inference, ChatGPT, Performance Evaluation, Data Science and AI},
location = {Las Vegas, NV, USA},
series = {CASCON '23}
}

@inproceedings{10.1145/3722237.3722374,
author = {He, Ping and Yang, Yin},
title = {Future Education: Freedom and Comprehensive Human Development in the Age of Artificial Intelligence},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722374},
doi = {10.1145/3722237.3722374},
abstract = {Artificial intelligence has a powerful database and language generation function, which can be used as an extension of the human brain to a certain extent. Its application in the field of education has brought about a double-sided effect. On the one hand, AI promotes the great enrichment of material and spiritual wealth and makes it possible to liberate people's hands, which are the basis and conditions for human's freedom and all-round development. On the other hand, AI also brings some hidden worries to education: reshaping people's values, exacerbating the gap in educational resources, and triggering ethical controversies. Based on the Marxist theory on the freedom and comprehensive development of human beings, this paper focuses on the hidden worries of future education under the influence of artificial intelligence to explore the reform paths of future education. The reform paths including establishing correct value concepts to correctly understand the value of education; focusing on independent and diversified learning to cultivate students’ ability of independent critical thinking; breaking down technological barriers to build a technology development platform and share AI technology; sounding ethical rules as well as strengthening institutional regulations and technological protection support to shape the concept of science and technology for good and enhance people's awareness of digital security and self-protection. Promoting future education's reformation in the age of artificial intelligence with correct values, fair educational resources and sound ethical rules can play a good role in educating and cultivating autonomous, diversified and comprehensive new-age talents.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {780–787},
numpages = {8},
keywords = {Artificial Intelligence, Educational Worries, Freedom and Comprehensive Human Development, Future Education, Reform Paths,},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3756580.3756591,
author = {Shao, Hongmeng and Luo, Tao and Zhong, Weimin and Wang, Rifeng and Pan, Jiezong},
title = {Breaking Boundaries Exploring the Driving Mechanisms of Artificial Intelligence in Enhancing Pre-service Teachers' Teaching Skills},
year = {2025},
isbn = {9798400715624},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3756580.3756591},
doi = {10.1145/3756580.3756591},
abstract = {The rapid development of artificial intelligence in education is making it increasingly difficult to adapt traditional methods of training teachers in pre-service to the needs of professional change.Based on constructivistic learning theory and Technology Adoption Model (Tam), this study builds a model of the driving mechanism " perceived utility — motivation for learning — improving teaching skills " and establishing the frequency of use of artificial intelligence tools as exogenous variables.After analyzing data from 213 pre-service teachers,it was found that the frequent use of AI tools can effectively increase perceived value and encourage motivation for learning, as well as encourage growth in teaching abilities.At the same time, motivation to learn plays an intermediate function in this process.The above results can serve as some theoretical basis and practical rationale for the integration of AI into education aimed at improving the use of learning models using AI and playing a catalytic role in improving the quality of teacher training.},
booktitle = {Proceedings of the 2025 6th International Conference on Education, Knowledge and Information Management},
pages = {65–72},
numpages = {8},
keywords = {Artificial Intelligence, Driving Path Model, Pre-service Teachers, Teaching Skill Enhancement},
location = {
},
series = {ICEKIM '25}
}

@inproceedings{10.1145/3657054.3657092,
author = {Mancera Andrade, Jos\'{e} Alberto and Ter\'{a}n, Luis},
title = {From GenAI to Political Profiling Avatars: A Data-Driven Approach to Crafting Virtual Experts for Voting Advice Applications},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657092},
doi = {10.1145/3657054.3657092},
abstract = {Voting advice applications (VAAs) are pivotal web-based tools that guide citizens to align with political parties and candidates that match their preferences. Traditional methods for creating candidate profiles predominantly rely on questionnaire responses, a time-intensive and costly process. To address these challenges, we introduce a data-centric methodology utilizing generative artificial intelligence (GenAI), culminating in creating political avatars. These political avatars are engineered using cutting-edge large language models (LLMs), including GPT-4 and Bard. They are adept at processing and interpreting data primarily sourced from Twitter and leveraging bespoke, self-trained datasets. Integrating advanced AI technology with diverse data sources equips political avatars with unprecedented analytical and predictive capabilities, setting a new standard in political analysis. Unlike traditional methods, political avatars are adept at emulating the responses of real politicians or experts, showcasing a remarkable capacity to interact with VAA surveys. This novel approach presents the potential to either compete with or enhance the insights traditionally obtained from human experts. Another critical aspect of our study is comparing political avatars and previous research employing question-answering (QA) models based on advanced natural language processing (NLP) techniques for political profiling. This comparative analysis reveals that Political Avatars offer a significantly more robust solution for profile construction. While QA models provide structured responses based on specific queries, political avatars bring an element of dynamism and depth, capable of generating nuanced, context-aware responses. This shift from static, questionnaire-based profiling to dynamic, AI-driven avatars marks a substantial leap in political analysis. Generative AI in crafting Political Avatars introduces a transformative element to data analysis. This approach facilitates a layered and more sophisticated interpretation of political stances, moving beyond the limitations of traditional profiling methods. By employing political avatars, our methodology not only streamlines the profiling process but also enriches the quality of insights derived, paving the way for a more nuanced understanding of the political landscape.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {305–311},
numpages = {7},
keywords = {Bard, GPT-4, Generative AI, Large Language Models, Natural Language Processing, Political Avatars, Question Answering, Social Media, Voting Advice Applications},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

@inbook{10.1145/3724504.3724634,
author = {Deng, Xiaomi and Li, Wang},
title = {The Integrated Development Path of Artificial Intelligence and Open Learning},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724634},
abstract = {With the rapid development of artificial intelligence, problems such as fragmentation of learning content and unequal distribution of resources as well as difficulties in evaluating the learning effects emerge for open learning. This paper proposes hybrid learning through AI-based intelligent recommendation and adaptive learning techniques as a solution. Statistics from the students' learning history and behavioural data are used with deep learning for the prediction of students' learning needs accurate enough to recommend personalised resources. Students' progress in understanding is checked through natural language processing before further personalisation. The complexity of the learning content then changes dynamically in accordance to every individual. The tasks of collecting data, training the proposed model, optimising its algorithm, and validating the experiments therein are undertaken. The experiments find that the performance of student learning using the hybrid model improved by 9.3\%, reduced learning time by 15.5\%, and improved finding the right recommendation by about 23.8\% compared to the non-intelligent platform. In conclusion, the study proves that Ai and open learning, in practice, can increase the efficiency of learning and enhance the learning experience, providing a way to bridge the equity in education with personalised education.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {792–798},
numpages = {7}
}

@inproceedings{10.1145/3706468.3706483,
author = {Hedlin, Elias and Estling, Ludwig and Wong, Jacqueline and Demmans Epp, Carrie and Viberg, Olga},
title = {Got It! Prompting Readability Using ChatGPT to Enhance Academic Texts for Diverse Learning Needs},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706483},
doi = {10.1145/3706468.3706483},
abstract = {Reading skills are crucial for students' success in education and beyond. However, reading proficiency among K-12 students has been declining globally, including in Sweden, leaving many underprepared for post-secondary education. Additionally, an increasing number of students have reading disorders, such as dyslexia, which require support. Generative artificial intelligence (genAI) technologies, like ChatGPT, may offer new opportunities to improve reading practices by enhancing the readability of educational texts. This study investigates whether ChatGPT-4 can simplify academic texts and which prompting strategies are most effective. We tasked ChatGPT to re-write 136 academic texts using four prompting approaches: Standard, Meta, Roleplay, and Chain-of-Thought. All four approaches improved text readability, with Meta performing the best overall and the Standard prompt sometimes creating texts that were less readable than the original. This study found variability in the simplified texts, suggesting that different strategies should be used based on the specific needs of individual learners. Overall, the findings highlight the potential of genAI tools, like ChatGPT, to improve the accessibility of academic texts, offering valuable support for students with reading difficulties and promoting more equitable learning opportunities.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {115–125},
numpages = {11},
keywords = {Analytics, Equity, Large language models, Literacy, Prompt engineering, Readability},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3613905.3650763,
author = {Gmeiner, Frederic and Conlin, Jamie Lynn and Tang, Eric Handa and Martelaro, Nikolas and Holstein, Kenneth},
title = {An Evidence-based Workflow for Studying and Designing Learning Supports for Human-AI Co-creation},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650763},
doi = {10.1145/3613905.3650763},
abstract = {Generative artificial intelligence (GenAI) systems introduce new possibilities for enhancing professionals’ workflows, enabling novel forms of human–AI co-creation. However, professionals often struggle to learn to work with GenAI systems effectively. While research has begun to explore the design of interfaces that support users in learning to co-create with GenAI, we lack systematic approaches to investigate the effectiveness of these supports. In this paper, we present a systematic approach for studying how to support learning to co-create with GenAI systems, informed by methods and concepts from the learning sciences. Through an experimental case study, we demonstrate how our approach can be used to study and compare the impacts of different types of learning supports in the context of text-to-image GenAI models. Reflecting on these results, we discuss directions for future work aimed at improving interfaces for human–AI co-creation.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {42},
numpages = {15},
keywords = {Case Study, Generative AI, Human–AI Co-creation, Human–AI Interaction, Learning, Study Method, Support Interfaces},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@article{10.1145/3649223,
author = {Silva, Jorge Sassaki Resende and Cardoso, Paula Christina Figueira and De Bettio, Raphael Winckler and Tavares, Daniela Cardoso and Silva, Carlos Alberto and Watanabe, Willian Massami and Freire, Andr\'{E} Pimenta},
title = {In-Page Navigation Aids for Screen-Reader Users with Automatic Topicalisation and Labelling},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1936-7228},
url = {https://doi.org/10.1145/3649223},
doi = {10.1145/3649223},
abstract = {Navigation aids such as headers and internal links provide vital support for screen-reader users on web documents to grasp a document’s structure. However, when such navigation aids are unavailable or not appropriately marked up, this situation can cause serious difficulties. This article presents the design and evaluation of a tool for automatically generating navigation aids with headers and internal links for screen readers with topicalisation and labelling algorithms. The proposed tool uses natural language processing techniques to divide a web document into topic segments and label each segment in two cycles based on its content. We conducted an initial user study in the first cycle with eight blind and partially-sighted screen reader users. The evaluation involved tasks with questions answered by participants with information from texts with and without automatically generated headers. The results in the first cycle provided preliminary indicators of performance improvement and cognitive load reduction. The second cycle involved co-designing an improved version with two blind experts in web accessibility, resulting in a browser extension which injects automatically generated headers and in-page navigation with internal links, along with improvements in the generation of labels using OpenAI’s ChatGPT. The browser extension was evaluated by seven blind participants using the same four texts used to evaluate the preliminary prototype developed in the first cycle. With the two development cycles, the study provided important insights into the design of navigation aids for screen-reader users using natural language processing techniques, including the potential use of generative artificial intelligence for assistive technologies and limitations that need to be explored in future research.},
journal = {ACM Trans. Access. Comput.},
month = jul,
articleno = {12},
numpages = {45},
keywords = {Accessibility, natural language processing, screen readers, topic segmentation and labelling, large language models, assistive technologies}
}

@inproceedings{10.1145/3746972.3747003,
author = {Wang, Longfeng and Chen, Ting and Wang, Xupeng and Cheng, Mengzeng},
title = {The Impact of Artificial Intelligence on Corporate Strategic Decision-Making: Convergence or Differentiation?},
year = {2025},
isbn = {9798400713576},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746972.3747003},
doi = {10.1145/3746972.3747003},
abstract = {The application of artificial intelligence (AI) is reshaping the strategic decision-making patterns of enterprises. To clarify the influence mechanism of AI on corporate strategic decision-making, to elucidate the mechanisms through which AI influences corporate strategic decision-making, this study uses Chinese A-share listed companies from 2013 to 2023 as a sample to empirically examine the impact of AI on strategic decision-making. The research finds that AI application significantly increases the overall strategic deviance of enterprises, supporting the "differentiation effect" hypothesis. Sub-dimensional tests show that AI drives enterprises to significantly deviate from industry norms in advertising investment, R&amp;D intensity, and fixed asset renewal, demonstrating characteristics of "active innovation"; while in the dimensions of capital intensity and financial leverage, enterprises tend to approach industry averages, reflecting a "rational contraction" tendency. This study provides a theoretical basis for understanding the strategic value of AI and offers practical insights for enterprises to optimize their technology application paths.},
booktitle = {Proceedings of the 2025 International Conference on Digital Economy and Intelligent Computing},
pages = {187–191},
numpages = {5},
keywords = {artificial intelligence, strategic decision-making, strategic deviance},
location = {
},
series = {DEIC '25}
}

@inproceedings{10.1145/3732801.3732812,
author = {Xu, Pengcheng and Li, Yunling},
title = {Research on typical scenarios of higher education based on artificial intelligence},
year = {2025},
isbn = {9798400712432},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3732801.3732812},
doi = {10.1145/3732801.3732812},
abstract = {This paper introduces the typical scenarios of the current development of AI-enabled higher education. It begins by deeply analyzing the contradictions in teaching, learning, and assessment that are inherent within traditional higher education frameworks. The paper then proceeds to study the advantages that AI-enabled higher education brings to the table, illustrating the empowerment path and application effect by analyzing a series of typical cases that showcase the transformative potential of artificial intelligence in the academic environment. Finally, the paper further explores and refines the typical application scenarios and specific methods of AI-based higher education, focusing on three core aspects: teaching, learning, and assessment. It delves into how AI can be leveraged to enhance the quality of instruction, personalize the learning experience, and provide more accurate and fair assessment methodologies, thereby paving the way for a more efficient and effective educational paradigm.},
booktitle = {Proceedings of the 2025 2nd International Conference on Informatics Education and Computer Technology Applications},
pages = {53–58},
numpages = {6},
keywords = {artificial intelligence, higher education, typical scenario},
location = {
},
series = {IECA '25}
}

@inproceedings{10.1145/3760544.3764129,
author = {Hube, Mika Leo and Lemic, Filip and Shitiri, Ethungshan and Bartra, Gerard Calvo and Abadal, Sergi and P\'{e}rez, Xavier Costa},
title = {Set Transformer Architectures and Synthetic Data Generation for Flow-Guided Nanoscale Localization},
year = {2025},
isbn = {9798400721663},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3760544.3764129},
doi = {10.1145/3760544.3764129},
abstract = {Flow-guided Localization (FGL) enables the identification of spatial regions within the human body that contain an event of diagnostic interest. FGL does that by leveraging the passive movement of energy-constrained nanodevices circulating through the bloodstream. Existing FGL solutions rely on graph models with fixed topologies or handcrafted features, which limit their adaptability to anatomical variability and hinder scalability. In this work, we explore the use of Set Transformer architectures to address these limitations. Our formulation treats nanodevices' circulation time reports as unordered sets, enabling permutation-invariant, variable-length input processing without relying on spatial priors. To improve robustness under data scarcity and class imbalance, we integrate synthetic data generation via deep generative models, including CGAN, WGAN, WGAN-GP, and CVAE. These models are trained to replicate realistic circulation time distributions conditioned on vascular region labels, and are used to augment the training data. Our results show that the Set Transformer achieves comparable classification accuracy compared to Graph Neural Networks (GNN) baselines, while simultaneously providing by-design improved generalization to anatomical variability. The findings highlight the potential of permutation-invariant models and synthetic augmentation for robust and scalable nanoscale localization.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Nanoscale Computing and Communication},
pages = {34–39},
numpages = {6},
keywords = {cardiovascular precision medicine, in-body nanoscale communication, flow-guided localization, generative artificial intelligence},
location = {University of Electronic Science and Technology of China, Chengdu, China},
series = {NANOCOM '25}
}

@inproceedings{10.1145/3711403.3711438,
author = {Zhang, Shaojun and He, Xiangchun and Zhou, Yaxin and Jiang, Ruishuang and Han, Yuqi and Guo, Xue},
title = {Artificial Intelligence Helps Teachers Personalise Their Teaching--Take ChatGPT as an Example},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711438},
doi = {10.1145/3711403.3711438},
abstract = {With the continuous development of science and technology, Artificial Intelligence (AI) has become an important driving force for innovation in the field of education, especially advanced AI language models such as ChatGPT, which shows great potential in assisting teachers to design, implement and evaluate personalised teaching due to its excellent language comprehension and generative ability. Nevertheless, how to use ChatGPT to help teachers carry out personalised teaching has yet to be explored. Therefore, this paper explores and analyses the ways in which ChatGPT can help teachers carry out personalised teaching based on the connotation of ChatGPT and personalised teaching, and discusses the challenges faced when using ChatGPT to assist teachers in carrying out personalised teaching, from the perspective of the three aspects of teaching: lesson planning, instruction, and evaluation and feedback. It also discusses the challenges faced when using ChatGPT to assist teachers in personalised teaching and proposes strategies to address them. The study shows that artificial intelligence can make teachers more scientific, precise, intelligent and diversified in the process of implementing personalised teaching.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {200–205},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, Personalised Teaching},
location = {
},
series = {ICETM '24}
}

