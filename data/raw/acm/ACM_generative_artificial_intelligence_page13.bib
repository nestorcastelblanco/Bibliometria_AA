@inproceedings{10.1145/3626772.3661371,
author = {Vedula, Nikhita and Rokhlenko, Oleg and Malmasi, Shervin},
title = {Question Suggestion for Conversational Shopping Assistants Using Product Metadata},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3661371},
doi = {10.1145/3626772.3661371},
abstract = {Digital assistants have become ubiquitous in e-commerce applications, following the recent advancements in Information Retrieval (IR), Natural Language Processing (NLP) and Generative Artificial Intelligence (AI). However, customers are often unsure or unaware of how to effectively converse with these assistants to meet their shopping needs. In this work, we emphasize the importance of providing customers a fast, easy to use, and natural way to interact with conversational shopping assistants. We propose a framework that employs Large Language Models (LLMs) to automatically generate contextual, useful, answerable, fluent and diverse questions about products, via in-context learning and supervised fine-tuning. Recommending these questions to customers as helpful suggestions or hints to both start and continue a conversation can result in a smoother and faster shopping experience with reduced conversation overhead and friction. We perform extensive offline evaluations, and discuss in detail about potential customer impact, and the type, length and latency of our generated product questions if incorporated into a real-world shopping assistant.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2960–2964},
numpages = {5},
keywords = {conversational shopping assistants, product question suggestion},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3613905.3651111,
author = {Milesi, Mikaela E and Alfredo, Riordan and Echeverria, Vanessa and Yan, Lixiang and Zhao, Linxuan and Tsai, Yi-Shan and Martinez-Maldonado, Roberto},
title = {"It's Really Enjoyable to See Me Solve the Problem like a Hero": GenAI-enhanced Data Comics as a Learning Analytics Tool},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3651111},
doi = {10.1145/3613905.3651111},
abstract = {Data comics are an emergent storytelling format that can enable non-experts to consume salient insights from data. Despite some research investigating the use of comic strips in education, there is limited evidence relating to how students perceive data comics about their own data as a way to reflect on their learning experience. In this paper, we summarise nursing students’ perceptions of the advantages and limitations of data comics by presenting personalised Multimodal Learning Analytics (LA) data in data comics form. We present GenAI-enhanced data comic prototypes created using a combination of the generative artificial intelligence tool, Midjourney, and graphics illustration software. Our findings indicate that while students see the potential of data comics as an engaging and enjoyable visualisation technique, concerns remain regarding the perceived lack of professionalism associated with this format.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {4},
numpages = {7},
keywords = {data comics, information visualisation, learning analytics},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3731763.3731792,
author = {Vu, Khoi Anh and Ngo, Khoa Quoc Anh and Tran, Anh Huy and Nguyen, Phuc Le Hoang and Nguyen, Duong Huu and Tran, Bao Dinh Gia},
title = {AI Tool for Room Decoration: Harnessing Diffusion Model for Interior Design},
year = {2025},
isbn = {9798400710841},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3731763.3731792},
doi = {10.1145/3731763.3731792},
abstract = {Based on the capabilities of generative artificial intelligence (AI) models, particularly diffusion models, this study proposes an effective AI tool for interior design. This tool helps users create personalized and aesthetically pleasing decoration ideas by leveraging diffusion models’ ability to analyze and reconstruct the fundamental distribution of interior design elements, enabling adaptation to diverse styles and trends. The accompanying figure illustrates the tool’s functionality through examples of three key tasks: appearance modulation, object moving and resizing, and object pasting, with clear visualizations of input and output images. By automating repetitive tasks, the tool significantly reduces the time and effort required in the design process while also encouraging creativity by allowing users to explore a broader range of design possibilities. In general, this study presents an innovative application of diffusion models in interior design, providing an AI-powered tool to enhance the user experience and support the creative interior styling process.},
booktitle = {Proceedings of the 2025 10th International Conference on Intelligent Information Technology},
pages = {87–91},
numpages = {5},
keywords = {Stable Diffusion, Image Generation, Neural Networks, Computer Vision, Generative Models, Deep Learning, Rendering, Interior Design, User Interface, Personalization},
location = {
},
series = {ICIIT '25}
}

@inproceedings{10.1145/3677996.3678289,
author = {Suckrow, Pierre-Louis Wolfgang L\'{e}on and Weber, Christoph Johannes and Rothe, Sylvia},
title = {Diffusion-Based Sound Synthesis in Music Production},
year = {2024},
isbn = {9798400710995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677996.3678289},
doi = {10.1145/3677996.3678289},
abstract = {In this paper, we explore the usability of generative artificial intelligence in music production through the development of a digital instrument that incorporates diffusion-based sound synthesis in its sound generation. Current text-to-audio models offer a novel method of defining sounds, which we aim to render utilizable in a music-production environment. Selected pretrained latent diffusion models, enable the synthesis of playable sounds through textual descriptions, which we incorporated into a digital instrument that integrates with standard music production tools. The resultant user interface not only allows generating but also modifying the sounds by editing model and instrument-specific parameters. We evaluated the applicability of current diffusion models with their parameters as well as the fitness of possible prompts for music production scenarios. Adapting published diffusion model pipelines for integration into the instrument, we facilitate experimentation and exploration of this innovative sound synthesis method. Our findings show that despite facing some limitations in the models' responsiveness to specific music production contexts and the instrument's functionality, the tool allows the development of novel and intriguing soundscapes. The instrument and code is published under https://github.com/suckrowPierre/WaveGenSynth},
booktitle = {Proceedings of the 12th ACM SIGPLAN International Workshop on Functional Art, Music, Modelling, and Design},
pages = {55–64},
numpages = {10},
keywords = {sound generation, text-to-sound, user interface, user study},
location = {Milan, Italy},
series = {FARM 2024}
}

@article{10.1145/3768581,
author = {Gu, Siqi and Fang, Chunrong and Zhang, Quanjun and Chen, Zhenyu},
title = {ACTesting: Automated Cross-modal Testing Method of Text-to-Image Software},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3768581},
doi = {10.1145/3768581},
abstract = {Recently, creative generative artificial intelligence software has emerged as a pivotal assistant, enabling users to generate content and seek inspiration rapidly. Text-to-Image (T2I) software, one of the most widely used, synthesizes images with text input by engaging in a cross-modal process. However, despite substantial advancements in the T2I engine, T2I software still encounters errors when generating complex or non-realistic scenes, including omitting focal entities, low image realism, and mismatched text-image information. The cross-modal nature of T2I software complicates error detection for traditional testing methods, and the absence of test oracles further exacerbates the complexity of the testing process. To fill this gap, we propose ACTesting, an Automated Cross-modal Testing Method of Text-to-Image Software, the first testing method explicitly designed for T2I software. ACTesting utilizes the metamorphic testing principle to address the oracle problem and identifies cross-modal semantic consistency as its fundamental Metamorphic relation (MR) by employing the Entity-relationship (ER) triples. We design three kinds of mutation operators under the guidance of MR and the adaptability density constraint to construct the new input text. After generating the images based on the text, ACTesting verifies whether MR is satisfied by detecting the ER triples across two modalities to detect the errors of T2I software. In our experiments across five popular T2I software, ACTesting effectively generates error-revealing tests, resulting in a decrease in text-image consistency by up to 20\% when compared to the baseline. Additionally, an ablation study demonstrates the efficacy of the proposed mutation operators. The experimental results validate that ACTesting can reliably identify errors within T2I software.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
keywords = {Software Testing, Cross-modal, Text-to-Image}
}

@article{10.1145/3652154,
author = {Russo, Daniel},
title = {Navigating the Complexity of Generative AI Adoption in Software Engineering},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3652154},
doi = {10.1145/3652154},
abstract = {This article explores the adoption of Generative Artificial Intelligence (AI) tools within the domain of software engineering, focusing on the influencing factors at the individual, technological, and social levels. We applied a convergent mixed-methods approach to offer a comprehensive understanding of AI adoption dynamics. We initially conducted a questionnaire survey with 100 software engineers, drawing upon the Technology Acceptance Model, the Diffusion of Innovation Theory, and the Social Cognitive Theory as guiding theoretical frameworks. Employing the Gioia methodology, we derived a theoretical model of AI adoption in software engineering: the Human-AI Collaboration and Adaptation Framework. This model was then validated using Partial Least Squares–Structural Equation Modeling based on data from 183 software engineers. Findings indicate that at this early stage of AI integration, the compatibility of AI tools within existing development workflows predominantly drives their adoption, challenging conventional technology acceptance theories. The impact of perceived usefulness, social factors, and personal innovativeness seems less pronounced than expected. The study provides crucial insights for future AI tool design and offers a framework for developing effective organizational implementation strategies.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {135},
numpages = {50},
keywords = {Generative AI, large language models, technology adaption, empirical software engineering}
}

@article{10.1145/3700142,
author = {Dwivedi, Divya and De', Rahul},
title = {Potential for GenAI in the Public Domain: A Review of Transportation, Healthcare, Agriculture, and Law},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
url = {https://doi.org/10.1145/3700142},
doi = {10.1145/3700142},
abstract = {Generative Artificial Intelligence (GenAI) tools are becoming quite popular for a variety of operations. One such tool, Chat Generative Pre-Trained Transformer (ChatGPT), is rapidly permeating into people's daily lives and is considered to have the potential to reshape our society. While private organizations are spending huge amounts of money on ChatGPT, its usage in the public domain is still driven by its open access and simple functionality. This study draws on the key concepts of Effective Use theory—Transparent Interaction, Representational Fidelity, Informed Action, and Learning and Adaptation—to examine ChatGPT's current state of diffusion in four public sector domains: transportation, healthcare, agriculture, and law. We find that transparent interaction is better in transportation, agriculture, and law than healthcare; representational fidelity presents a complex picture, whereas informed action has been positive across domains; and learning and adaptation is an ongoing need. We conclude with various suggestions related to research and policy toward boosting GenAI's adoption. We suggest that governments invest resources and develop new regulatory frameworks considering the specific context and use cases for leveraging the enormous potential of GenAI tools in the public domain.},
journal = {Digit. Gov.: Res. Pract.},
month = feb,
articleno = {3},
numpages = {11},
keywords = {GenAI, ChatGPT in public domain, Effective Use theory, Ethical and regulatory considerations, Policy suggestions}
}

@inproceedings{10.1145/3669754.3669806,
author = {Batac, Carlo Antonio and Baroja, Marc Jethro and Caballero, Don John Daniel and Coloma, Louis Gabriel and Tan, Lind Matthew and Ebardo, Ryan},
title = {Do Human Beliefs and Traits Influence the Adoption of ChatGPT among Programming Students?},
year = {2024},
isbn = {9798400717055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669754.3669806},
doi = {10.1145/3669754.3669806},
abstract = {Abstract: Increased use of generative artificial intelligence or AI in various academic activities such as programming is a significant milestone in technology diffusion in learning. To bring AI closer to how programmers think, behave, and interact, it is imperative for research to establish a clear connection between various human factors that lead to its adoption. Using a model based on the Theory of Reasoned Action, we positioned human traits of academic stress, risk propensity, neuroticism, and computer self-efficacy as factors that positively influence attitudes toward the use of AI in programming among university students. We further posited that attitude and social norms lead to the behavioral intention to use AI in programming. We used PLS-SEM to analyze responses from 131 programming students who use ChatGPT to accomplish learning tasks. We found that both academic stress and computer self-efficacy influence attitudes toward using AI in programming. While attitude positively influences the behavioral intention to use ChatGPT, we found that risk propensity and neuroticism do not affect attitude, and social norms do not influence behavioral intention. We discuss the implications of our investigation to the industry and the academe.},
booktitle = {Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence},
pages = {339–344},
numpages = {6},
keywords = {ChatGPT, PLS-SEM, education, generative AI, programming},
location = {Bali Island, Indonesia},
series = {ICCAI '24}
}

@inbook{10.1145/3713043.3731602,
author = {Morales-Navarro, Luis},
title = {Investigating Youth’s Technical and Ethical Understanding of Generative Language Models When Engaging in Construction and Deconstruction Activities},
year = {2025},
isbn = {9798400714733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713043.3731602},
abstract = {The widespread adoption of generative artificial intelligence/machine learning (AI/ML) technologies has increased the need to support youth in developing AI/ML literacies. However, most work has centered on preparing young people to use these systems, with less attention to how they can participate in designing and evaluating them. This study investigates how engaging young people in the design and auditing of generative language models (GLMs) may foster the development of their understanding of how these systems work from both technical and ethical perspectives. The study takes an in-pieces approach to investigate novices’ conceptions of GLMs. Such an approach supports the analysis of how technical and ethical conceptions evolve and relate to each other. I am currently conducting a series of participatory design workshops with sixteen ninth graders (ages 14–15) in which they will (a) build GLMs from a data-driven perspective that glassboxes how data shapes model performance and (b) audit commercial GLMs by repeatedly and systematically querying them to draw inferences about their behaviors. I will analyze participants’ interactions to identify ethical and technical conceptions they may exhibit while designing and auditing GLMs. Then I will investigate the contexts in which these conceptions emerge and how participants’ personal interests and prior experiences may relate to their conceptions. I will also conduct clinical interviews and use microgenetic knowledge analysis and ordered network analysis to investigate how participants’ ethical and technical conceptions of GLMs relate to each other and change after the workshop. The study will contribute (a) evidence of how engaging youth in design and auditing activities may support the development of ethical and technical understanding of GLMs and (b) an inventory of novice design and auditing practices that may support youth’s technical and ethical understanding of GLMs.},
booktitle = {Proceedings of the 24th Interaction Design and Children},
pages = {1172–1175},
numpages = {4}
}

@inproceedings{10.1145/3630106.3658898,
author = {Goetze, Trystan S.},
title = {AI Art is Theft: Labour, Extraction, and Exploitation: Or, On the Dangers of Stochastic Pollocks},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658898},
doi = {10.1145/3630106.3658898},
abstract = {Since the launch of applications such as dall•e, Midjourney, and Stable Diffusion, generative artificial intelligence has been controversial as a tool for creating artwork. Some writers have presented worries about these technologies as harbingers of fully automated futures to come, but more pressing is the impact of generative AI on creative labour in the present. Already, business leaders have begun replacing human artistic labour with AI-generated images. In response, the artistic community has launched a protest movement, which argues that AI image generation is a kind of theft. This paper analyzes, substantiates, and critiques these arguments, concluding that AI image generators involve an unethical kind of labour theft. If correct, many other AI applications also rely upon theft.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {186–196},
numpages = {11},
keywords = {AI ethics, John Locke, automation, computer art, computer ethics, data colonialism, diffusion models, generative AI, intellectual property, labour, philosophy, text-to-image AI},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3643491.3660283,
author = {Schmitt, Vera and Csomor, Bal\'{a}zs Patrik and Meyer, Joachim and Villa-Areas, Luis-Felipe and Jakob, Charlott and Polzehl, Tim and M\"{o}ller, Sebastian},
title = {Evaluating Human-Centered AI Explanations: Introduction of an XAI Evaluation Framework for Fact-Checking},
year = {2024},
isbn = {9798400705526},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643491.3660283},
doi = {10.1145/3643491.3660283},
abstract = {The rapidly increasing amount of online information and the advent of Generative Artificial Intelligence (GenAI) make the manual verification of information impractical. Consequently, AI systems are deployed to detect disinformation and deepfakes. Prior studies have indicated that combining AI and human capabilities yields enhanced performance in detecting disinformation. Furthermore, the European Union (EU) AI Act mandates human supervision for AI applications in areas impacting essential human rights, like freedom of speech, necessitating that AI systems be transparent and provide adequate explanations to ensure comprehensibility. Extensive research has been conducted on incorporating explainability (XAI) attributes to augment AI transparency, yet these often miss a human-centric assessment. The effectiveness of such explanations also varies with the user’s prior knowledge and personal attributes. Therefore, we developed a framework for validating XAI features for the collaborative human-AI fact-checking task. The framework allows the testing of XAI features with objective and subjective evaluation dimensions and follows human-centric design principles when displaying information about the AI system to the users. The framework was tested in a crowdsourcing experiment with 433 participants, including 406 crowdworkers and 27 journalists for the collaborative disinformation detection task. The tested XAI features increase the AI system’s perceived usefulness, understandability, and trust. With this publication, the XAI evaluation framework is made open source.},
booktitle = {Proceedings of the 3rd ACM International Workshop on Multimedia AI against Disinformation},
pages = {91–100},
numpages = {10},
keywords = {Human-centered eXplanations, blind trust in AI systems, objective and subjective evaluation of eXplanations},
location = {Phuket, Thailand},
series = {MAD '24}
}

@inproceedings{10.1145/3670653.3677507,
author = {Kubullek, Ann-Kathrin and Kuma\c{c}, Nadire and Dogang\"{u}n, Ayseg\"{u}l},
title = {Understanding the Adoption of ChatGPT in Higher Education: A Comparative Study with Insights from STEM and Business Students},
year = {2024},
isbn = {9798400709982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670653.3677507},
doi = {10.1145/3670653.3677507},
abstract = {Since ChatGPT’s introduction, generative artificial intelligence (AI) has significantly influenced the media, technological innovation, and educational discourse. Its increasing importance, especially in academia, necessitates a detailed examination of the impact of AI on higher education, particularly on how it changes teaching and learning processes. This study therefore looks at the factors affecting students’ attitudes towards AI technologies in the university setting, with a particular focus on the differences between business and STEM programmes. Using a mixed methods approach, the study combines surveys and interviews to collect data on students’ perceptions, attitudes and experiences with generative AI technology in academia. The data collected is analysed both quantitatively and qualitatively to reveal significant trends and insights into the adoption and use of generative AI tools in the university environment. The main objective of the study is to shed light on the determinants that determine the varying degrees of AI adoption in different academic disciplines. The findings have the potential to inform the implementation of educational technology and assist in the development of strategies for the effective integration of generative AI tools to meet the different needs and preferences of students in a range of academic contexts.},
booktitle = {Proceedings of Mensch Und Computer 2024},
pages = {684–689},
numpages = {6},
keywords = {ChatGPT, STEM degree programs, academic disciplines, acceptance of AI, business degree programs, generative AI adoption, higher education, students},
location = {Karlsruhe, Germany},
series = {MuC '24}
}

@inproceedings{10.1145/3722237.3722245,
author = {Fan, Sun and Peng, Lu and Wu, Shaofeng and Yu, Xingmu},
title = {ChatGPT Empowers Higher Education: —Research Topics Hotspots and Quantitative Visual Analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722245},
doi = {10.1145/3722237.3722245},
abstract = {In order to deeply explore the current research hotspots and development trends of ChatGPT generative artificial intelligence in empowering higher education applications, this study conducted a detailed analysis of 178 articles related to ChatGPT+higher education in the knowledge Resource Database. By using software tools such as Power BI, SPSS, and Excel, this study conducted a visual analysis of core authors, research funding, research topics, author institutions, discipline areas, and related indicators in the literature. The aim of the study is to analyze the current status of ChatGPT research in higher education applications and to explore the hot issues surrounding ChatGPT empowerment in higher education.The study points out that current research in higher education in the era of artificial intelligence mainly focuses on introducing ChatGPT, the characteristics and connotations of large language models, and discussing the opportunities, challenges, coping strategies, and digital transformation research they bring. However, there is still a lack of in-depth exploration of the application of ChatGPT and other technologies in education, especially in areas such as personalized learning and precision teaching, the integration of virtual and actual teaching spaces, intelligent teaching facilities and resources, human-computer collaborative teaching methods, and interdisciplinary innovative research methods.We should actively respond to the opportunities and challenges brought by intelligent tools such as ChatGPT to higher education, and comprehensively and deeply explore how to integrate ChatGPT into key areas of digital education, including teaching design, teaching resource development, teaching organization and implementation, teaching evaluation and reflection, learning and personal knowledge management, innovation team building, and enhancing the digital literacy and professional capabilities of teachers and students. In addition, the impact of the application of ChatGPT and other technologies in education on educational equity, and how to ensure that all students can benefit from it through reasonable design and use, should also be of concern. The goal of this study is to further promote and drive the digital transformation of higher education by building a brand new higher education ecosystem based on ChatGPT.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {38–45},
numpages = {8},
keywords = {ChatGPT, Digital transformation, Empowers, higher education, hot topics, human-machine collaborative intelligence, trends, visualization},
location = {
},
series = {ICAIE '24}
}

@article{10.1145/3649883,
author = {Cheong, Marc and Abedin, Ehsan and Ferreira, Marinus and Reimann, Ritsaart and Chalson, Shalom and Robinson, Pamela and Byrne, Joanne and Ruppanner, Leah and Alfano, Mark and Klein, Colin},
title = {Investigating Gender and Racial Biases in DALL-E Mini Images},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
url = {https://doi.org/10.1145/3649883},
doi = {10.1145/3649883},
abstract = {Generative artificial intelligence systems based on transformers, including both text generators such as GPT-4 and image generators such as DALL-E 3, have recently entered the popular consciousness. These tools, while impressive, are liable to reproduce, exacerbate, and reinforce extant human social biases, such as gender and racial biases. In this article, we systematically review the extent to which DALL-E Mini suffers from this problem. In line with the Model Card published alongside DALL-E Mini by its creators, we find that the images it produces tend to represent dozens of different occupations as populated either solely by men (e.g., pilot, builder, plumber) or solely by women (e.g., hairdresser, receptionist, dietitian). In addition, the images DALL-E Mini produces tend to represent most occupations as populated primarily or solely by White people (e.g., farmer, painter, prison officer, software engineer) and very few by non-White people (e.g., pastor, rapper). These findings suggest that exciting new AI technologies should be critically scrutinized and perhaps regulated before they are unleashed on society.},
journal = {ACM J. Responsib. Comput.},
month = jun,
articleno = {13},
numpages = {20},
keywords = {Gender bias, racial bias, algorithmic bias, generative AI, DALL-E Mini}
}

@inproceedings{10.1145/3626772.3661350,
author = {Zhao, Kang and Zhao, Xinyu and Jin, Zhipeng and Yang, Yi and Tao, Wen and Han, Cong and Li, Shuanglong and Liu, Lin},
title = {Enhancing Baidu Multimodal Advertisement with Chinese Text-to-Image Generation via Bilingual Alignment and Caption Synthesis},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3661350},
doi = {10.1145/3626772.3661350},
abstract = {Recent advances in generative artificial intelligence have revolutionized information retrieval and content generation, opening up new opportunities for the e-commerce industry. In particular, text-to-image generation models offer a novel approach to guiding the image generation process using natural language input, which is inspiring for multimodal search advertising. Traditional multimodal search ads require advertisers to prepare ad creatives, such as ad images, which is time-consuming and requires uniform image specifications and content quality inspection. To this end, we propose a streamlined generation framework for search ad image creatives. First, we prepare a Chinese image caption model with high-quality image-caption pairs to bootstrap training data refinement. With curated high-quality images and synthesized descriptive captions, we then train a Chinese text-to-image generation model, the largest to date, using SDXL and a 10-billion multimodal text encoder. Specifically, we introduce a two-stage bilingual multimodal representation alignment process to seamlessly integrate the text encoder with the generation model. Extensive experiments validate the effectiveness of our framework, including assessments of image captioning and image generation. The implementation of our framework in Baidu Search Ads shows significant revenue increase, For example, beauty industry ads with generated image creatives achieve a 29\% higher click-through rate (CTR).},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2855–2859},
numpages = {5},
keywords = {advertisement image creatives, multimodal sponsored search, text-to-image generation},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3641555.3705064,
author = {Erez, Yael and Ayali, Lilach and Hazzan, Orit},
title = {Evolution of Students' Attitudes Towards the Use of Generative AI Tools in a CS1 Course: Implications for Instructors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705064},
doi = {10.1145/3641555.3705064},
abstract = {Recent advancements in large language model-based generative artificial intelligence (GenAI) tools have transformed computer science education, presenting both opportunities and challenges. A study investigating students' attitudes toward these tools was conducted during an Introduction to Computer Science course. The target of the study was to gauge students' evolving attitudes toward using GenAI tools in the course, before, during and after ChatGPT was gradually assimilated into homework assignments. The study refers to three phases: preliminary phase, assimilation phase, and calibration stage, which currently takes place. Findings show that, in the preliminary phase, students appreciated the efficiency of GenAI tools offered but were concerned about developing a dependency on these tools and about ''cheating''. Findings from the assimilation phase indicate that consistent, guided exposure to GenAI tools positively shifted students' views, alleviating initial concerns and promoting a positive attitude toward using GenAI tools in the course. The targets of the calibration phase are: a) to examine how to leverage independent learning by formulating clear guidelines that can build trust in the technology and help overcome concerns regarding reliability and credibility; b) to check how GenAI can help students in a Introduction to Computer Science course acquire skills such as critical thinking and code comprehension. The study offers insights for educators on the integration of GenAI tools into computer science courses to enhance learning while maintaining academic integrity.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1740},
numpages = {1},
keywords = {critical thinking, cs1, generative ai, introduction to computer science, mixed methods, program comprehension, skills, students' attitudes},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3745812.3745858,
author = {Bhattad, Anil and Gulhane, Monali and Gavhale, Kiran and Revatkar, Abhay and Patil, Dilip and Singh, Uday Pratap},
title = {Generative AI for Simulating Rare Disease Scenarios in Training Robots},
year = {2025},
isbn = {9798400711220},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3745812.3745858},
doi = {10.1145/3745812.3745858},
abstract = {Generative artificial intelligence (AI) can be used to simulate rare disease situations. This is a potential way to train robotic systems, especially for medical actions. It can be hard to get real-world data for training because trends in rare diseases are often complicated, varied, and hard to predict. This can make it time-consuming, expensive, and morally problematic. Generative AI models, like Generative Adversarial Networks (GANs) and Variation Autoencoders (VAEs), can make fake but real medical situations that show how complicated rare diseases are. It is easy to make different datasets with these AI-driven models. These datasets can then be used to train robots so they can do complicated medical treatments more accurately and quickly By adding these AI models to artificial training environments, it is possible to create many rare disease cases that would be hard to make in regular training settings. The models improve robots' abilities to make smart choices, deal with new problems, and guess how patients will do in real time by exposing them to a lot of different situations. Using generative AI also cuts down on the need for real patient data, which protects privacy while still providing the reality needed for effective training. This method not only makes medical robots better at their jobs and more flexible in situations involving rare diseases, but it also makes it easier for them to keep learning. The robots can get better at making decisions by going through virtual situations that get more complicated. In the end, this study looks at how generative AI could be used to make computer systems that are smarter and can react to rare diseases. This would make medical treatments in these specialized fields more accurate and safer.},
booktitle = {Proceedings of the 6th International Conference on Information Management \&amp; Machine Intelligence},
articleno = {42},
numpages = {10},
keywords = {Generative AI, Rare disease simulation, Robotic training, Synthetic medical data, medical robotics},
location = {
},
series = {ICIMMI '24}
}

@inproceedings{10.1145/3706598.3713686,
author = {Zhang, Hongbo and Chen, Pei and Xie, Xuelong and Jiang, Zhaoqu and Wu, Yifei and Li, Zejian and Chen, Xiaoyu and Sun, Lingyun},
title = {FusionProtor: A Mixed-Prototype Tool for Component-level Physical-to-Virtual 3D Transition and Simulation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713686},
doi = {10.1145/3706598.3713686},
abstract = {Developing and simulating 3D prototypes is crucial in product conceptual design for ideation and presentation. Traditional methods often keep physical and virtual prototypes separate, leading to a disjointed prototype workflow. In addition, acquiring high-fidelity prototypes is time-consuming and resource-intensive, distracting designers from creative exploration. Recent advancements in generative artificial intelligence&nbsp;(GAI) and extended reality&nbsp;(XR) provided new solutions for rapid prototype transition and mixed simulation. We conducted a formative study to understand current challenges in the traditional prototype process and explore how to effectively utilize GAI and XR ability in prototype. Then we introduced FusionProtor, a mixed-prototype tool for component-level 3D prototype transition and simulation. We proposed a step-by-step generation pipeline in FusionProtor, effectively transiting 3D prototypes from physical to virtual and low- to high-fidelity for rapid ideation and iteration. We also innovated a component-level 3D creation method and applied it in XR environment for the mixed-prototype presentation and interaction. We conducted technical and user experiments to verify FusionProtor’s usability in supporting diverse designs. Our results verified that it achieved a seamless workflow between physical and virtual domains, enhancing efficiency and promoting ideation. We also explored the effect of mixed interaction on design and critically discussed its best practices for HCI community.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {685},
numpages = {19},
keywords = {conceptual design, 3D prototype, generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3722237.3722354,
author = {Han, Xue and Li, Zhixiang and Zhang, Wenchuan and Fan, Wentao},
title = {Generative AI in Education: Developing Personalized Learning Experiences with Hyperspherical Variational Self-Attention Autoencoder},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722354},
doi = {10.1145/3722237.3722354},
abstract = {With the advancement of artificial intelligence (AI) technology, content generation has sparked a transformative revolution in the field of education. In traditional education, teachers often spend a lot of time preparing lessons, because students have varying levels of proficiency, teachers need to consider whether the teaching content is suitable for everyone. Generative AI provides an effective solution to this problem by automatically generating personalized, high-quality educational content, which not only alleviates the burden on teachers but also enhances students' learning outcomes. This study focuses on a novel deep generative model—a framework based on Variational Autoencoders (VAE) and the self-attention mechanism (Transformer). We propose a model called the Hyperspherical Variational Self-Attention Autoencoder (HVSAE), which aims to generate personalized learning content based on students' learning situations, thereby reducing the burden on teachers and improving learning outcomes. The experimental results indicate that the model can generate high-quality educational resources, providing important support for achieving more personalized and efficient education.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {670–674},
numpages = {5},
keywords = {Generative artificial intelligence, HVSAE, Personalized education, Self-attention mechanism, VAE},
location = {
},
series = {ICAIE '24}
}

@article{10.5555/3648699.3649055,
author = {Pillutla, Krishna and Liu, Lang and Thickstun, John and Welleck, Sean and Swayamdipta, Swabha and Zellers, Rowan and Oh, Sewoong and Choi, Yejin and Harchaoui, Zaid},
title = {MAUVE scores for generative models: theory and practice},
year = {2023},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {Generative artificial intelligence has made significant strides, producing text indistinguishable from human prose and remarkably photorealistic images. Automatically measuring how close the generated data distribution is to the target distribution is central to diagnosing existing models and developing better ones. We present MAUVE, a family of comparison measures between pairs of distributions such as those encountered in the generative modeling of text or images. These scores are statistical summaries of divergence frontiers capturing two types of errors in generative modeling. We explore three approaches to statistically estimate these scores: vector quantization, non-parametric estimation, and classifier-based estimation. We provide statistical bounds for the vector quantization approach.Empirically, we find that the proposed scores paired with a range of f-divergences and statistical estimation methods can quantify the gaps between the distributions of humanwritten text and those of modern neural language models by correlating with human judgments and identifying known properties of the generated texts. We demonstrate in the vision domain that MAUVE can identify known properties of generated images on par with or better than existing metrics. In conclusion, we present practical recommendations for using MAUVE effectively with language and image modalities.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {356},
numpages = {92},
keywords = {generative models, evaluation, divergence frontiers, neural text generation, large language models, f-divergences, statistical estimation}
}

@inproceedings{10.1145/3706468.3706520,
author = {Albuquerque, Josmario and Rienties, Bart and Divjak, Bla\v{z}enka},
title = {Decoding Learning Design Decisions: A Cluster Analysis of 12,749 Teaching and Learning Activities},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706520},
doi = {10.1145/3706468.3706520},
abstract = {Substantial progress has been made in how educators can be supported to implement effective learning design (LD) with learning analytics (LA). However, how educators make micro-decisions about designing individual teaching and learning activities (TLAs) and how these are related to wider pedagogical approaches has received limited empirical support. This study explored how 165 educators designed and integrated 12,749 TLA in 218 LDs using clustering, pattern-mining, and correlational analysis. The findings suggest most educators use a combination of four common LD TLAs (i.e., Collaboration, Generating independent learning, Assessment, and Traditional classroom activities). The four common TLAs could be used to develop LA and Generative Artificial Intelligence (Gen-AI) approaches to support educators in making more informed and evidence-based design decisions for effective learning and teaching.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {407–417},
numpages = {11},
keywords = {Learning Design, Learning Analytics, Cluster Analysis, Teaching and Learning Activities, Artificial Intelligence},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3702652.3744219,
author = {Shihab, Md Istiak Hossain and Hundhausen, Christopher and Tariq, Ahsun and Haque, Summit and Qiao, Yunhan and Mulanda, Brian Wise},
title = {The Effects of GitHub Copilot on Computing Students' Programming Effectiveness, Efficiency, and Processes in Brownfield Coding Tasks},
year = {2025},
isbn = {9798400713408},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702652.3744219},
doi = {10.1145/3702652.3744219},
abstract = {When graduates of computing degree programs enter the software industry, they will most likely join teams working on legacy code bases developed by people other than themselves. In these so-called brownfield software development settings, generative artificial intelligence (GenAI) coding assistants like GitHub Copilot are rapidly transforming software development practices, yet the impact of GenAI on student programmers performing brownfield development tasks remains underexplored. This paper investigates how GitHub Copilot influences undergraduate students’ programming performance, behaviors, and understanding when completing brownfield programming tasks in which they add new code to an unfamiliar code base. We conducted a controlled experiment in which 10 undergraduate computer science students completed highly similar brownfield development tasks with and without Copilot in a legacy web application. Using a mixed-methods approach combining performance analysis, behavioral analysis, and exit interviews, we found that students completed tasks 34.9\% faster (p &lt; 0.05) and made 50.0\% more solution progress (p &lt; 0.05) when using Copilot. Moreover, our analysis revealed that, when using Copilot, students spent 10.6\% less time manually writing code (p &lt; 0.05), and 11.6\% less time conducting web searches (p &lt; 0.05), providing evidence of a fundamental shift in how they engaged in programming. In exit interviews, students reported concerns about not understanding how or why Copilot suggestions work. This research suggests the need for computing educators to develop new pedagogical approaches that leverage GenAI assistants’ benefits while fostering reflection on how and why GenAI suggestions address brownfield programming tasks. Complete study results and analysis are presented at ghcopilot-icer.github.io.},
booktitle = {Proceedings of the 2025 ACM Conference on International Computing Education Research V.1},
pages = {407–420},
numpages = {14},
keywords = {GitHub Copilot, AI-assisted programming, brownfield software development, legacy code, software engineering education, undergraduate programming, large language models, Generative AI code assistants, empirical studies of programming},
location = {
},
series = {ICER '25}
}

@inproceedings{10.1145/3664647.3688985,
author = {Wang, Yifan and Wu, Xuecheng and Zhang, Jia and Jing, Mohan and Lu, Keda and Yu, Jun and Su, Wen and Gao, Fang and Liu, Qingsong and Sun, Jianqing and Liang, Jiaen},
title = {Building Robust Video-Level Deepfake Detection via Audio-Visual Local-Global Interactions},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3688985},
doi = {10.1145/3664647.3688985},
abstract = {The continual advancements in Generative Artificial Intelligence have created substantial hurdles for accurate deepfake detection, leading to limitations of currently popular detection methods across content-driven video-level deepfake detection scenarios. In this paper, we present the solutions to the Video-Level Deepfake Detection task. Our empirical findings demonstrate that modeling correlations of audio-visual modalities is important for video-level deepfake detection. Therefore, we introduce the model denoted Audio-Visual Local-Global Neural Network (i.e., AV-LGNN) in which the core design is the proposed AV-LGI Module (Audio-Visual Local-Global Interaction Module). The AV-LGI Module is composed of three stages: Local Intra-Region Interaction, Global Inter-Region Interaction, and Local-Global Interaction, which can better capture detailed information at local-level and efficiently learn the fine-grained correlations of inter-modalities in video deepfake detection under lower computational overheads. We further propose an adaptive modality selection strategy to facilitate model learning. Besides, a variety of data augmentation techniques are incorporated for audio-visual branches to enhance the robustness of the AV-LGNN. The experimental results verify the effectiveness of our model.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {11370–11376},
numpages = {7},
keywords = {audio-viusal learning, deepfake detection, feature interactions},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3613905.3636272,
author = {Nacke, Lennart E.},
title = {How to Write Better CHI Papers (with AI)},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636272},
doi = {10.1145/3613905.3636272},
abstract = {Writing and organizing research papers is a valuable skill that can make or break your academic career. Generative artificial intelligence (AI) tools offer unprecedented opportunities for researchers to improve their skills in writing research papers and conducting literature reviews. In the past six years, my writing course has introduced you to everything you wanted to know about writing papers. However, with the arrival of generative AI, our writing process is changing. So, now I offer the opportunity to learn how to leverage generative AI tools to edit your writing, brainstorm, and help you find citations, so that your papers are easy to read and have impact. It is broken up into three 75-minute online units that will help you structure your paper’s research content and use generative AI as assistive research technology. The goal of the course is to learn how to leverage generative AI to help you write a paper that makes a contribution to the field of human-computer interaction and can be understood by other HCI researchers facilitated by the use of generative AI tools.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {599},
numpages = {4},
keywords = {Clarity, LaTeX, Research Methods, Submission Process, Writing},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3664934.3664955,
author = {Baldoni, Matteo and Baroglio, Cristina and Bucciarelli, Monica and Micalizio, Roberto and Gandolfi, Elena and Iani, Francesco and Marengo, Elisa and Capecchi, Sara},
title = {Thinking Strategies Training to Support the Development of Machine Learning Understanding. A study targeting fifth-grade children},
year = {2024},
isbn = {9798400716409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664934.3664955},
doi = {10.1145/3664934.3664955},
abstract = {Artificial Intelligence applications permeate our lives and are increasingly making the news, surprising society with applications that until a few years ago would have been relegated to the science fiction genre. Thanks to generative artificial intelligence, tools that once could only be used by highly qualified technical personnel are now in the hands of potentially inexperienced users, but unfortunately, the understanding of the layman is very far from the machinery behind the scenes. More than ever, it is necessary to help people develop an awareness that allows them to use these tools in an appropriate way and with the appropriate expectations. We believe this problem should be addressed by exploring ways to train thinking strategies to facilitate understanding of machine learning concepts that can be applied in daily life, not just by developing teaching tools on this or that topic. We describe our current activities with 9-10 years old children attending primary school and the ad hoc unplugged training we have developed to foster an understanding of machine learning mechanisms.},
booktitle = {Proceedings of the 2024 9th International Conference on Information and Education Innovations},
pages = {85–92},
numpages = {8},
keywords = {Artificial Intelligence, Education, Machine Learning, Thinking strategies, Training},
location = {Verbania, Italy},
series = {ICIEI '24}
}

@inproceedings{10.1145/3749566.3749602,
author = {Yan, Xun and Lu, Beier},
title = {Cultural Relic IP Generation Based On Structured Prompt And Hybrid Verification Methods},
year = {2025},
isbn = {9798400713927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3749566.3749602},
doi = {10.1145/3749566.3749602},
abstract = {Aiming at the high threshold and cultural distortion faced by generative artificial intelligence technology in cultural heritage digitization, this paper proposes a cross-modal generation framework without programming environment, and realizes the high-fidelity generation and dissemination optimization of cultural heritage IP image through structured prompt and hybrid verification mechanism. This research method builds a three-level symbol control system based on cultural semiotics theory. MidJourney collaborates with large-scale language models to transform cultural relics features into structured prompt, and combines cross-modal narration to ensure historical logic consistency. Through social media A/B testing, the communication efficiency of the generated IP is significantly higher than that of traditional manual design, and the reference rate of cultural keywords is significantly improved, which promotes the innovative communication of cultural heritage among young groups, and provides a theoretical paradigm and practical reference in the interdisciplinary application field of AIGC.},
booktitle = {Proceedings of the 2025 5th International Conference on Internet of Things and Machine Learning},
pages = {161–165},
numpages = {5},
keywords = {AIGC, Hybrid verification, Image processing},
location = {
},
series = {IoTML '25}
}

@inproceedings{10.1145/3629606.3629675,
author = {He, Qingyang and Zheng, Weicheng and Bao, Hanxi and Chen, Ruiqi and Tong, Xin},
title = {Exploring Designers’ Perceptions and Practices of Collaborating with Generative AI as a Co-creative Agent in a Multi-stakeholder Design Process: Take the Domain of Avatar Design as an Example},
year = {2024},
isbn = {9798400716454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629606.3629675},
doi = {10.1145/3629606.3629675},
abstract = {Nowadays, the traditional workflow of designers’ completing complicated design tasks has undergone a profound transformation due to the pervasive intervention of generative artificial intelligence (AI) tools, especially when multi-stakeholder participation is getting involved in the design process. Yet we know little about the designers’ perceptions and practices of collaborating with generative AI as a co-creative agent within the context of multi-stakeholder participation. To investigate these questions, we took the domain of avatar design as an example and conducted a qualitative interview study with 21 expert avatar designers who have got different levels of experience and expertise in utilizing generative AI tools in their design workflow. We found that designers not only would fall in a dilemma when deciding whether to consider AI as a co-creative agent according to different stakeholders’ interests, but they also face many challenges in effectively co-creating with the current systems, including challenges in consistently adjusting AI outputs and getting design inspiration within the iterative generation process, etc. Based on our findings, we concluded both the epistemological and creative patterns of collaborating with generative AI and highlighted several design opportunities from both technical and ethical perspectives to better support future designer-AI co-creation.},
booktitle = {Proceedings of the Eleventh International Symposium of Chinese CHI},
pages = {596–613},
numpages = {18},
keywords = {AI-assisted Design, Avatar Design, Co-creation Experience, Generative AI, Human-AI Collaboration, Stakeholder Identification},
location = {Denpasar, Bali, Indonesia},
series = {CHCHI '23}
}

@inproceedings{10.1145/3689217.3690616,
author = {Chernyshev, Maxim and Baig, Zubair and Doss, Robin Ram Mohan},
title = {Towards Large Language Model (LLM) Forensics Using LLM-based Invocation Log Analysis},
year = {2024},
isbn = {9798400712098},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689217.3690616},
doi = {10.1145/3689217.3690616},
abstract = {Large Language Models (LLMs) have fostered the emergence of software application architectures that improve user experiences powered by generative artificial intelligence. A range of cyber attacks are possible against an LLM. A novel approach to digital forensic analysis of LLM-integrated applications is presented for prompt injection attacks. The forensic analysis process is invoked through LLM log analysis. We propose LLM invocation logging as a critical component for enhancing digital forensic readiness in LLM-integrated applications and evaluate 13 state-of-the-art LLMs for this analysis task. Our findings demonstrate the potential utility of selected LLMs in the context of prompt-to-SQL attacks, influenced by sampling temperature and context window size parameters. We also identify limitations of our work and propose key areas for future research, for ongoing contribution to the emerging field of LLM forensics.},
booktitle = {Proceedings of the 1st ACM Workshop on Large AI Systems and Models with Privacy and Safety Analysis},
pages = {89–96},
numpages = {8},
keywords = {digital forensics, large language model (llm), llm-integrated applications, log analysis},
location = {Salt Lake City, UT, USA},
series = {LAMPS '24}
}

@inproceedings{10.1145/3690624.3709401,
author = {Jin, Zhipeng and Tao, Wen and Li, Yafei and Yang, Yi and Han, Cong and Li, Shuanglong and Liu, Lin},
title = {Large Vison-Language Foundation Model in Baidu AIGC Image Advertising},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709401},
doi = {10.1145/3690624.3709401},
abstract = {Recent advances in generative artificial intelligence have revolutionized information retrieval and content generation, opening up new opportunities for the e-commerce industry. Alignment learning between small models and parallel corpora cannot meet current needs. The success of ChatGPT demonstrates that large models need to first establish a fundamental understanding, and then utilize high-quality corpora for generation. Having a large model foundation is indispensable. In this paper, we establish a fundamental 10B multimodal model foundation for multimodal generation tasks and propose a scene-based alignment learning approach called conditional sample supervised fine-tuning for downstream generation tasks. Meanwhile, diffusion models are known to be vulnerable to outliers in training data. To address this, we utilize an alternative diffusion loss function that preserves the high quality of generated data like the original squared L2 loss while being robust to outliers.In practical test sets, the multimodal foundation fully demonstrates its alignment and comprehension abilities for graphic and textual content. Additionally, conditional fine-tuning and the design of the loss function significantly enhance the quality of generated content. The quality rate of images has increased by 34.3 percentage points, and prompt control has improved by 19.8 percentage points. The application of our framework in Baidu Search Ads has led to significant revenue growth. For instance, ads with generated image creatives have achieved a 29\% higher click-through rate (CTR), resulting in a daily consumption of 3 million yuan.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {2303–2312},
numpages = {10},
keywords = {advertisement image creatives, cross-modal retrieval, multimodal sponsored search, text-to-image generation},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@article{10.1145/3736765,
author = {Li, Xiang and Chen, Pin-Yu and Wei, Wenqi},
title = {Where are We in Audio Deepfake Detection? A Systematic Analysis over Generative and Detection Models},
year = {2025},
issue_date = {August 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {3},
issn = {1533-5399},
url = {https://doi.org/10.1145/3736765},
doi = {10.1145/3736765},
abstract = {Recent advances in Text-to-Speech (TTS) and Voice-Conversion (VC) using generative Artificial Intelligence (AI) technology have made it possible to generate high-quality and realistic human-like audio. This introduces significant challenges to distinguishing AI-synthesized speech from the authentic human voice and could raise potential issues of misuse for malicious purposes such as impersonation and fraud, spreading misinformation, deepfakes, and scams. However, existing detection techniques for AI-synthesized audio have not kept pace and often exhibit poor generalization across diverse datasets. In this article, we introduce SONAR, a synthetic AI-Audio Detection Framework and Benchmark, aiming at providing a comprehensive evaluation for distinguishing cutting-edge AI-synthesized auditory content. SONAR includes a novel evaluation dataset sourced from 9 diverse audio synthesis platforms, including leading TTS providers and state-of-the-art TTS models. It is the first framework to uniformly benchmark AI-audio detection across both traditional and foundation model-based deepfake detection systems. Through extensive experiments, (1) we reveal the generalization limitations of existing detection methods and demonstrate that foundation models exhibit stronger generalization capabilities, which can be attributed to their model size and the scale and quality of pretraining data. (2) Our evaluation of the generalization across languages suggests that speech foundation models demonstrate robust cross-lingual generalization capabilities, maintaining strong performance across diverse languages despite being fine-tuned solely on English speech data. This finding also suggests that the primary challenges in audio deepfake detection are more closely tied to the realism and quality of synthetic audio rather than language-specific characteristics. (3) We also explore the effectiveness and efficiency of few-shot fine-tuning in improving generalization, highlighting its potential for tailored applications, such as personalized detection systems for specific entities or individuals. Code and dataset are available at .},
journal = {ACM Trans. Internet Technol.},
month = aug,
articleno = {20},
numpages = {19},
keywords = {Audio, deepfake detection, benchmark framework}
}

@inproceedings{10.1145/3756580.3756590,
author = {Zhang, Jianing and Ma, Yanli and Zhang, Lichen and Wang, Zhengchao},
title = {Research and Application of Big Model Interactive Assisted Teaching in Big Data Specialization},
year = {2025},
isbn = {9798400715624},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3756580.3756590},
doi = {10.1145/3756580.3756590},
abstract = {With the accelerated development of generative artificial intelligence, the application of large models in education has gradually attracted attention. This paper combines the practical experience of the authors in the two courses, "Principles and Applications of Database" and "Data Warehouse HIVE", and explores the interactive teaching method based on large models for the big data major. New teaching strategies were designed through the Dify and DeepSeek platforms. By using personalized learning content recommendations and real-time feedback mechanisms, the large models deployed locally were fine-tuned to meet the teaching requirements. Significantly enhance students' enthusiasm and participation. Experimental research spanning two semesters (2024-2025) indicates that the proposed future teaching strategy utilizing large models has improved students' academic performance and contributed to the teaching reform of computer science.},
booktitle = {Proceedings of the 2025 6th International Conference on Education, Knowledge and Information Management},
pages = {58–64},
numpages = {7},
keywords = {Big Data Specialization, Big Models, Interactive Supplemental Instruction, Teaching effect evaluation},
location = {
},
series = {ICEKIM '25}
}

@inproceedings{10.1145/3678698.3687210,
author = {Kroma, Assem},
title = {Invisibles: Collection of Artificial Intelligence Generated Shorts},
year = {2024},
isbn = {9798400709678},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678698.3687210},
doi = {10.1145/3678698.3687210},
abstract = {"Invisibles" is a thought-provoking collection of short films that explores societal invisibility by highlighting overlooked minorities, hidden disabilities, and unacknowledged suffering. Drawing on Erving Goffman’s social stigma theories, these films employ AI-generated media —including spoken word poetry, images, video, and music— to give voice to marginalized groups. The narrative is uniquely enhanced by the expected glitches of AI technology, creating a distinctive and immersive storytelling experience. Optimized for conference presentations, "Invisibles" not only showcases the innovative capabilities of AI in film production but also invites viewers to reflect on the often-unseen struggles within society.},
booktitle = {Proceedings of the 17th International Symposium on Visual Information Communication and Interaction},
articleno = {55},
numpages = {2},
keywords = {Post cinema, future cinema, expanded cinema, generative artificial intelligence, artificial intelligence generated films, deepfakes},
location = {
},
series = {VINCI '24}
}

@inproceedings{10.1145/3698061.3734397,
author = {Elise Bruen, Jacqueline and Jeon, Myounghoon},
title = {AI-Supported Dance Performances Provoke Audiences to Seek Creative Merit and Meaning in AI's Artistic Decisions},
year = {2025},
isbn = {9798400712890},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698061.3734397},
doi = {10.1145/3698061.3734397},
abstract = {With the development of tools using generative artificial intelligence (GenAI) to create art, stakeholders cannot come to an agreement on the value of these works. In this study we uncovered the mixed opinions surrounding art made by AI.We developed two versions of a dance performance augmented by technology either with or without GenAI. For each version we informed audiences of how the performance was developed either before or after they had taken a survey on their perceptions of the performance. There were thirty-nine participants (13 males, 26 female) recruited and divided between the four performances. After the survey, we conducted focus groups with a subset of audience members. Results demonstrated that individuals were more inclined to attribute artistic merit to works made by GenAI when they were unaware its use. Our work contributes to the understanding of the design and reception of AI-made art.},
booktitle = {Proceedings of the 2025 Conference on Creativity and Cognition},
pages = {423–430},
numpages = {8},
keywords = {Generative AI, Live Performance, Technology in Arts},
location = {
},
series = {C&amp;C '25}
}

@inproceedings{10.1145/3706598.3713365,
author = {Santana, Vagner Figueredo de and Berger, Sara E and Candello, Heloisa and Machado, Tiago and Sanctos, Cassia Sampaio and Su, Tianyu and Williams, Lemara},
title = {Responsible Prompting Recommendation: Fostering Responsible AI Practices in Prompting-Time},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713365},
doi = {10.1145/3706598.3713365},
abstract = {Human-Computer Interaction practitioners have been proposing best practices in user interface design for decades. However, generative Artificial Intelligence (GenAI) brings additional design considerations and currently lacks sufficient user guidance regarding affordances, inputs, and outputs. In this context, we developed a recommender system to promote responsible AI (RAI) practices while people prompt GenAI systems. We detail 10 interviews with IT professionals, the resulting recommender system developed, and 20 user sessions with IT professionals interacting with our prompt recommendations. Results indicate that responsible prompting recommendations have the potential to support novice prompt engineers and raise awareness about RAI in prompting-time. They also suggest that recommendations should simultaneously maximize both a prompt’s similarity to a user’s input as well as a diversity of associated social values provided. These findings contribute to RAI by offering practical ways to provide user guidance and enrich human-GenAI interaction via prompt recommendations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {836},
numpages = {30},
keywords = {Prompt Engineering, Human-AI Interaction, Responsible Computing, Responsible AI, Responsible Prompting, Recommender Systems, Proactive Value Alignment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3630106.3659012,
author = {Orr, Will and Kang, Edward B.},
title = {AI as a Sport: On the Competitive Epistemologies of Benchmarking},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3659012},
doi = {10.1145/3630106.3659012},
abstract = {Artificial Intelligence (AI) systems are evaluated using competitive methods that rely on benchmark datasets to determine performance. These benchmark datasets, however, are often constructed through arbitrary processes that fall short in encapsulating the depth and breadth of the tasks they are intended to measure. In this paper, we interrogate the naturalization of benchmark datasets as veracious metrics by examining the historical development of benchmarking as an epistemic practice in AI research. Specifically, we highlight three key case studies that were crucial in establishing the existing reliance on benchmark datasets for evaluating the capabilities of AI systems: (1) the sharing of Highleyman’s OCR dataset in the 1960s, which solidified a community of knowledge production around a shared benchmark dataset, (2) the Common Task Framework (CTF) of the 1980s, a state-led project to standardize benchmark datasets as legitimate indicators of technical progress; and (3) the Netflix Prize which further solidified benchmarking as a competitive goal within the ML research community. This genealogy highlights how contemporary dynamics and limitations of benchmarking developed from a longer history of collaboration, standardization, and competition. We end with reflections on how this history informs our understanding of benchmarking in the current era of generative artificial intelligence.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1875–1884},
numpages = {10},
keywords = {Benchmark datasets., Benchmarking for generative AI, History of benchmarking, Machine learning benchmarks, Machine learning competitions},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.5555/3539845.3540111,
author = {Mirka, Maxime and France-Pillois, Maxime and Sassatelli, Gilles and Gamati\'{e}, Abdoulaye},
title = {A generative AI for heterogeneous network-on-chip design space pruning},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Often suffering from under-optimization, Networks-on-Chip (NoCs) heavily impact the efficiency of domain-specific Systems-on-Chip. To cope with this issue, heterogeneous NoCs are promising alternatives. Nevertheless, the design of optimized NoCs satisfying multiple performance objectives is extremely challenging and requires significant expertise. Prior works failed to combine many objectives or required an extended design space exploration time. In this paper, we propose an approach based on generative artificial intelligence to help pruning complex design spaces for heterogeneous NoCs, according to configurable performance objectives. This is made possible by the ability of Generative Adversarial Networks to learn and generate relevant design candidates for the target NoCs. The speed and flexibility of our solution enable a fast generation of optimized NoCs that fit users' expectations. Through some experiments, we show how to obtain competitive NoC designs reducing the power consumption with no communication performance or area penalty compared to a given conventional NoC design.},
booktitle = {Proceedings of the 2022 Conference \&amp; Exhibition on Design, Automation \&amp; Test in Europe},
pages = {1135–1138},
numpages = {4},
keywords = {CAD, DSSoC, generative adversarial network, heterogeneous, machine learning, network-on-chip},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.1145/3750069.3750090,
author = {Al-Othmani, Rhied and de Vries, Roelof},
title = {Trust in Trust: a Scoping Review on Trust and Conversational Agent Design},
year = {2025},
isbn = {9798400721021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3750069.3750090},
doi = {10.1145/3750069.3750090},
abstract = {Rapid progression in generative artificial intelligence technology facilitates faster and easier conversational agent design. However, deploying conversational agents is challenging and can easily have adverse effects. To this end, more conceptual clarity on how to design for, for example, trust, in conversational agents is needed. Ideally, using theories could provide conceptual clarity and guide and ground conversational agents designed for trust. We conducted a scoping review on how systematically trust is being designed for in conversational agents. The review shows that although the conversational agent work is well grounded, the variation in referential theories used, manipulations chosen, and measures used is high. Moreover, the relation between these dimensions is not always explicitly explained. This hinders the abstraction of more generalizable research findings. We conclude with the suggestion for the development of more intermediate levels of knowledge in the context of designing for trust in conversational agents.},
booktitle = {Proceedings of the 16th Biannual Conference of the Italian SIGCHI Chapter},
articleno = {58},
numpages = {6},
keywords = {Conversational Agents, Trust, Design, Scoping Review},
location = {
},
series = {CHItaly '25}
}

@inproceedings{10.1145/3613905.3647966,
author = {Lim, Jullia},
title = {The Potential of Learning With AI-Generated Pedagogical Agents in Instructional Videos},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3647966},
doi = {10.1145/3613905.3647966},
abstract = {With the recent advancement in technology, generative artificial intelligence (GenAI) can produce hyper-realistic multimedia content, such as audio, text, images, and videos. Although this technology has raised great concerns about its misuse and harmful applications, it holds great potential to revolutionize traditional ways of teaching and learning. The use of GenAI in education has increased markedly, however, pedagogical research on this rapidly emerging technology is yet to be studied extensively. There is an urgent need to investigate the unexamined potential of this technology. Therefore, this ongoing research will explore the potential of AI-generated pedagogical agents (PA), or avatars, in instructional videos to facilitate learning. The effects of the type of PA (AI-generated, real-life human), and voice (AI-generated, human voice) on an individual's learning outcomes, cognitive load, motivation, and attention will be studied. Findings from a pilot study provide some preliminary evidence that PA appearance influences learners’ retention and cognitive load, but not attention. The type of PA influenced learners' perception of the agent's ability to facilitate learning, its human-like qualities, and its engagement level. However, it did not affect its credibility. This ongoing work will contribute to the growing understanding of the impact of AI in education, provide evidence of the efficacy of AI-generated PAs in instructional videos for learning, and narrow the gap between human-computer interaction research and education.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {615},
numpages = {6},
keywords = {avatars, multimedia learning, pedagogical agents, videos},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3715275.3732027,
author = {Valdivia, Ana},
title = {Data Ecofeminism},
year = {2025},
isbn = {9798400714825},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715275.3732027},
doi = {10.1145/3715275.3732027},
abstract = {Generative Artificial Intelligence (GenAI) is driving significant environmental impacts. The rapid development and deployment of larger algorithmic models consumes substantially more energy than traditional models, contributing to rising carbon emissions, water withdrawal, and e-waste generation. To mitigate these impacts, big tech companies are developing different strategies such as turning to nuclear energy to meet the demand for GenAI electricity and avoid carbon emissions, an approach that could have profound social and environmental implications beyond carbon reduction.This paper proposes a critical rethinking of GenAI’s proliferation through an ecofeminist framing, which has historically interrogated the role of science and technology in the context of gender and environmental justice. To do so, it introduces seven data ecofeminist principles delineating a pathway for developing technological and just transition alternatives within the AI research context, emphasising a critical examination of this technology’s role in the current socio-ecological crisis. The paper calls for an urgent reassessment of the GenAI innovation race, advocating for ecological and feminist technological projects that prioritise and respect life, people, and the planet.},
booktitle = {Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency},
pages = {391–403},
numpages = {13},
keywords = {Ecofeminism, Artificial Intelligence, Sustainability, Critical Data Studies, Data Feminism},
location = {
},
series = {FAccT '25}
}

@inproceedings{10.1145/3629606.3629625,
author = {Liu, Xi and Lau, Newman and Chuin, Alex and Leung, Wun Kam Reginia and Ho, Ada How Sim and Das, Mohana and Liu, Mengru and Kwok, Cheuk Lam},
title = {Understanding Students’ Perspectives, Practices, and Challenges of Designing with AI in Special Schools},
year = {2024},
isbn = {9798400716454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629606.3629625},
doi = {10.1145/3629606.3629625},
abstract = {As generative artificial intelligence (GenAI) develops rapidly, equipping students with basic knowledge of GenAI at the secondary school level is beneficial. However, few subjects in special schools cover AI-related topics, and it remains unclear how students with special educational needs (SEN) perceive, learn, and use AI. In this study, we documented the Artificial Intelligence Generated Content (AIGC) learning experience of seven students from two special schools who participated in a series of game design workshops. We analysed their learning process, usage, and perspectives of text-to-image GenAI through video analysis, questionnaire, and evaluation of design outputs. Our findings reveal the students' willingness to learn and utilise AI technology. This AI experience allows students, especially those who struggle with fine motor skills, to translate their ideas into digital images. Moreover, the text-to-image interaction enhances students' ability to convey their ideas in writing and develop their skills in conceptualisation. We also summarised significant human-AI interaction challenges, including difficulties with typing, Chinese and English spelling, and prompt writing. We conclude with recommendations for designing future inclusive human-AI interaction experiences for students with SEN in China.},
booktitle = {Proceedings of the Eleventh International Symposium of Chinese CHI},
pages = {197–209},
numpages = {13},
keywords = {Artificial Intelligence Generated Content (AIGC), Children with Special Educational Needs (SEN), Design-based Learning Activities, Human-AI Interaction, User Experience},
location = {Denpasar, Bali, Indonesia},
series = {CHCHI '23}
}

@article{10.5555/3665464.3665471,
author = {Mouli, Chandra and Kotteti, Madhav and Lal, Ratan and Chetti, Prasad},
title = {Coding Integrity Unveiled: Exploring the Pros and Cons of Detecting Plagiarism in Programming Assignments Using Copyleaks},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {Before the advent of generative Artificial Intelligence (AI) tools, for example, ChatGPT, students traditionally approached assignment development authentically by employing libraries and by referring to textbooks. However, with the widespread reliance on powerful AI tools for assignment completion, the process has become more convenient. Unfortunately, this ease of use has led to a potential detriment in students' genuine understanding of subjects, as well as a decline in their problem-solving and innovative thinking skills. Moreover, AI tools like ChatGPT will evolve as technology advances such that the need to detect AI-generated content is even more crucial in educational setting to reinforce the value of original work [5]. This paper aims to address this issue by focusing on the detection of plagiarism in student assignments through the utilization of the Copyleaks1 tool, specifically designed to identify AI-generated code. The accuracy of the tool is systematically evaluated by submitting various pairs of codes, each with similar functionality, wherein one is generated by AI and the other by humans.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {61–69},
numpages = {9}
}

@inproceedings{10.1145/3721239.3734125,
author = {Bigeault, Julien and Karimpour-Harvey, Nelly Roxane and Tozier, Conner and Doyon-Lacroix, Alexis},
title = {GenAI and Immersive Theater - Moment Factory x Third Rail Projects},
year = {2025},
isbn = {9798400715419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721239.3734125},
doi = {10.1145/3721239.3734125},
abstract = {This research explores the integration of Generative Artificial Intelligence (GenAI) into immersive, site-specific theater through a collaborative initiative between Moment Factory and Third Rail Projects. The objective was to investigate how GenAI technologies can augment dramaturgical practices by enabling co-creation among authors, performers, and audience members.Using an iterative research-creation methodology, the project unfolded in two phases: a remote prototyping cycle and an on-site laboratory. Across three use cases: generative scenography, physical space extension, and improvised narration—AI tools were integrated into live performance contexts to dynamically respond to human presence and input. Techniques included the use of real-time generative visuals, silhouette-based transformations, and voice-activated storytelling systems.The findings highlight both the creative opportunities and technical constraints of employing GenAI in live performance. Critical insights emerged around timing, audience perception, system orchestration, and the need for adaptable, artist-centric AI workflows. This study emphasizes the potential of GenAI to function not merely as a technical instrument, but as a dramaturgical collaborator in the creation of emotionally resonant, participatory experiences.},
booktitle = {Proceedings of the Special Interest Group on Computer Graphics and Interactive Techniques Conference Talks},
articleno = {44},
numpages = {2},
keywords = {AI, Art, Immersive Theater, Design, Generative AI, Interactive, Human performance},
location = {
},
series = {SIGGRAPH Talks '25}
}

@inproceedings{10.1145/3613905.3636268,
author = {Santana, Vagner Figueredo De},
title = {Challenges and Opportunities for Responsible Prompting},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636268},
doi = {10.1145/3613905.3636268},
abstract = {Generative Artificial Intelligence (GenAI) such as ChatGPT and Midjourney have garnered significant attention recently. However, responsible practices while interacting with these systems often go overlooked. This course explores the integration of responsible practices with prompt engineering. It examines key prompt engineering concepts, dissects common prompt structures, addresses some productivity misconceptions on using GenAI, underscores the enduring significance of domain knowledge, and explores their application in emerging GenAI-powered systems.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {592},
numpages = {4},
keywords = {Prompt Engineering, Prompting, Responsible AI, Responsible Computing, Responsible Technology, Trustworthy AI},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inbook{10.1145/3718491.3718662,
author = {Wei, Xueling and Lin, Tao},
title = {Binary Choice Probit Model for Enterprise Management Decision-making System Based on Artificial Intelligence Generated Content},
year = {2025},
isbn = {9798400710865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3718491.3718662},
abstract = {From the perspective of high-quality and efficient intelligent problem solving in business decision-making, a artificial intelligence generated content solution is proposed. In order to solve this problem, a Artificial Intelligence Generated Content binary choice Probit model is used. The solution proposes feature engineering, model assumptions, variable selection, feedback iteration, and security and compliance technical methods to effectively solve the business decision-making process. A business decision data simulation experiment was conducted by using this model. Compared with the general decision-making system without Artificial Intelligence Generated Content, the reference data volume of this business decision-making system increased by 86.63 times, and the decision efficiency increased by 51.21\%. The experimental values are key indicators such as return on equity and market value. The results show that this technical method has high accuracy and practical value in evaluating the stability of corporate business decisions and predicting debt repayment capability.},
booktitle = {Proceedings of the 4th Asia-Pacific Artificial Intelligence and Big Data Forum},
pages = {1059–1063},
numpages = {5}
}

@inproceedings{10.1145/3637907.3637988,
author = {Guo, Xue and He, Xiangchun and Pei, Zhuoyun},
title = {Data-driven Personalized Learning},
year = {2024},
isbn = {9798400716676},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637907.3637988},
doi = {10.1145/3637907.3637988},
abstract = {With the continuous development of big data, artificial intelligence and other technologies, education is becoming more and more intelligent, personalized and accurate, accelerating the process of education modernization in China. On the basis of analyzing the connotation of data-driven and personalized learning, this paper sorts out the main research aspects of data-driven personalized learning at present, and proposes a data-driven personalized learning mechanism from four aspects of data-driven. Through data collection, data modeling, data analysis and data feedback, data collection of learners is completed, characteristics of learners are analyzed, and digital portraits are formed. chatGPT and other generative artificial intelligence are used to provide accurate personalized services for learners and promote the personalized development of learners. Research shows that data-driven personalized learning is more scientific, precise, intelligent and diversified.},
booktitle = {Proceedings of the 2023 6th International Conference on Educational Technology Management},
pages = {49–54},
numpages = {6},
keywords = {Big data, Data-driven, Personalized learning},
location = {Guangzhou, China},
series = {ICETM '23}
}

@article{10.14778/3749646.3749650,
author = {Liu, Qiyu and Qi, Yanlin and Han, Siyuan and Peng, Jingshu and Li, Jin and Chen, Lei},
title = {Not Small Enough? SegPQ: A Learned Approach to Compress Product Quantization Codebooks},
year = {2025},
issue_date = {July 2025},
publisher = {VLDB Endowment},
volume = {18},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3749646.3749650},
doi = {10.14778/3749646.3749650},
abstract = {The rapid advancements of generative artificial intelligence (GenAI) have recently led to renewed attention towards approximate nearest neighbor (ANN) search and vector databases (VectorDB). Among various ANN methodologies, vector quantization techniques like product quantization (PQ) are widely used to generate space-efficient representations for large-scale dense vectors. However, the code-books generated by PQ often reach several gigabytes in size, making them impractical for web-scale, high-dimensional vectors in resource-constrained environments like mobile devices.In this study, we propose SegPQ, a simple yet effective framework for losslessly compressing codebooks generated by any PQ variants, enabling efficient in-memory vector search on devices with limited memory. SegPQ represents the raw PQ codewords as a trained error-bounded piecewise linear approximation model (ϵ-PLA) and pre-computed low-bit residuals. We theoretically demonstrate that, with high probability, the number of bits per compressed codeword is 1.721 + ⌈log2 ϵOPT⌉, where ϵOPT is the optimal error parameter that can be determined by data characteristics. To accelerate query execution, we further design SIMD-aware query processing algorithms on compressed codebooks to fully exploit the hardware parallelism offered by modern architectures. Extensive experimental studies on real datasets showcase that, for 1 billion vectors, SegPQ reduces PQ codebook memory consumption by up to 4.7x (approx. 851 MB) while incurring only 3.3\% additional query processing overhead caused by decompression.},
journal = {Proc. VLDB Endow.},
month = sep,
pages = {3730–3743},
numpages = {14}
}

@inproceedings{10.1145/3675812.3675871,
author = {Zhong, Xuanyan and Xin, Haiyang and Li, Wenfeng and Zhan, Zehui and Cheng, May-hung},
title = {The Design and application of RAG-based conversational agents for collaborative problem solving},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675871},
doi = {10.1145/3675812.3675871},
abstract = {Dialogue is the basis of collaborative problem solving, and the development of generative artificial intelligence has made dialogue no longer limited to human-to-human, and human-computer dialogue has gradually become an important way for people to solve problems. At the same time, with the change of the subject of collaborative problem solving, the cultivation of collaborative problem-solving skill urgently needs to explore a new path. In this regard, more and more studies have begun to apply conversational agents in collaborative problem-solving activities, digging deeper into the effects of time on students in conversational agents. However, there is no clear answer to the question of how conversational agents can be better integrated into a collaborative environment for all to assist people in the collaborative problem-solving process and improve performance. In this study, we constructed a conceptual model of human-computer collaboration in order to improve students' learning performance. Based on this model, we integrated Retrieval-Augmented Generative and GPT to construct a conversational agent, and the results of the study showed that the Retrieval-Augmented Generative Agent for Collaborative Problem Solving constructed in this study can effectively promote students' collaborative problem-solving performance.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {62–68},
numpages = {7},
keywords = {Collaborative problem solving, Conversational agent, GPT},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3706599.3719910,
author = {Lin, Weiyue and Hu, Xiao},
title = {GenAI-Supported Creative Learning in Digital Museum Education: A Case Study of Maritime Art Painting Creation},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719910},
doi = {10.1145/3706599.3719910},
abstract = {Creative learning has significantly enriched on-site museum education by fostering deeper engagement, encouraging exploration, and promoting active participation through hands-on experiences. However, the digital transformation of holistic and structured creative learning processes in museum education remains largely underexplored. Although Generative Artificial Intelligence (GenAI) holds promise for supporting creative learning, its full integration across all phases in non-formal education settings like museums remains limited. In this work, we designed Mariscope, a GenAI-supported creative learning platform for marine museum education. By integrating GenAI with the five stages of the iterative creative learning path, Mariscope offers a personalized and dynamic learning experience. A preliminary study with four participants demonstrated positive impacts on learning outcomes and creative self-efficacy, showcasing the platform’s potential for enhancing digital museum education through iterative and interactive creative learning processes.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {300},
numpages = {8},
keywords = {Museum education, Creative learning, AI in education, Human-AI co-creation},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706599.3706641,
author = {Nacke, Lennart E.},
title = {How to write higher-quality CHI papers (with AI research tools)},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706641},
doi = {10.1145/3706599.3706641},
abstract = {Writing high-quality research papers is crucial for advancing your academic career. With the advent of generative artificial intelligence (AI) tools, researchers now have novel ways to improve their writing, literature reviews, and overall paper quality. This course, delivered in person at CHI 2025 in Yokohama, Japan, offers a practical exploration of how to use AI tools effectively throughout the research writing process. Over three interactive 75-minute sessions, participants will learn to apply AI tools to edit their writing, brainstorm ideas, and enhance their paper’s readability and impact. Through hands-on activities and peer discussions, attendees will gain the skills needed to produce high-impact CHI papers that meet publication standards. This course emphasizes using AI to support writing, structuring research, and refining contributions, providing attendees with practical tools and insights to succeed in academic publishing in the field of Human-Computer Interaction.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {816},
numpages = {3},
keywords = {Generative AI, Writing, ChatGPT, Publication, Writing, Submission Process, Research Methods},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3642979.3642985,
author = {White, Ryen W.},
title = {Tasks, Copilots, and the Future of Search: A Keynote at SIGIR 2023},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3642979.3642985},
doi = {10.1145/3642979.3642985},
abstract = {Search is far from being a solved problem. While search engines may cope well with simple tasks, searchers and systems struggle as task complexity increases. Task is central to the search process, motivating the search and driving search behavior. Complex search tasks require more than support for rudimentary fact finding or re-finding. Various support options have been offered by search systems over time (e.g., query suggestions, contextual search) to help search engine users more effectively tackle complex tasks. The recent emergence of generative artificial intelligence (AI) and the arrival of assistive agents, or copilots, based on this technology, has the potential to offer further assistance to searchers, especially those engaged in complex tasks. The implications from these advances for the design of intelligent systems and for the future of search itself are significant. This overview of the keynote that I gave at the 2023 ACM SIGIR Conference introduces AI copilots and briefly presents some of the challenges and opportunities for researching, developing, and deploying search copilots.Date: 26 July 2023.},
journal = {SIGIR Forum},
month = jan,
articleno = {4},
numpages = {8}
}

