<div class="modal__dialog"><div class="modal__header"><button type="button" data-dismiss="modal" class="close"><i aria-hidden="true" aria-label="close popup" class="icon-close_thin"></i><span class="sr-only">Close modal</span></button><h2 id="exportCitationsPopup">Export Citations</h2></div><div class="modal__body"><div class="exportCitation__tabs"><div class="tab"><ul role="tablist" class="rlist tab__nav"><li role="presentation" class="active"><a id="selected" href="#selectedTab" aria-controls="selectedTab" role="tab" data-toggle="tab" title="Selected" aria-selected="true"><span>Selected</span></a></li><li role="presentation"><a id="allResults" href="#allResultstab" aria-controls="allResultstab" role="tab" data-toggle="tab" title="All Results" aria-selected="false"><span>All Results</span></a></li></ul></div><div class="csl-wrapper copy__text-wrapper"><form action="/action/exportCiteProcCitation" method="post" target="_blank"><input type="hidden" name="content" value="@inproceedings{10.1145/3626772.3657982,
author = {B\'{e}n\'{e}dict, Gabriel and Zhang, Ruqing and Metzler, Donald and Yates, Andrew and Jiang, Ziyan},
title = {Gen-IR @ SIGIR 2024: The Second Workshop on Generative Information Retrieval},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657982},
doi = {10.1145/3626772.3657982},
abstract = {Generative information retrieval (Gen-IR) is a fast-growing interdisciplinary research area that investigates how to leverage advances in generative Artificial Intelligence (AI) to improve information retrieval systems. Gen-IR has attracted interest from the information retrieval, natural language processing, and machine learning communities, among others. Since the dawn of Gen-IR last year, there has been an explosion of Gen-IR systems that have launched and are now widely used. Interest in this area across academia and industry is only expected to continue to grow as new research challenges and application opportunities arise. The goal of this proposed workshop, The Second Workshop on Generative Information Retrieval (Gen-IR @ SIGIR 2024) is to provide an interactive venue for exploring a broad range of foundational and applied Gen-IR research. The workshop will focus on tasks such as generative document retrieval, grounded answer generation, generative recommendation, and generative knowledge graphs, all through the lens of model training, model behavior, and broader issues. The workshop will be highly interactive, favoring panel discussions, poster sessions, and roundtable discussions over one-sided keynotes and paper talks.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3029–3032},
numpages = {4},
keywords = {generative models, information retrieval, large language models},
location = {Washington DC, USA},
series = {SIGIR '24}
}
  
@inproceedings{10.1145/3633083.3633094,
author = {Marassi, Lidia},
title = {Assessing User Perceptions of Bias in Generative AI Models: Promoting Social Awareness for Trustworthy AI},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633094},
doi = {10.1145/3633083.3633094},
abstract = {Recently, generative Artificial Intelligence (AI) models have experienced an incredible surge in interest and use. The proliferation of these technologies suggests that it would be prudent to raise awareness of the potential consequences of irresponsible use of these models. Indeed, to achieve trustworthy AI solutions, it is essential to promote AI education as a fundamental step. Educating people to use AI responsibly not only improves their understanding of the technology, but also equips them to address issues of bias and discrimination. Indeed, informed users are more likely to recognize when AI is producing biased or discriminatory results and to demand appropriate solutions. This awareness of the ethical implications of AI decisions is crucial for the responsible and socially conscious adoption of AI. The aim of this poster is to report the results obtained as a final thesis work, pursued within the context of the Human-Centred AI Masters (HCAIM) programme in Naples, focused on the analysis of users’ perceptions of biases in media created by generative AI models.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {46},
numpages = {1},
keywords = {AI Ethics, Bias, Generative AI, Social Awareness, Trustworthy AI},
location = {Dublin, Ireland},
series = {HCAIep '23}
}
  
@inproceedings{10.1145/3626253.3635543,
author = {Glynn, Colin and Hed, Emily and Pexa, Abbigail and Pohlmann, Tyler and Rahal, Imad and Hesse, Robert},
title = {CAET: Code Analysis and Education Tutor},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635543},
doi = {10.1145/3626253.3635543},
abstract = {The introduction of OpenAI's ChatGPT in 2022 kickstarted the release of Generative Artificial Intelligence (GAI) applications to the public domain. Such chat interfaces are based on large language models (LLMs) and possess a vast array of abilities spanning conversation, the writing and debugging of code, the writing of papers, and the creation of images, music, and songs. With students now having access to a myriad of GAI tools, academia has been permanently altered.Our proposed system, named Code Analysis and Education Tutor (CAET), integrates GAI into early Computer Science education by providing students with an ethical alternative to existing GAI tools. CAET is designed to assist students with programming tasks in a manner tailored to their individual needs without jeopardizing the integrity of their learning. A point of uniqueness from existing works is CAET's ability to display or hide generated code based on its pertinence to the problem at hand. After subjecting multiple GAI models to common programming errors and queries, we settled on OpenAI's GPT-3.5 Turbo model due to its comprehensive capabilities and cost-effectiveness. Overall, CAET underscored the model's conversational dynamics and provided insights for creating a more personalized learning experience for students in an introductory computer science course.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1656–1657},
numpages = {2},
keywords = {computer science education, generative artificial intelligence, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}
  
@inproceedings{10.1145/3660650.3660657,
author = {Roberts, Jordan and Mohamed, Abdallah},
title = {Generative AI in CS Education: Literature Review through a SWOT Lens},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660657},
doi = {10.1145/3660650.3660657},
abstract = {The rapid growth of generative artificial intelligence (AI) models introduced challenges for educators, students and administrators across the academic sphere related to how to manage and regulate these tools. While some oppose their use, many researchers have begun to approach the topic of educational AI use from a different perspective. Despite being in its early stages; this field of research has produced notable insights into the capabilities and limitations of models like ChatGPT. This paper utilizes a SWOT analysis framework to analyze and consolidate existing literature, with a specific focus on Computer Science education. Through the analysis of this literature, we have created a set of use cases and guidelines to aid in the future development of strategies and tools within this field. Our findings indicate that while some concerns are valid, such as AI's ability to generate plagiarized work, we identified several promising avenues and opportunities for careful integration of this technology into education.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {10},
numpages = {6},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}
  
@inproceedings{10.1145/3696630.3727235,
author = {Hyrynsalmi, Sonja and Tuape, Micheal and Knutas, Antti},
title = {&quot;Person is a person, a tool is a tool&quot; - ChatGPT’s Role in Student Help-Seeking Behavior and Peer Support},
year = {2025},
isbn = {9798400712760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696630.3727235},
doi = {10.1145/3696630.3727235},
abstract = {Generative Artificial Intelligence (GenAI) tools, such as ChatGPT, are reshaping higher education. In research, a lot of attention has been given to concerns like academic integrity and how to integrate AI into learning and teaching. However, little is known about how these tools impact student help-seeking patterns and peer interactions. This short paper investigates GenAI tools, help-seeking preferences and the importance of peer support among first-year software engineering students (n=94). Our responses show that 50\% of the students use GenAI tools as the primary source of help-seeking, and 43\% report that using ChatGPT reduces their need to interact with peers. However, students generally recognize the importance of social interaction and peer support for their learning. We use these duality findings to extend previous recommendations for integrating generative AI in education by providing new recommendations on how educators can support help-seeking and peer support in the age of GenAI.},
booktitle = {Proceedings of the 33rd ACM International Conference on the Foundations of Software Engineering},
pages = {783–788},
numpages = {6},
keywords = {help-seeking, peer-support, informal learning, software engineering education and teaching},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {FSE Companion '25}
}
  
@inproceedings{10.1145/3563703.3591453,
author = {Van Der Maden, Willem and Van Beek, Evert and Nicenboim, Iohanna and Van Der Burg, Vera and Kun, Peter and Lomas, James Derek and Kang, Eunsu},
title = {Towards a Design (Research) Framework with Generative AI},
year = {2023},
isbn = {9781450398985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563703.3591453},
doi = {10.1145/3563703.3591453},
abstract = {This one day workshop will explore the use of Generative Artificial Intelligence (GenAI) in design research and practice. Generative technologies are developing rapidly and many designers are using them. Yet, there remains little published work on the use of GenAI in design. Our goal is to not only showcase the potential of GenAI for design, but to engage in discussions of its shortcomings and opportunities as they have been already articulated by scholars. By synthesizing both published and unpublished works, we will develop best practices, ethical considerations, and future research directions for the use of GenAI in design. We will explore a range of topics and themes, including leveraging the characteristics of GenAI for design, mapping the diverse applications of GenAI in design, envisioning a framework for design, and guiding future work on GenAI in design research. Ultimately, we hope to provide a roadmap for the integration of GenAI into the design research process and to encourage designers and researchers to explore the potential of GenAI in a thoughtful and deliberate way.},
booktitle = {Companion Publication of the 2023 ACM Designing Interactive Systems Conference},
pages = {107–109},
numpages = {3},
keywords = {computational creativity, creative practices, design research, generative artificial intelligence},
location = {Pittsburgh, PA, USA},
series = {DIS '23 Companion}
}
  
@inproceedings{10.1145/3613904.3642296,
author = {Berney, Manon and Ouaazki, Abdessalam and Macko, Vladimir and Kocher, Bruno and Holzer, Adrian},
title = {Care-Based Eco-Feedback Augmented with Generative AI: Fostering Pro-Environmental Behavior through Emotional Attachment},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642296},
doi = {10.1145/3613904.3642296},
abstract = {Lights out! With the escalating climate crisis, eco-feedback has gained prominence over the last decade. However, traditional approaches could be underperforming as they often use data-driven strategies and assume that people only need additional information about their consumption to change behavior. A proposed path to overcome this issue is to design eco-feedback to foster emotional connections with users. However, not much is known about the effectiveness of such designs. In this paper, we propose a novel care-based eco-feedback system. Central to the system is a Tamagotchi-inspired digital character named Infi who gets its life force from the user’s energy savings. Additionally, we harness the latest advancements in generative artificial intelligence to enhance emotional attachment through conversational interactions that users can have with Infi. The results of a randomized controlled experiment (N=420) convey the fact that this design increases emotional attachment, which in turn increases energy-saving behavior.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {469},
numpages = {15},
keywords = {care-based intervention, conversational interaction, eco-feedback, emotional attachment, gamification, generative AI},
location = {Honolulu, HI, USA},
series = {CHI '24}
}
  
@inproceedings{10.1145/3665348.3665370,
author = {Lu, Qianlong and Gao, Maoting},
title = {A Research on Shilling Attacks Based on Variational graph auto-encoders for Improving the Robustness of Recommendation Systems},
year = {2024},
isbn = {9798400709562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665348.3665370},
doi = {10.1145/3665348.3665370},
abstract = {As personalized recommendation techniques continue to evolve and be applied, recommendation systems face a plethora of malicious attacks. In order to defend against potential malicious attacks, enhance the robustness of recommendation systems, and strengthen their ability to withstand attacks, it is necessary to propose a method based on Variational Graph Auto-encoders (VGAE) for generating shilling attacks. This method improves the VGAE model, models user profiles, and generates reconstructed user profiles that conform to the original rating patterns. By utilizing spectral clustering, users are selected from the original dataset as templates in a dispersed manner according to a certain attack scale. These templates are then matched with the most similar fake users in the reconstructed user profiles. Within these fake user profiles, ratings for the most popular items in each category and target item ratings are inserted. Finally, fake user profiles are generated and injected into the recommendation system to broadly promote target items to users of the system. Experimental results on the MovieLens 100k and 1M datasets demonstrate that this new method exhibits more stable attack performance and stronger detection evasion capabilities compared to traditional attack strategies, thereby better exposing existing issues within recommendation systems.},
booktitle = {Proceedings of the 2024 International Conference on Generative Artificial Intelligence and Information Security},
pages = {120–126},
numpages = {7},
location = {Kuala Lumpur, Malaysia},
series = {GAIIS '24}
}
  
@inproceedings{10.1145/3745238.3745459,
author = {Huang, Zhenxiong},
title = {Application of AIGC in multilingual teaching in higher education},
year = {2025},
isbn = {9798400712791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3745238.3745459},
doi = {10.1145/3745238.3745459},
abstract = {This study systematically evaluates the technological realization path and social benefits of generative artificial intelligence (AIGC) in multilingual teaching and learning in higher education.  Based on current advanced multilingual model architectures and cross-modal content generation technologies, an automatic generation system for teaching resources supporting 12 languages is constructed.  Experimental data showed that the system led to a 41.2\% increase in learning efficiency in a Tamil course at the Indian Institute of Technology (IIT) (p&lt;0.01, n=320), while a test of teaching Chinese as a second language at the Beijing Language and Culture University (BLCU) showed that AIGC-generated personalized exercises reduced the learner error rate by 33.7\%.  The study further revealed that (i) the cost of generating instructional materials for low-resource languages (e.g., Kiswahili) decreased to 18.5\% of the traditional approach;  and (ii) through an authoritative equity assessment framework, it was confirmed that the technological solution could narrow the digital education divide between developing and developed countries by up to 27.3 percentage points.  This provides actionable technological support for the equity goals of the UN's Education 2030 Agenda.},
booktitle = {Proceedings of the 2nd Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {1414–1418},
numpages = {5},
keywords = {AIGC, Digital Transformation, Educational equity, Multilingual education},
location = {
},
series = {DEAI '25}
}
  
@inproceedings{10.1145/3633083.3633099,
author = {Stone, Irene},
title = {Exploring the Research Gap: Generative AI and Learning of Python Programming among Post-Primary Students},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633099},
doi = {10.1145/3633083.3633099},
abstract = {The introduction of Leaving Certificate Computer Science (LCCS) in Ireland in 2018 signifies a notable advancement in post-primary education. Moreover, developments in generative Artificial Intelligence (GAI) in education, are gaining prominence, yet we do not understand its value or how best to implement it in post-primary educational settings. Despite a growing international body of research in this area, my scoping review highlights that many aspects of these topics have yet to be explored, particularly in the context of post-primary students in Ireland. My study will begin to bridge this gap by exploring how a purposeful sample of LCCS post-primary students in Ireland engage with GAI tools, such as ChatGPT, during their initial experiences learning Python programming. These findings, when approached through the lens of Human-Centred Artificial Intelligence (HCAI), can help enhance pedagogical strategies and lead to improved learning experiences for students.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {51},
numpages = {1},
location = {Dublin, Ireland},
series = {HCAIep '23}
}
  
@inproceedings{10.1145/3679318.3685370,
author = {Park, Hyerim and Eirich, Joscha and Luckow, Andre and Sedlmair, Michael},
title = {&quot;We Are Visual Thinkers, Not Verbal Thinkers!&quot;: A Thematic Analysis of How Professional Designers Use Generative AI Image Generation Tools},
year = {2024},
isbn = {9798400709661},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3679318.3685370},
doi = {10.1145/3679318.3685370},
abstract = {Generative artificial intelligence (GenAI) has become increasingly popular, influencing various creative domains. However, while broader societal perspectives have been analyzed, specific examinations of how practitioners utilize GenAI tools to enhance their current workflows remain limited. To address this gap, we conducted a qualitative study involving 16 professional designers from the automotive industry. We aimed to identify their challenges with existing GenAI image generation tools in daily design practices. Thematic analysis revealed four key themes: (1) the need for visual input-centric multi-modal interfaces that extend beyond textual prompts, (2) the lack of support for the iterative nature of design processes in GenAI tools, (3) difficulties in controlling prompts to achieve desired outputs, and (4) the significance of incorporating human experiences and emotions into design. Based on our findings, we propose and discuss potential design considerations for enhancing future GenAI image generation tool interfaces.},
booktitle = {Proceedings of the 13th Nordic Conference on Human-Computer Interaction},
articleno = {35},
numpages = {14},
keywords = {creativity support tools, generative AI, human-AI interaction, qualitative research},
location = {Uppsala, Sweden},
series = {NordiCHI '24}
}
  
@inproceedings{10.1145/3613905.3636294,
author = {Muller, Michael and Kantosalo, Anna and Maher, Mary Lou and Martin, Charles Patrick and Walsh, Greg},
title = {GenAICHI 2024: Generative AI and HCI at CHI 2024},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636294},
doi = {10.1145/3613905.3636294},
abstract = {This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI), and - among other approaches - particularly to Large Language Models (LLMs) and Foundation Models (FMs). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together. Following successful workshops in 2022 and 2023, we convene the interdisciplinary research domain of generative AI and HCI. Participation in this invitational workshop is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {470},
numpages = {7},
keywords = {Bias, Design, Generative AI, Uncertainty.},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}
  
@inproceedings{10.1145/3616961.3616978,
author = {Oppenlaender, Jonas and Silvennoinen, Johanna and Paananen, Ville and Visuri, Aku},
title = {Perceptions and Realities of Text-to-Image Generation},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616978},
doi = {10.1145/3616961.3616978},
abstract = {Generative artificial intelligence (AI) is a widely popular technology that will have a profound impact on society and individuals. Less than a decade ago, it was thought that creative work would be among the last to be automated&nbsp;– yet today, we see AI encroaching on many creative domains. In this paper, we present the findings of a survey study on people’s perceptions of text-to-image generation. We touch on participants’ technical understanding of the emerging technology, their fears and concerns, and thoughts about risks and dangers of text-to-image generation to the individual and society. We find that while participants were aware of the risks and dangers associated with the technology, only few participants considered the technology to be a personal risk. The risks for others were more easy to recognize for participants. Artists were particularly seen at risk. Interestingly, participants who had tried the technology rated its future importance lower than those who had not tried it. This result shows that many people are still oblivious of the potential personal risks of generative artificial intelligence and the impending societal changes associated with this technology.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {279–288},
numpages = {10},
keywords = {text-to-image generation, generative AI},
location = {Tampere, Finland},
series = {Mindtrek '23}
}
  
@inproceedings{10.1145/3641554.3701917,
author = {Wang, Kevin Shukang and Lawrence, Ramon},
title = {Quantitative Evaluation of Using Large Language Models and Retrieval-Augmented Generation in Computer Science Education},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701917},
doi = {10.1145/3641554.3701917},
abstract = {Generative artificial intelligence (GenAI) is transforming Computer Science education, and every instructor is reflecting on how AI will impact their courses. Instructors must determine how students may use AI for course activities and what AI systems they will support and encourage students to use. This task is challenging with the proliferation of large language models (LLMs) and related AI systems. The contribution of this work is an experimental evaluation of the performance of multiple open-source and commercial LLMs utilizing retrieval-augmented generation in answering questions for computer science courses and a cost-benefit analysis for instructors when determining what systems to use. A key factor is the time an instructor has to maintain their supported AI systems and the most effective activities for improving their performance. The paper offers recommendations for deploying, using, and enhancing AI in educational settings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1183–1189},
numpages = {7},
keywords = {artificial intelligence, human-in-the-loop, large language model, question answering, retrieval-augmented generation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}
  
@inbook{10.1145/3713043.3731498,
author = {Dangol, Aayushi and Wolfe, Robert and Yoo, Daeun and Thiruvillakkat, Arya and Chickadel, Ben and Kientz, Julie A.},
title = {If anybody finds out you are in BIG TROUBLE”: Understanding Children’s Hopes, Fears, and Evaluations of Generative AI},
year = {2025},
isbn = {9798400714733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713043.3731498},
abstract = {As generative artificial intelligence (genAI) increasingly mediates how children learn, communicate, and engage with digital content, understanding children’s hopes and fears about this emerging technology is crucial. In a pilot study with 37 fifth-graders, we explored how children (ages 9–10) envision genAI and the roles they believe it should play in their daily life. Our findings reveal three key ways children envision genAI: as a companion providing guidance, a collaborator working alongside them, and a task automator that offloads responsibilities. However, alongside these hopeful views, children expressed fears about overreliance, particularly in academic settings, linking it to fears of diminished learning, disciplinary consequences, and long-term failure. This study highlights the need for child-centric AI design that balances these tensions, empowering children with the skills to critically engage with and navigate their evolving relationships with digital technologies.},
booktitle = {Proceedings of the 24th Interaction Design and Children},
pages = {872–877},
numpages = {6}
}
  
@inproceedings{10.1145/3665348.3665357,
author = {Wu, Junying and Lu, Yanyan and Li, Zixin and Peng, Jiao and Xu, Xing and Song, Hui},
title = {Word-Phrase Fusion Encoding Model for Natural Language Understanding in the Electric Power Field},
year = {2024},
isbn = {9798400709562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665348.3665357},
doi = {10.1145/3665348.3665357},
abstract = {Intelligent question-answering systems have been widely applied in the field of electric power. However, with the complexity of terms in the electric power field, the generic word-based encoding approach of natural language understanding model fails to identify those domain phrases even if they appear in the training samples. To improve the semantic accuracy of special content labeling, this paper proposes a words-phrase fusion encoding NLU model with the help of domain corpus. We pre-train a phrase-level Bert model in the electric power field which is involved during the model encoding step to accurately capture the semantics of domain terms and perceive the boundary of phrases. Additionally, continuous consistency loss of sequences is added to the model to reduce the to reduce the misclassification of individual words in the phrases. Experiment with real dataset in power QA system demonstrates that our model helps improve semantic parsing accuracy on both training and untrained items, alleviates the complete dependency of the phrase encoding model on word segmentation results.},
booktitle = {Proceedings of the 2024 International Conference on Generative Artificial Intelligence and Information Security},
pages = {43–49},
numpages = {7},
location = {Kuala Lumpur, Malaysia},
series = {GAIIS '24}
}
  
@inproceedings{10.1145/3704217.3704224,
author = {Qi, Linyi and Zhu, Jiangqin},
title = {Visualizing Research Trends on the Use of Generative AI in Assessment in the WOS database from 2019 to 2024 via Vosviewer and CiteSpace},
year = {2025},
isbn = {9798400707094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704217.3704224},
doi = {10.1145/3704217.3704224},
abstract = {The first typical generative Artificial Intelligence (Gen AI) model ChatGpt 1 was introduced in 2018, but has not drawn much attention until the release of ChatGpt 3 in 2022. Since then, researchers and educators have been experimenting with Gen AI tools to explore their possibilities in various fields. In education, the use of Gen AI in assessment is a research focus. To reveal the research patterns in this field, the study employed Vosviewer and CiteSpace to analyze 816 papers in the Web of Science (WOS) database published between 2019 and 2024. The annual publications surged during the period of 2023-2024 due to the release of higher versions of Gen AI tools such as ChatGpt 3. Researchers in the United States, United Kingdom and China engage most actively in the field. American and Hong Kong universities are particularly productive. However, the collaboration between institutions and authors still needs to be enhanced. Highly influential journals such as Nature and famous medical journals such as JMIR Medical Education and Cureus Journal of Medical sciences are most frequently cited. The analysis of co-occurrence keywords and keyword clusters identified two research areas: responding to the academic integrity issue with the use of Gen AI in assessment and exploring the valuable use of Gen AI in assessments in higher education especially medical education. Future research could explore the design of innovative or alternative assessments and the use of Gen AI tools in interactive and game-based assessment creation, marking and feedback giving.},
booktitle = {Proceedings of the 2024 8th International Conference on E-Society, E-Education and E-Technology},
pages = {28–35},
numpages = {8},
keywords = {Academic integrity, Assessment, Education, Generative AI},
location = {
},
series = {ESET '24}
}
  
@inproceedings{10.1145/3665348.3665374,
author = {Zhang, Zongnan and Li, Meng and An, Xiaoxin and Li, Zhen and Ma, Zhe},
title = {Side-Channel Analysis of Curve-25519 Based on Deep Learning},
year = {2024},
isbn = {9798400709562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665348.3665374},
doi = {10.1145/3665348.3665374},
abstract = {This paper explores the integration of deep learning technology with Side-Channel Analysis (SCA) methods to effectively analyze the Curve-25519 algorithm implemented on an MCU chip. The Curve-25519 algorithm, protected by the security features of elliptical curve algorithms and constant-time operations, presents a challenge for low-cost, non-invasive SCA methods due to its robustness. This work focuses on the leakage of conditional judgment operations that occur before each point addition and point doubling operation. By identifying these information leakage points through SCA, electromagnetic radiation and power consumption information are collected and labeled. We conduct a dataset and transformed 1-dimensional signals into a 2D image for training. The trained model is subsequently used for testing. Experiments demonstrate that this method can effectively analyze leakage points in the Curve-25519 algorithm and help to improve the robustness of the algorithm.},
booktitle = {Proceedings of the 2024 International Conference on Generative Artificial Intelligence and Information Security},
pages = {144–149},
numpages = {6},
location = {Kuala Lumpur, Malaysia},
series = {GAIIS '24}
}
  
@inproceedings{10.1145/3607822.3618018,
author = {Hu, Yongquan and Zhang, Dawen and Quigley, Aaron},
title = {GenAIR: Exploring Design Factor of Employing Generative AI for Augmented Reality},
year = {2023},
isbn = {9798400702815},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607822.3618018},
doi = {10.1145/3607822.3618018},
abstract = {Generative Artificial Intelligence (GenAI) has emerged as a fundamental component of intelligent interactive systems, enabling the automatic generation of multimodal media content. The continuous enhancement in the quality of Artificial Intelligence-Generated Content (AIGC), including but not limited to images and text, is forging new paradigms for its application, particularly within the domain of Augmented Reality (AR). Nevertheless, the application of GenAI within the AR design process remains opaque. This paper aims to articulate a design space encapsulating a series of criteria and a prototypical process to aid practitioners in assessing the aptness of adopting pertinent technologies. The proposed model has been formulated based on a synthesis of design insights garnered from ten experts, obtained through focus group interviews. Leveraging these initial insights, we delineate potential applications of GenAI in AR.},
booktitle = {Proceedings of the 2023 ACM Symposium on Spatial User Interaction},
articleno = {47},
numpages = {3},
keywords = {Design Factor, Generative AI, Spatial Augmented Reality},
location = {Sydney, NSW, Australia},
series = {SUI '23}
}
  
@inproceedings{10.1145/3706599.3721208,
author = {Wang, Amy and Ruparel, Roma and Iurchenko, Anna and Jhun, Paul and S\'{e}guin, Julie Anne and Strachan, Patricia and Wong, Renee and Karthikesalingam, Alan and Matias, Yossi and Hassidim, Avinatan and Webster, Dale and Semturs, Christopher and Krause, Jonathan and Schaekermann, Mike},
title = {Generative AI for medical education: Insights from a case study with medical students and an AI tutor for clinical reasoning},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3721208},
doi = {10.1145/3706599.3721208},
abstract = {Generative Artificial Intelligence (AI), particularly Large Language Models (LLMs), have demonstrated significant potential in clinical reasoning skills such as history-taking and differential diagnosis generation—critical aspects of medical education. This work explores how LLMs can augment medical curricula through interactive learning. We conducted a participatory design process with medical students, residents and medical education experts to co-create an AI-powered tutor prototype for clinical reasoning. As part of the co-design process, we conducted a qualitative user study, investigating learning needs and practices via interviews, and conducting concept evaluations through interactions with the prototype. Findings highlight the challenges learners face in transitioning from theoretical knowledge to practical application, and how an AI tutor can provide personalized practice and feedback. We conclude with design considerations, emphasizing the importance of context-specific knowledge and emulating positive preceptor traits, to guide the development of AI tools for medical education.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {303},
numpages = {8},
keywords = {Education, Medicine, Generative AI, Large Language Models},
location = {
},
series = {CHI EA '25}
}
  
@inproceedings{10.1145/3641032.3641055,
author = {Faccia, Alessio and Ridon, Manjeet and Beebeejaun, Zeenat and Mosteanu, Narcisa Mosteanu Roxana},
title = {Advancements and Challenges of Generative AI in Higher Educational Content Creation A Technical Perspective},
year = {2024},
isbn = {9798400709173},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641032.3641055},
doi = {10.1145/3641032.3641055},
abstract = {Generative Artificial Intelligence (AI) has witnessed remarkable advancements, igniting interest in various domains, including Higher Education. This research paper explores the impacts and challenges of integrating Generative AI in content creation within Higher Education. We utilise a literature review and case study approach to gain insights into the potential benefits and complexities of implementing Generative AI in educational settings. Specific research questions are formulated to investigate the influence of Generative AI on content creation efficiency, productivity, quality, and adaptability. The paper also highlights ethical considerations and the evolving role of educators in the AI-driven educational landscape. Furthermore, the research paper examines the practical applications of Generative AI tools such as OpenAI GPT, GPT-Neo, Hugging Face's Transformers Library, Cognii, MosaChat-AI, TeacherMatic, and OpenAI Codex in Higher Education content creation. This comprehensive analysis aims to provide educators, instructional designers, and policymakers with valuable insights and concrete examples of how Generative AI can be leveraged to create personalised learning materials, improve assessment strategies, and enhance the overall educational experience for students pursuing advanced technical subjects. The culmination of this research presents a vision for a future where Generative AI, thoughtfully implemented and ethically managed, empowers educational institutions to meet the diverse and evolving needs of learners in the digital era.},
booktitle = {Proceedings of the 2023 8th International Conference on Information Systems Engineering},
pages = {48–54},
numpages = {7},
keywords = {Applications, Chat GPT, Generative AI, Higher Education},
location = {Bangkok, Thailand},
series = {ICISE '23}
}
  
@inproceedings{10.1145/3658549.3658561,
author = {Ke, Chih-Kun and Wu, Mei-Yu and Chung, Bor-Lin},
title = {Automation, Trustworthy, Intelligent Prenatal Examinations - I Do!!},
year = {2024},
isbn = {9798400709180},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658549.3658561},
doi = {10.1145/3658549.3658561},
abstract = {Medical institutions are looking forward to importing innovative information services to reduce the burden on medical staff. For example, medical staff repeatedly process the contextual data in each stage of the prenatal examinations, which is labor-intensive and time-consuming. If a dispute happens, the data will become the evidence to support whether the prenatal examinations were handled appropriately. Therefore, if the prenatal examination data is not accurately recorded and properly preserved, it will become a source of pressure for medical staff to face disputes in the future. This research takes the prenatal examinations of pregnant as a use case. We apply robotic process automation technology to assist in the automation of prenatal examinations and blockchain technology to establish trustworthy prenatal examinations. Besides, we also use generative artificial intelligence technology to provide intelligent user-assisted consultation in open-domain question answering. The contribution of this work is to build an automated reliable prenatal examination information service to provide good care for pregnant.},
booktitle = {Proceedings of the 2024 International Conference on Information Technology, Data Science, and Optimization},
pages = {42–47},
numpages = {6},
location = {Taipei, Taiwan},
series = {I-DO '24}
}
  
@inproceedings{10.1145/3613904.3642800,
author = {Jin, Yucheng and Cai, Wanling and Chen, Li and Zhang, Yizhe and Doherty, Gavin and Jiang, Tonglin},
title = {Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642800},
doi = {10.1145/3613904.3642800},
abstract = {Music-based reminiscence has the potential to positively impact the psychological well-being of older adults. However, the aging process and physiological changes, such as memory decline and limited verbal communication, may impede the ability of older adults to recall their memories and life experiences. Given the advanced capabilities of generative artificial intelligence (AI) systems, such as generated conversations and images, and their potential to facilitate the reminiscing process, this study aims to explore the design of generative AI to support music-based reminiscence in older adults. This study follows a user-centered design approach incorporating various stages, including detailed interviews with two social workers and two design workshops (involving ten older adults). Our work contributes to an in-depth understanding of older adults’ attitudes toward utilizing generative AI for supporting music-based reminiscence and identifies concrete design considerations for the future design of generative AI to enhance the reminiscence experience of older adults.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1012},
numpages = {17},
keywords = {Generative AI, Human-AI Interaction, Music-based Reminiscence, Older Adults, Reminiscence},
location = {Honolulu, HI, USA},
series = {CHI '24}
}
  
@article{10.5555/3711988.3711989,
author = {Tham, Jason},
title = {Teaching UX: Amid the Hype of Generative AI},
year = {2025},
issue_date = {November 2024},
publisher = {Usability Professionals' Association},
address = {Bloomingdale, IL},
volume = {20},
number = {1},
issn = {1931-3357},
abstract = {I am a faculty member in a technical communication program at a comprehensive research university. Recently, I have been inundated with questions, concerns, and critiques about the rise of augmentation technologies in writing and design processes, particularly generative artificial intelligence (AI) tools that support chat-based text generation and text-to-image production. I'm sure many UX researchers and designers face similar issues in their work. It remains unclear how generative AI should fit into existing workflow or design processes. Common questions include these:• How does AI work? What can it do? Is it free?• Is it cheating if I use AI to produce content?• Who is responsible for the quality of AI-generated content?• To what extent can I outsource my routine work to AI? In other words, what's an acceptable threshold for using AI before it is considered too much?Specific to UX is the value (cost and labor versus gains and effects) of generative AI in the research and design of user-centered products. Students in my UX courses are increasingly worried about the presence of AI and, consequently, the relevance of their developing skill sets in UX. Educators are growing wary about the presence of AI in the context of teaching and learning; many form partially informed decisions on academic policies for AI usage.},
journal = {J. User Exper.},
month = feb,
pages = {1–8},
numpages = {8}
}
  
@inproceedings{10.1145/3614419.3644014,
author = {Wu, Chuhao and Wang, Xinyu and Carroll, John and Rajtmajer, Sarah},
title = {Reacting to Generative AI: Insights from Student and Faculty Discussions on Reddit},
year = {2024},
isbn = {9798400703348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614419.3644014},
doi = {10.1145/3614419.3644014},
abstract = {Generative Artificial intelligence (GenAI) such as ChatGPT has elicited strong reactions from almost all stakeholders across the education system. Education-oriented and academic social media communities provide an important venue for these stakeholders to share experiences and exchange ideas about GenAI, which is constructive for developing human-centered policies. This study examines early user reactions to GenAI, consisting of 725 Reddit threads between 06/2022 and 05/2023. Through natural language processing (NLP) and content analysis, we observe an increasingly negative sentiment in the discussion and identify six main categories of student and faculty experiences of GenAI in education. These experiences reflect concerns about academic integrity and AI’s negative impact on the values of traditional education. Our analysis also highlights the tension and burden imposed by new technologies. Our findings suggest that dialogue between stakeholders in the education community is critical and can mitigate sources of tension between students and faculty.},
booktitle = {Proceedings of the 16th ACM Web Science Conference},
pages = {103–113},
numpages = {11},
keywords = {Generative AI, Higher Education, Social Media, Topic Modeling},
location = {Stuttgart, Germany},
series = {WEBSCI '24}
}
  
@inproceedings{10.1145/3706599.3720249,
author = {Reinhard, Philipp and Li, Mahei Manhai and Fina, Matteo and Leimeister, Jan Marco},
title = {Fact or Fiction? Exploring Explanations to Identify Factual Confabulations in RAG-Based LLM Systems},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720249},
doi = {10.1145/3706599.3720249},
abstract = {The adoption of generative artificial intelligence (GenAI) and large language models (LLMs) in society and business is growing rapidly. While these systems often generate convincing and coherent responses, they risk producing incorrect or non-factual information, known as confabulations or hallucinations. Consequently, users must critically assess the reliability of these outputs when interacting with LLM-based agents. Although advancements such as retrieval-augmented generation (RAG) have improved the technical performance of these systems, there is a lack of empirical models that explain how humans detect confabulations. Building on the explainable AI (XAI) literature, we examine the role of reasoning-based explanations in helping users identify confabulations in LLM systems. An online experiment (n = 97) reveals that analogical and factual explanations improve detection accuracy but require more time and cognitive effort than the no explanation baseline.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {274},
numpages = {13},
keywords = {Generative AI, Explainable AI, XAI, RAG, LLM, Confabulations, Hallucinations, GenXAI},
location = {
},
series = {CHI EA '25}
}
  
@inproceedings{10.1145/3625468.3652912,
author = {Artioli, Emanuele},
title = {Generative AI for HTTP Adaptive Streaming},
year = {2024},
isbn = {9798400704123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625468.3652912},
doi = {10.1145/3625468.3652912},
abstract = {Video streaming stands as the cornerstone of telecommunication networks, constituting over 60\% of mobile data traffic as of June 2023. The paramount challenge faced by video streaming service providers is ensuring high Quality of Experience (QoE) for users. In HTTP Adaptive Streaming (HAS), including DASH and HLS, video content is encoded at multiple quality versions, with an Adaptive Bitrate (ABR) algorithm dynamically selecting versions based on network conditions. Concurrently, Artificial Intelligence (AI) is revolutionizing the industry, particularly in content recommendation and personalization. Leveraging user data and advanced algorithms, AI enhances user engagement, satisfaction, and video quality through super-resolution and denoising techniques.However, challenges persist, such as real-time processing on resource-constrained devices, the need for diverse training datasets, privacy concerns, and model interpretability. Despite these hurdles, the promise of Generative Artificial Intelligence emerges as a transformative force. Generative AI, capable of synthesizing new data based on learned patterns, holds vast potential in the video streaming landscape. In the context of video streaming, it can create realistic and immersive content, adapt in real time to individual preferences, and optimize video compression for seamless streaming in low-bandwidth conditions.This research proposal outlines a comprehensive exploration at the intersection of advanced AI algorithms and digital entertainment, focusing on the potential of generative AI to elevate video quality, user interactivity, and the overall streaming experience. The objective is to integrate generative models into video streaming pipelines, unraveling novel avenues that promise a future of dynamic, personalized, and visually captivating streaming experiences for viewers.},
booktitle = {Proceedings of the 15th ACM Multimedia Systems Conference},
pages = {516–519},
numpages = {4},
keywords = {Generative AI, Video Streaming},
location = {Bari, Italy},
series = {MMSys '24}
}
  
@inproceedings{10.1145/3613904.3641951,
author = {Mim, Nusrat Jahan and Nandi, Dipannita and Khan, Sadaf Sumyia and Dey, Arundhuti and Ahmed, Syed Ishtiaque},
title = {In-Between Visuals and Visible: The Impacts of Text-to-Image Generative AI Tools on Digital Image-making Practices in the Global South},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641951},
doi = {10.1145/3613904.3641951},
abstract = {This paper joins the growing body of HCI work on critical AI studies and focuses on the impact of Generative Artificial Intelligence (GAI) tools in Bangladesh. While the West has started to examine the limitations and risks associated with these tools, their impacts on the Global South have remained understudied. Based on our interviews, focus group discussions (FGD), and social media-based qualitative study, this paper reports how popular text-to-image GAI tools (ex., DALL-E, Midjourney, Stable Diffusion, Firefly) are affecting various image-related local creative fields. We report how these tools limit the creative explorations of marginal artists, struggle to understand linguistic nuances, fail to generate local forms of art and architecture, and misrepresent the diversity among citizens in the image production process. Drawing from a rich body of work on critical image theory, postcolonial computing, and design politics, we explain how our findings are pertinent to HCI’s broader interest in social justice, decolonization, and global development.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {474},
numpages = {18},
keywords = {Architecture, Art, Artificial Intelligence, Generative AI, Image, Urban Design},
location = {Honolulu, HI, USA},
series = {CHI '24}
}
  
@inproceedings{10.1145/3656650.3660544,
author = {Inkpen, Kori},
title = {Achievement Unlocked: The Future of Human-AI Experiences},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3660544},
doi = {10.1145/3656650.3660544},
abstract = {We are currently witnessing the rapid evolution of Generative Artificial Intelligence (Gen-AI), marking the beginning of a transformative era. Gen-AI is not only revolutionizing what we can achieve with computing but also redefining how we engage with this new medium. Much like the printing press, which unlocked immense potential as a tool, its true value was fully realized when paired with human creativity. Similarly, the true magic of AI lies in the experiences it will empower when combined with human ingenuity. This talk will explore new research directions in Human-Computer Interaction that enable us to leverage the power of Gen-AI, shaping the experiences we create to empower individuals in the future.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {2},
numpages = {1},
keywords = {Generative User Interfaces, Human-AI Experiences, Human-Centered AI, Human-Computer Interaction},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}
  
@inproceedings{10.1145/3637528.3671883,
author = {Oosterhuis, Harrie and Jagerman, Rolf and Qin, Zhen and Wang, Xuanhui and Bendersky, Michael},
title = {Reliable Confidence Intervals for Information Retrieval Evaluation Using Generative A.I.},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671883},
doi = {10.1145/3637528.3671883},
abstract = {The traditional evaluation of information retrieval (IR) systems is generally very costly as it requires manual relevance annotation from human experts. Recent advancements in generative artificial intelligence -specifically large language models (LLMs)- can generate relevance annotations at an enormous scale with relatively small computational costs. Potentially, this could alleviate the costs traditionally associated with IR evaluation and make it applicable to numerous low-resource applications. However, generated relevance annotations are not immune to (systematic) errors, and as a result, directly using them for evaluation produces unreliable results.In this work, we propose two methods based on prediction-powered inference and conformal risk control that utilize computer-generated relevance annotations to place reliable confidence intervals (CIs) around IR evaluation metrics. Our proposed methods require a small number of reliable annotations from which the methods can statistically analyze the errors in the generated annotations. Using this information, we can place CIs around evaluation metrics with strong theoretical guarantees. Unlike existing approaches, our conformal risk control method is specifically designed for ranking metrics and can vary its CIs per query and document. Our experimental results show that our CIs accurately capture both the variance and bias in evaluation based on LLM annotations, better than the typical empirical bootstrapping estimates. We hope our contributions bring reliable evaluation to the many IR applications where this was traditionally infeasible.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2307–2317},
numpages = {11},
keywords = {confidence intervals, conformal prediction, generative A.I., information retrieval evaluation, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}
  
@inproceedings{10.1145/3675812.3675874,
author = {Liu, Liyuan and Mendoza, Ruben A. and Martin, Thomas R. and Miori, Virginia M.},
title = {Generative AI-Powered Educational Alignment: A Framework for Matching Syllabus Course Topics with Web Description},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675874},
doi = {10.1145/3675812.3675874},
abstract = {The application of generative artificial intelligence (GAI) in the educational sector is increasingly gaining attention from researchers. This study explores the congruence between online course descriptions and actual course syllabi to improve course preparation and consistency for instructors. Alignment between course catalog descriptions and actual course content as detailed in the syllabus can lead to learning improvements, student satisfaction, and academic alignment in a program. Our research introduces a novel framework utilizing GAI to systematically evaluates and identifies mismatches and suggests content to close the gap between online course descriptions and syllabus content. We used OpenAI’s ChatGPT to extract key topics from course syllabi and assessed the congruence between results and course description content with embedding methods such as BERT, GPT-2, RoBERTa, and DistilBERT, coupled with cosine similarity metrics. Our framework also integrates an outlier detection algorithm to identify courses with significant misalignments and use GAI applications to refine and enhance course catalog descriptions. This approach helps higher education institutions update course offerings with cutting-edge technology and contributes to curriculum development, helping improve student learning efficiency and course design.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {340–346},
numpages = {7},
keywords = {AI in education, ChatGPT, Curriculum alignment, Curriculum development, Generative AI, Syllabus analysis},
location = {Guangzhou, China},
series = {ICDEL '24}
}
  
@inproceedings{10.1145/3715336.3735805,
author = {Sandhaus, Hauke and Gu, Qiuquan and Parreira, Maria Teresa and Ju, Wendy},
title = {Co-Designing with Transformers: Unpacking the Complex Role of GenAI in Interactive System Design Education},
year = {2025},
isbn = {9798400714856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715336.3735805},
doi = {10.1145/3715336.3735805},
abstract = {Generative Artificial Intelligence (GenAI) is transforming Human-Computer Interaction (HCI) education and technology design, yet its impact remains poorly understood. This study explores how graduate students in an applied HCI course used GenAI tools during interactive device design. Despite no encouragement, all groups integrated GenAI into their workflows. Through 12 post-class group interviews, we identified how GenAI co-design behaviors present both benefits—such as enhanced creativity and faster design iterations—and risks, including shallow learning and reflection. Benefits were most evident during the execution phases, while the discovery and reflection phases showed limited gains. A taxonomy of usage patterns revealed that students’ outcomes depended more on how they used GenAI than the specific tasks performed. These findings highlight the need for HCI education to adapt to GenAI’s role and offer recommendations for curricula to better prepare future designers for effective creative co-design.},
booktitle = {Proceedings of the 2025 ACM Designing Interactive Systems Conference},
pages = {1228–1243},
numpages = {16},
keywords = {LLMs, GenAI, education, prototyping, user-centered design, ethics},
location = {
},
series = {DIS '25}
}
  
@inproceedings{10.1145/3610542.3626142,
author = {Wu, Yaokun and Kouta, Minamizawa and Yun Suen, Pai},
title = {OwnDiffusion: A Design Pipeline Using Design Generative AI to preserve Sense Of Ownership},
year = {2023},
isbn = {9798400703133},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610542.3626142},
doi = {10.1145/3610542.3626142},
abstract = {Generative Artificial Intelligence (AI) has been a fast-growing technology, well known for generating high-quality design drawings and images in seconds with a simple text input. However, users often feel uncertain about whether generative art should be considered created by AI or by themselves. Losing the sense of ownership of the outcome might impact the learning process and confidence of novice designers and design learners who seek to benefit from using Generative Design Tools. In this context, we propose OwnDiffusion, a design pipeline that utilizes Generative AI to assist in the physical prototype ideation process for novice product designers and industrial design learners while preserving their sense of ownership. The pipeline incorporates a prompt weight assessing tool, allowing designers to fine-tune the AI’s input based on their sense of ownership. We envision this method as a solution for AI-assisted design, enabling designers to maintain confidence in their creativity and ownership of a design.},
booktitle = {SIGGRAPH Asia 2023 Posters},
articleno = {28},
numpages = {2},
keywords = {Avatar, Emotion Regulation, Empathy, Journaling, Mood, Reflection, Virtual Reality},
location = {Sydney, NSW, Australia},
series = {SA '23}
}
  
@inproceedings{10.1145/3581961.3609828,
author = {Choe, Mungyeong and Bosch, Esther and Dong, Jiayuan and Alvarez, Ignacio and Oehl, Michael and Jallais, Christophe and Alsaid, Areen and Nadri, Chihab and Jeon, Myounghoon},
title = {Emotion GaRage Vol. IV: Creating Empathic In-Vehicle Interfaces with Generative AIs for Automated Vehicle Contexts},
year = {2023},
isbn = {9798400701122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581961.3609828},
doi = {10.1145/3581961.3609828},
abstract = {This workshop aims to design advanced empathic user interfaces for in-vehicle displays, particularly for high-level automated vehicles (SAE level 3 or higher). Incorporating model-based approaches for understanding human emotion regulation, it seeks to enhance the user-vehicle interaction. A unique aspect of this workshop is the integration of generative artificial intelligence (AI) tools in the design process. The workshop will explore generative AI’s potential in crafting contextual responses and its impact on user experience and interface design. The agenda includes brainstorming on various driving scenarios, developing emotion-oriented intervention methods, and rapid prototyping with AI tools. The anticipated outcome includes practical prototypes of affective user interfaces and insights on the role of AI in designing human-machine interactions. Through this workshop, we hope to contribute to making automated driving more accessible and enjoyable.},
booktitle = {Adjunct Proceedings of the 15th International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
pages = {234–236},
numpages = {3},
keywords = {ChatGPT, affective computing, emotions, empathic vehicles, interaction design},
location = {Ingolstadt, Germany},
series = {AutomotiveUI '23 Adjunct}
}
  
@inproceedings{10.1145/3644116.3644221,
author = {Zhao, Shifan and Chen, Mingkai},
title = {Psychological Healing in the Digital Age: A Study of Personalized Collaborative Models Empowered by GAI},
year = {2024},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644116.3644221},
doi = {10.1145/3644116.3644221},
abstract = {AI has shown promise in enhancing psychological healing. This research delves into using AI, specifically human-computer interaction and generative artificial intelligence (GAI), for precise mental health assessments and personalized treatment designs. Emotional tools like sentiment analysis and healing digitized journey discern minor mood shifts, precisely pinpointing user needs and offering user mental healing experience. As the design industry prioritizes psychological healing, AI aids in psychotherapy, facilitating tailored treatments, co-created plans, and suggesting future healing directions.},
booktitle = {Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
pages = {637–641},
numpages = {5},
location = {Chengdu, China},
series = {ISAIMS '23}
}
  
@inproceedings{10.1145/3686038.3686063,
author = {Clos, Jeremie and Chen, Yoke Yie},
title = {Investigating the Impact of Generative AI on Students and Educators: Evidence and Insights from the Literature},
year = {2024},
isbn = {9798400709890},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686038.3686063},
doi = {10.1145/3686038.3686063},
abstract = {Generative artificial intelligence (AI) has become one of the main concerns of knowledge workers due to its ability to mimic realistic human reasoning and creativity. However, this integration raises critical concerns about trust and ethics, which are crucial in shaping both the acceptance and effective utilisation of these technologies. There are many reports, articles and papers currently exploring the opportunities and challenges of LLMs in higher education from the perspective of students and educators. However, these papers often focus on specific contexts like in the UK, US or a particular institutions. In this paper, we examine the problems of generative AI in higher education from educator and student perspectives using scientometrics and text analysis to provide an overview of the research landscape, followed by a narrative review and thematic analysis of selected literature. Some findings of this work are: (1) Students and educators found different ways to use generative AI. Students focus more on using it as an assistant (revising and preparing for lectures, helping with homework) and educators as a content production assistant (writing lecture notes, personalising content). Commonalities are that both students and educators use generative AI as an accessibility aid, e.g., to rephrase sentences or explain concepts. (2) The main concerns of higher education regarding generative AI are equity in access, clarity of rules regarding usage, and job displacement.},
booktitle = {Proceedings of the Second International Symposium on Trustworthy Autonomous Systems},
articleno = {25},
numpages = {6},
location = {Austin, TX, USA},
series = {TAS '24}
}
  
@inproceedings{10.1145/3641555.3705235,
author = {Gonzalez, Elias and Chan, Joel and Weintrop, David},
title = {Quack! Configuring Large Language Models to Serve as Rubber Duck Coding Assistants},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705235},
doi = {10.1145/3641555.3705235},
abstract = {The emergence of Generative Artificial Intelligence (GenAI) tools broadly, and Large Language Models (LLMs) specifically, are equipping introductory programming instructors with a whole new class of pedagogical tools. While GenAI certainly poses threats to time-honored instructional techniques, it also provides opportunities for new forms of instructional support. In this work, we introduce our strategy for configuring an LLM to serve as a ''rubber duck debugging'' coding assistant to help novice programmers when they encounter difficulties in programming assignments. The key contribution of this work is not in the idea of using LLMs for debugging itself (which has already been demonstrated elsewhere, e.g., [3]) but to demonstrate the ease, flexibility, and pedagogical potential of the strategy. In particular, through carefully crafted prompts and easily accessible platforms, rubber duck LLMs can assist learners with specific questions while also situating those questions alongside larger computer science concepts and computational thinking practices. This work contributes an easily replicated and model-agnostic instructional strategy that productively and responsibly leverages the power of LLMs to assist novice programmers in developing foundational programming skills.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1463–1464},
numpages = {2},
keywords = {computer science education, generative ai, introductory programming, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}
  
@inproceedings{10.1145/3702163.3702182,
author = {Yaqub, Irfan and Chen, Zhiyuan and Liao, Iman Yi and Maul, Tomas and Seow, Hsin-Vonn and Chandesa, Tissa},
title = {A Novel Framework using Large Language Models to Automate Coursework Feedback for Computer Science modules},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702182},
doi = {10.1145/3702163.3702182},
abstract = {Prompt and sufficient feedback is essential for students' academic learning since it enables them to review their learning techniques and improve their areas of weakness. Nevertheless, delivering personalised feedback to every student continues to be difficult&nbsp;for teachers due to its demanding and time-intensive nature. While automated feedback systems are available, their primary focus is providing feedback on a single subject, and most of them utilise statistical analysis or traditional machine learning techniques to provide feedback. Moreover, no feedback model utilises the same criteria to generate text-based feedback for more than one subject. Generative artificial intelligence (GEN AI) has recently made incredible progress, and large language models (LLMs) can retain the context from the vast amount of text. Hence, this research presents a framework that employs an innovative technique to offer text-based feedback to students in different fields of study. This framework employs two LLMs, one for generating the feedback and another for categorising it into separate subjects using suitable headings for structural organising. Consequently, the output produced by this technology corresponds to the original tone of the teacher.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {130–137},
numpages = {8},
keywords = {Deep Learning Artificial Intelligence, Generative Artificial Intelligence, Large Language Model},
location = {
},
series = {ICETC '24}
}
  
@inproceedings{10.1145/3706599.3719804,
author = {Pammer-Schindler, Viktoria and Liut, Michael and Ley, Tobias},
title = {What if (Everyday) Technologies were Designed for Learning? Towards &quot;Support for Learning&quot; as a Design Goal for Every(day) Technology},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719804},
doi = {10.1145/3706599.3719804},
abstract = {What if everyday technologies were designed for productivity and learning? This is critical in the era of generative artificial intelligence and pervasive digital technologies, where technology design substantially shapes what and how humans are learning. This paper introduces “support for learning” as an explicit design goal for everyday technologies. To provide background, we first differentiate four relationships between learning and technology: (1) learning to use technology, (2) learning about technology, (3) learning as a primary design goal, and (4) learning through technology. Designers can intentionally facilitate the latter (a) by following established design principles for usability and user experience, but need to go beyond such known ground by (b) identifying potential learning goals, and (c) connecting to high-quality learning resources and technology designed from within the system. A future research agenda should investigate the relationships between patterns of technology design, patterns of technology use, and learning.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {595},
numpages = {7},
keywords = {HCI design goals, design goals, technology evaluation, human-centered design, human-centered computing, human-centered AI, humanistic design, lifelong learning},
location = {
},
series = {CHI EA '25}
}
  
@inproceedings{10.1145/3709022.3736542,
author = {Hacmon, Yaniv and Gorelik, Keren and Mirsky, Yisroel},
title = {The Threat of Deepfake Fingerprints},
year = {2025},
isbn = {9798400714191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709022.3736542},
doi = {10.1145/3709022.3736542},
abstract = {Fingerprint biometrics are extensively used for identification and security, from border control to consumer electronics. The permanence of fingerprints means security breaches can have lasting impacts. Traditionally, organizations store only fingerprint templates to mitigate the risks associated with stolen fingerprint images. However, advances in generative artificial intelligence (GenAI), particularly deepfake technologies, now enable adversaries to generate fingerprints from stolen templates, increasing the threat of data breaches.In this paper, we demonstrate and validate a previously theorized threat by evaluating an end-to-end attack in the physical world. Our approach involves: (1) generating fingerprint images from unseen templates, (2) fabricating silicone replicas of these deepfake fingerprints using a 3D resin printer, and (3) successfully deceiving fingerprint scanners with the replicas. The entire lab setup cost only $440 USD and only 7 cents to replicate each fingerprint thereafter, highlighting the attack's practicality.To support reproducibility and encourage the development of defenses, we publicly release our deepfake fingerprint pipeline.},
booktitle = {Proceedings of the 4th Workshop on Security Implications of Deepfakes and Cheapfakes},
pages = {1–8},
numpages = {8},
keywords = {Biometrics, Deepfake, Fingerprint Spoofing, Generative AI},
location = {Hanoi, Vietnam},
series = {WDC '25}
}
  
@inproceedings{10.1145/3702386.3702394,
author = {Qi, Yunlong and Fu, Fangxiang and Tian, Jianchi and Sun, Yan},
title = {Can AI Be Environmentally Responsible? A Comparative Study on the Pro-Environmental Portrait of ChatGPT and Chinese Respondents},
year = {2025},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702386.3702394},
doi = {10.1145/3702386.3702394},
abstract = {ChatGPT, a representative of the new generation of generative artificial intelligence (AI), has garnered widespread attention due to its extraordinary natural language processing capabilities. This study examined ChatGPT's environmental value orientations and ecological worldview within the Value-Belief-Norm (VBN) theory framework and compared these findings with the perceptions and self-assessments of 300 Chinese respondents. The results indicate that ChatGPT exhibits a significant pro-environmental orientation, although differences exist between its orientations and individual predictions of its environmental stance. The study provides theoretical support for the application of next-generation AI in environmental education and advocacy, contributes new evidence to the discourse on human-machine value alignment, and offers insights into human-AI collaboration in environmental protection.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
pages = {43–49},
numpages = {7},
keywords = {ChatGPT, alignment, pro-environmental orientation, “Value-Belief-Norm” theory},
location = {
},
series = {ICAITE '24}
}
  
@inproceedings{10.1145/3706599.3719957,
author = {Benner, Dennis and Rauch, Jannik and Janson, Andreas and Leimeister, Jan Marco},
title = {An Explorative Diary Study of AI-Generated Podcasts in University Education: Benefits, Challenges, and Future Directions},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719957},
doi = {10.1145/3706599.3719957},
abstract = {In this study, we explore the potential of AI-generated podcasts as an educational tool in the evolving landscape of learning media. Podcasts have grown increasingly relevant in education due to their accessibility and ability to integrate learning into everyday life. With the advent of generative artificial intelligence (AI), there is a unique opportunity for scalable and adaptable creation of learning media. However, with novel technology, there also come new challenges. Thus, we developed fine-tuned AI-generated podcasts using Google NotebookLM, our course materials, and a custom prompt. We conducted a one-month explorative evaluation in the field using a qualitative diary study. Our study reveals that students find the podcasts beneficial for flexible everyday learning but also point toward challenges like a lack of emotional engagement and technical non-English language issues. In sum, our study highlights the current benefits and challenges of AI-generated podcasts and presents an agenda for future research.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {70},
numpages = {8},
keywords = {AI-Generated Podcasts, NotebookLM, Diary Study, Explorative Study, Field Study, Digital Education, University Education, Research Agenda},
location = {
},
series = {CHI EA '25}
}
  
@inproceedings{10.1145/3702653.3744328,
author = {Roy, Nimisha and Horielko, Oleksandr and Omojokun, Olufisayo},
title = {Benchmarking of Generative AI Tools in Software Engineering Education: Formative Insights for Curriculum Integration},
year = {2025},
isbn = {9798400713415},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702653.3744328},
doi = {10.1145/3702653.3744328},
abstract = {Generative Artificial Intelligence (Gen-AI) has revolutionized software engineering (SE) by automating tasks across design, coding, and testing [1] [2]. Tools like ChatGPT and GitHub Copilot streamline code generation, architectural modeling, debugging, and test-case creation [3] [4]. Despite their rapid adoption in industry, the pedagogical implications of these tools in computing education have not been systematically examined. This study solves the existing gap by conducting a comprehensive benchmarking study of Gen-AI tools across four core SE phases— design documentation, feature implementation, debugging support, and testing — to address two research questions:RQ1: What strengths and limitations do Gen-AI tools exhibit in each phase?RQ2: How can insights from benchmarking inform effective integration of Gen-AI into SE curricula?To answer these questions, a diverse set of Gen-AI tools is evaluated, ranging from design-focused assistants such as Lucidchart, Mermaid.js and UIzard; implementation-oriented systems including GitHub Copilot, TabNine, Codeium and Supermaven; debugging supports like GPT-4 and Claude 3.5 Sonnet; and testing frameworks such as Testim, Mabl and Applitools—while also surveying emerging platforms (as of summer 2024) like Replit, Postman, Visily, Gemini, Eraser.io and others. For each tool and development phase, we applied phase-specific metrics: in design documentation, we assessed diagram accuracy, completeness, user effort, and IDE integration; in feature implementation, we measured pattern-based code generation quality, code-completion effectiveness, refactoring robustness, and UI/UX scaffolding; in debugging, we evaluated error-detection accuracy, hallucination rates, and clarity of explanatory feedback; and in testing, we examined test-case relevance and defect-detection coverage. Across all phases, we tracked prompt engineering complexity as a key mediating factor influencing tool performance.Our evaluation reveals speed-fidelity trade-offs: Code-completion assistants accelerate boilerplate generation but demand manual oversight to ensure cross-file consistency and manage higher-order abstractions; diagramming tools can produce precise UML models with minimal effort— but at the cost of iterative prompt refinement for complex cases; LLM debuggers deliver context-sensitive fixes yet suffer from nontrivial hallucination rates; testing generators exhibit wide variance in edge-case coverage. On average, tools needed 2.4 prompt iterations for usable diagrams and 1.5 prompts for bug fixes, underscoring the human effort in guiding AI.We recommend a scaffolded framework for integrating Gen-AI into SE education by: embedding AI tools into hands-on assignments, to explore tasks in a controlled context; by structuring small team projects in which one subgroup uses AI assistants while the other completes the same tasks manually (covering design, implementation, debugging and testing) to surface contrasts in workflow, tool strengths, and human reasoning; by requiring students to maintain a reflective journal documenting their AI usage and prompt-engineering strategies, fostering metacognitive insight into how tool inputs shape outputs; and by equipping learners with decision making criteria, teaching them to evaluate AI assistants according to task fit- preparing them to leverage AI responsibly across SE phases in its evolving landscape.},
booktitle = {Proceedings of the 2025 ACM Conference on International Computing Education Research V.2},
pages = {3},
numpages = {1},
keywords = {Generative AI, Software Engineering Education, Benchmarking, Prompt Engineering, Hallucination, Productivity},
location = {
},
series = {ICER '25}
}
  
@inproceedings{10.1145/3712255.3734261,
author = {Frapp\'{e} - - Vialatoux, C\^{o}me and Parrend, Pierre},
title = {Introducing H-Leading-Ones as a Mixed-Category Benchmark Problem for Evolutionary Algorithms},
year = {2025},
isbn = {9798400714641},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712255.3734261},
doi = {10.1145/3712255.3734261},
abstract = {In the wake of generative artificial intelligence and the exponential growth in the volume of data generated, the associated increase in data complexity in the sense of the quantity of different data types present in a single system poses a challenge to evolutionary algorithms. To allow for the development and testing of new algorithms adapted to this new data landscape, test problems are necessary as a way to both evaluate and compare algorithms performances. However, while recent advances extended known test problems such as the r-Leading-Ones marking the transition from binary to multi-valued variables, having different data-types coexisting in the search space is still an open question. We propose the h-Leading-Ones as an extension of the r-Leading-Ones to evaluate the ability of an algorithm to solve problems on a search space composed of multi-valued and real-valued data types. Its design with dependency between the different data-types and its continuity with the r-Leading-Ones provides a convenient new environment for benchmark and runtime analysis for mixed-category search spaces.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {97–98},
numpages = {2},
keywords = {evolutionary algorithms, problem, data-types},
location = {NH Malaga Hotel, Malaga, Spain},
series = {GECCO '25 Companion}
}
  
@inproceedings{10.1145/3690712.3690717,
author = {Wang, Yadi and Fussell, Susan R.},
title = {They May Have Seen My ChatGPT Tab: Exploring Social Perceptions of AI-Assisted Writing for ESL Students},
year = {2024},
isbn = {9798400710315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690712.3690717},
doi = {10.1145/3690712.3690717},
abstract = {Many English as a Second Language (ESL) students have begun to use generative artificial intelligence (AI) tools to improve their writing artifacts. In this process, however, ESL students are also facing scrutiny due to the social expectation of independent language acquisition. Therefore, we propose a study design consisting of diary studies and interviews to investigate the ways ESL students perceive and navigate the nuanced social dynamics around using generative AI in their writing. Through this study, we aim to gain a deeper understanding of the social-technical implication of AI usage in second language acquisition, and to offer suggestions to ESL learners and educators on ways to incorporate AI into their educational journey.},
booktitle = {Proceedings of the Third Workshop on Intelligent and Interactive Writing Assistants},
pages = {13–15},
numpages = {3},
location = {Honolulu, HI, USA},
series = {In2Writing '24}
}
  
@inproceedings{10.1145/3733155.3737910,
author = {Leporini, Barbara and Buzzi, Marina and Della Penna, Giuseppe},
title = {A Preliminary Evaluation of Generative AI Tools for Blind Users: Usability and Screen Reader Interaction},
year = {2025},
isbn = {9798400714023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3733155.3737910},
doi = {10.1145/3733155.3737910},
abstract = {The increasing use of Generative Artificial Intelligence (GAI) tools such as ChatGPT, Copilot, Perplexity and Gemini opens up new possible scenarios for supporting work and everyday activities. For people who are blind, the usability of such tools through screen readers is crucial to ensure their use of such AI-based technologies. In this study, we explore the accessibility and usability of the interfaces of four popular AI-based tools via screen readers through a combination of semi-automated evaluations and inspections conducted by both sighted and blind accessibility experts and screen readers with more than 20 years of experience. Navigation, labeling of control elements, feedback mechanisms, and prompt handling were considered in the study. The results point to usability difficulties in all tools, particularly in navigation structure, clarity of feedback and interactive elements. Although this work empirically explores the accessibility of AI-based tools it brings out the first critical issues that deserve further investigation. However, they are based on a small group of experts and thus should be considered preliminary and useful for future studies.},
booktitle = {Proceedings of the 18th ACM International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {562–568},
numpages = {7},
keywords = {Accessibility, Blind users, ChatGPT, Copilot, Gemini, Generative AI, Perplexity, screen reader interaction},
location = {
},
series = {PETRA '25}
}
  
@inproceedings{10.1145/3597503.3649400,
author = {Smith, Carol},
title = {Trustworthy by Design},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3649400},
doi = {10.1145/3597503.3649400},
abstract = {The relatively recent public release of generative artificial intelligence (AI) systems has ignited a significant leap in awareness of the capabilities of AI. In parallel, there has been a recognition of AI system limitations and the bias inherent in systems created by humans. Expectations are rising for more trustworthy, human-centered, and responsible software connecting humans to powerful systems that augment their abilities. There are decades of practice designing systems that work with, and for humans, that we can build upon to face the new challenges and opportunities brought by dynamic AI systems.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {3},
numpages = {4},
keywords = {keynote, ethics, trust, emerging technology, AI},
location = {Lisbon, Portugal},
series = {ICSE '24}
}
  
@inproceedings{10.1145/3596454.3597176,
author = {Schmidt, Albrecht},
title = {Speeding Up the Engineering of Interactive Systems with Generative AI},
year = {2023},
isbn = {9798400702068},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3596454.3597176},
doi = {10.1145/3596454.3597176},
abstract = {This keynote discusses the opportunities and challenges of using Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) as tools for developing interactive systems. We will look at different stages in the development lifecycle of interactive systems and assess the value of AI support. We explore how GenAI and LLMs can potentially speed-up the ideation, requirements elicitation, architecture development, prototyping, implementation, and testing of interactive systems. The talk will outline emerging practices, such as the use of prompts for code and system generation, to facilitate prototyping and accelerate implementation. We will outline fundamental challenges and suggest emerging research directions, and pose research questions. What will software development tools look like in the future? How can we efficiently use AI to develop interactive systems without compromising quality? We also speculate about the implications of these developments for researchers, practitioners, and society. We believe that it will massively accelerate the digital transformation. Interactive AI-based tools for systems and software development will become a major research direction.},
booktitle = {Companion Proceedings of the 2023 ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
pages = {7–8},
numpages = {2},
keywords = {Software and System Development, Large Language Models, Interactive Systems, Engineering, ChatGPT, Automation},
location = {Swansea, United Kingdom},
series = {EICS '23 Companion}
}
  
@inproceedings{10.1145/3573382.3616033,
author = {Huang, Yuxuan},
title = {The Future of Generative AI: How GenAI Would Change Human-Computer Co-creation in the Next 10 to 15 Years},
year = {2023},
isbn = {9798400700293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573382.3616033},
doi = {10.1145/3573382.3616033},
abstract = {The past few years have witnessed a remarkable advancement in the field of Generative Artificial Intelligence (GenAI), a technology capable of generating new content based on input prompts and existing knowledge. This technology has the potential to revolutionize the way of human-computer co-creation. However, existing research on GenAI has primarily focused on technical aspects, and more research is needed from a design perspective, mainly through speculative and critical design. Therefore, this study aims to explore how GenAI would transform human-computer co-creation in the next 10 to 15 years by means of design fiction and playful critical design. The study will involve (co-)speculative workshops utilizing design fiction, followed by focus groups to gather insights. In addition, this research will examine the user experience issues of interacting with functional GenAI prototypes through playful critical design.},
booktitle = {Companion Proceedings of the Annual Symposium on Computer-Human Interaction in Play},
pages = {322–325},
numpages = {4},
keywords = {AI-generated content, design fiction, generative AI, playful critical design, speculative design},
location = {Stratford, ON, Canada},
series = {CHI PLAY Companion '23}
}
  
@inproceedings{10.1145/3613904.3642160,
author = {Sun, Yuan and Jang, Eunchae and Ma, Fenglong and Wang, Ting},
title = {Generative AI in the Wild: Prospects, Challenges, and Strategies},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642160},
doi = {10.1145/3613904.3642160},
abstract = {Propelled by their remarkable capabilities to generate novel and engaging content, Generative Artificial Intelligence (GenAI) technologies are disrupting traditional workflows in many industries. While prior research has examined GenAI from a techno-centric perspective, there is still a lack of understanding about how users perceive and utilize GenAI in real-world scenarios. To bridge this gap, we conducted semi-structured interviews with (N = 18) GenAI users in creative industries, investigating the human-GenAI co-creation process within a holistic LUA (Learning, Using and Assessing) framework. Our study uncovered an intriguingly complex landscape: Prospects – GenAI greatly fosters the co-creation between human expertise and GenAI capabilities, profoundly transforming creative workflows; Challenges – Meanwhile, users face substantial uncertainties and complexities arising from resource availability, tool usability, and regulatory compliance; Strategies – In response, users actively devise various strategies to overcome many of such challenges. Our study reveals key implications for the design of future GenAI tools.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {747},
numpages = {16},
keywords = {Generative AI, Human-AI Collaboration, Transparency, User Agency},
location = {Honolulu, HI, USA},
series = {CHI '24}
}
  
"><input type="hidden" name="dois" value="10.1145/3626772.3657982,10.1145/3633083.3633094,10.1145/3626253.3635543,10.1145/3660650.3660657,10.1145/3696630.3727235,10.1145/3563703.3591453,10.1145/3613904.3642296,10.1145/3665348.3665370,10.1145/3745238.3745459,10.1145/3633083.3633099,10.1145/3679318.3685370,10.1145/3613905.3636294,10.1145/3616961.3616978,10.1145/3641554.3701917,10.1145/3713043.3731498,10.1145/3665348.3665357,10.1145/3704217.3704224,10.1145/3665348.3665374,10.1145/3607822.3618018,10.1145/3706599.3721208,10.1145/3641032.3641055,10.1145/3658549.3658561,10.1145/3613904.3642800,10.5555/3711988.3711989,10.1145/3614419.3644014,10.1145/3706599.3720249,10.1145/3625468.3652912,10.1145/3613904.3641951,10.1145/3656650.3660544,10.1145/3637528.3671883,10.1145/3675812.3675874,10.1145/3715336.3735805,10.1145/3610542.3626142,10.1145/3581961.3609828,10.1145/3644116.3644221,10.1145/3686038.3686063,10.1145/3641555.3705235,10.1145/3702163.3702182,10.1145/3706599.3719804,10.1145/3709022.3736542,10.1145/3702386.3702394,10.1145/3706599.3719957,10.1145/3702653.3744328,10.1145/3712255.3734261,10.1145/3690712.3690717,10.1145/3733155.3737910,10.1145/3597503.3649400,10.1145/3596454.3597176,10.1145/3573382.3616033,10.1145/3613904.3642160"><input type="hidden" name="format" value="bibTex"><fieldset class="input-group"><label for="citation-format" class="visibility-hidden">Select Citation format</label><select id="citation-format" aria-label="Select Citation format"><option value="bibtex" data-format="bibTex">BibTeX</option><option value="endNote" data-format="endNote">EndNote</option><option value="acm" data-format="text">ACM Ref</option></select><span class="select-arrow"><i class="icon-bottom-arrow"></i></span></fieldset><ul class="rlist tab__content"><li id="allResultstab" aria-labelledby="allResults" role="tabpanel" class="tab__pane"><div class="all-results-tab-container"><div class="warning-message mb-2">Please download or close your previous search result export first before starting a new bulk export.</div><div class="desc-text"><div class="bold">Preview is not available.</div>By clicking download,<b class="ml-1">a status dialog</b> will open to start the export process. The process may take<b class="ml-1">a few minutes</b> but once it finishes a file will be downloadable from your browser. You may continue to browse the DL while the export process is in progress.</div><a href="#" title="Download" data-href="/action/searchCitationExport?query=AllField%3Dgenerative%2Bartificial%2Bintelligence%26content%3Dstandard%26pageSize%3D50%26startPage%3D9%26target%3Ddefault" class="btn transparent downloadBtn disabled"><i aria-hidden="true" class="icon-Icon_Download"></i>Download<i aria-hidden="true" class="icon-export"></i></a></div></li><li id="selectedTab" aria-labelledby="selected" role="tabpanel" class="tab__pane active"><div class="csl-wrapper copy__text-wrapper"><pre class="copy__text csl-response"><div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3626772.3657982,
author = {B\'{e}n\'{e}dict, Gabriel and Zhang, Ruqing and Metzler, Donald and Yates, Andrew and Jiang, Ziyan},
title = {Gen-IR @ SIGIR 2024: The Second Workshop on Generative Information Retrieval},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657982},
doi = {10.1145/3626772.3657982},
abstract = {Generative information retrieval (Gen-IR) is a fast-growing interdisciplinary research area that investigates how to leverage advances in generative Artificial Intelligence (AI) to improve information retrieval systems. Gen-IR has attracted interest from the information retrieval, natural language processing, and machine learning communities, among others. Since the dawn of Gen-IR last year, there has been an explosion of Gen-IR systems that have launched and are now widely used. Interest in this area across academia and industry is only expected to continue to grow as new research challenges and application opportunities arise. The goal of this proposed workshop, The Second Workshop on Generative Information Retrieval (Gen-IR @ SIGIR 2024) is to provide an interactive venue for exploring a broad range of foundational and applied Gen-IR research. The workshop will focus on tasks such as generative document retrieval, grounded answer generation, generative recommendation, and generative knowledge graphs, all through the lens of model training, model behavior, and broader issues. The workshop will be highly interactive, favoring panel discussions, poster sessions, and roundtable discussions over one-sided keynotes and paper talks.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3029–3032},
numpages = {4},
keywords = {generative models, information retrieval, large language models},
location = {Washington DC, USA},
series = {SIGIR '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3633083.3633094,
author = {Marassi, Lidia},
title = {Assessing User Perceptions of Bias in Generative AI Models: Promoting Social Awareness for Trustworthy AI},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633094},
doi = {10.1145/3633083.3633094},
abstract = {Recently, generative Artificial Intelligence (AI) models have experienced an incredible surge in interest and use. The proliferation of these technologies suggests that it would be prudent to raise awareness of the potential consequences of irresponsible use of these models. Indeed, to achieve trustworthy AI solutions, it is essential to promote AI education as a fundamental step. Educating people to use AI responsibly not only improves their understanding of the technology, but also equips them to address issues of bias and discrimination. Indeed, informed users are more likely to recognize when AI is producing biased or discriminatory results and to demand appropriate solutions. This awareness of the ethical implications of AI decisions is crucial for the responsible and socially conscious adoption of AI. The aim of this poster is to report the results obtained as a final thesis work, pursued within the context of the Human-Centred AI Masters (HCAIM) programme in Naples, focused on the analysis of users’ perceptions of biases in media created by generative AI models.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {46},
numpages = {1},
keywords = {AI Ethics, Bias, Generative AI, Social Awareness, Trustworthy AI},
location = {Dublin, Ireland},
series = {HCAIep '23}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3626253.3635543,
author = {Glynn, Colin and Hed, Emily and Pexa, Abbigail and Pohlmann, Tyler and Rahal, Imad and Hesse, Robert},
title = {CAET: Code Analysis and Education Tutor},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635543},
doi = {10.1145/3626253.3635543},
abstract = {The introduction of OpenAI's ChatGPT in 2022 kickstarted the release of Generative Artificial Intelligence (GAI) applications to the public domain. Such chat interfaces are based on large language models (LLMs) and possess a vast array of abilities spanning conversation, the writing and debugging of code, the writing of papers, and the creation of images, music, and songs. With students now having access to a myriad of GAI tools, academia has been permanently altered.Our proposed system, named Code Analysis and Education Tutor (CAET), integrates GAI into early Computer Science education by providing students with an ethical alternative to existing GAI tools. CAET is designed to assist students with programming tasks in a manner tailored to their individual needs without jeopardizing the integrity of their learning. A point of uniqueness from existing works is CAET's ability to display or hide generated code based on its pertinence to the problem at hand. After subjecting multiple GAI models to common programming errors and queries, we settled on OpenAI's GPT-3.5 Turbo model due to its comprehensive capabilities and cost-effectiveness. Overall, CAET underscored the model's conversational dynamics and provided insights for creating a more personalized learning experience for students in an introductory computer science course.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1656–1657},
numpages = {2},
keywords = {computer science education, generative artificial intelligence, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3660650.3660657,
author = {Roberts, Jordan and Mohamed, Abdallah},
title = {Generative AI in CS Education: Literature Review through a SWOT Lens},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660657},
doi = {10.1145/3660650.3660657},
abstract = {The rapid growth of generative artificial intelligence (AI) models introduced challenges for educators, students and administrators across the academic sphere related to how to manage and regulate these tools. While some oppose their use, many researchers have begun to approach the topic of educational AI use from a different perspective. Despite being in its early stages; this field of research has produced notable insights into the capabilities and limitations of models like ChatGPT. This paper utilizes a SWOT analysis framework to analyze and consolidate existing literature, with a specific focus on Computer Science education. Through the analysis of this literature, we have created a set of use cases and guidelines to aid in the future development of strategies and tools within this field. Our findings indicate that while some concerns are valid, such as AI's ability to generate plagiarized work, we identified several promising avenues and opportunities for careful integration of this technology into education.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {10},
numpages = {6},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3696630.3727235,
author = {Hyrynsalmi, Sonja and Tuape, Micheal and Knutas, Antti},
title = {"Person is a person, a tool is a tool" - ChatGPT’s Role in Student Help-Seeking Behavior and Peer Support},
year = {2025},
isbn = {9798400712760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696630.3727235},
doi = {10.1145/3696630.3727235},
abstract = {Generative Artificial Intelligence (GenAI) tools, such as ChatGPT, are reshaping higher education. In research, a lot of attention has been given to concerns like academic integrity and how to integrate AI into learning and teaching. However, little is known about how these tools impact student help-seeking patterns and peer interactions. This short paper investigates GenAI tools, help-seeking preferences and the importance of peer support among first-year software engineering students (n=94). Our responses show that 50\% of the students use GenAI tools as the primary source of help-seeking, and 43\% report that using ChatGPT reduces their need to interact with peers. However, students generally recognize the importance of social interaction and peer support for their learning. We use these duality findings to extend previous recommendations for integrating generative AI in education by providing new recommendations on how educators can support help-seeking and peer support in the age of GenAI.},
booktitle = {Proceedings of the 33rd ACM International Conference on the Foundations of Software Engineering},
pages = {783–788},
numpages = {6},
keywords = {help-seeking, peer-support, informal learning, software engineering education and teaching},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {FSE Companion '25}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3563703.3591453,
author = {Van Der Maden, Willem and Van Beek, Evert and Nicenboim, Iohanna and Van Der Burg, Vera and Kun, Peter and Lomas, James Derek and Kang, Eunsu},
title = {Towards a Design (Research) Framework with Generative AI},
year = {2023},
isbn = {9781450398985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563703.3591453},
doi = {10.1145/3563703.3591453},
abstract = {This one day workshop will explore the use of Generative Artificial Intelligence (GenAI) in design research and practice. Generative technologies are developing rapidly and many designers are using them. Yet, there remains little published work on the use of GenAI in design. Our goal is to not only showcase the potential of GenAI for design, but to engage in discussions of its shortcomings and opportunities as they have been already articulated by scholars. By synthesizing both published and unpublished works, we will develop best practices, ethical considerations, and future research directions for the use of GenAI in design. We will explore a range of topics and themes, including leveraging the characteristics of GenAI for design, mapping the diverse applications of GenAI in design, envisioning a framework for design, and guiding future work on GenAI in design research. Ultimately, we hope to provide a roadmap for the integration of GenAI into the design research process and to encourage designers and researchers to explore the potential of GenAI in a thoughtful and deliberate way.},
booktitle = {Companion Publication of the 2023 ACM Designing Interactive Systems Conference},
pages = {107–109},
numpages = {3},
keywords = {computational creativity, creative practices, design research, generative artificial intelligence},
location = {Pittsburgh, PA, USA},
series = {DIS '23 Companion}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3613904.3642296,
author = {Berney, Manon and Ouaazki, Abdessalam and Macko, Vladimir and Kocher, Bruno and Holzer, Adrian},
title = {Care-Based Eco-Feedback Augmented with Generative AI: Fostering Pro-Environmental Behavior through Emotional Attachment},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642296},
doi = {10.1145/3613904.3642296},
abstract = {Lights out! With the escalating climate crisis, eco-feedback has gained prominence over the last decade. However, traditional approaches could be underperforming as they often use data-driven strategies and assume that people only need additional information about their consumption to change behavior. A proposed path to overcome this issue is to design eco-feedback to foster emotional connections with users. However, not much is known about the effectiveness of such designs. In this paper, we propose a novel care-based eco-feedback system. Central to the system is a Tamagotchi-inspired digital character named Infi who gets its life force from the user’s energy savings. Additionally, we harness the latest advancements in generative artificial intelligence to enhance emotional attachment through conversational interactions that users can have with Infi. The results of a randomized controlled experiment (N=420) convey the fact that this design increases emotional attachment, which in turn increases energy-saving behavior.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {469},
numpages = {15},
keywords = {care-based intervention, conversational interaction, eco-feedback, emotional attachment, gamification, generative AI},
location = {Honolulu, HI, USA},
series = {CHI '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3665348.3665370,
author = {Lu, Qianlong and Gao, Maoting},
title = {A Research on Shilling Attacks Based on Variational graph auto-encoders for Improving the Robustness of Recommendation Systems},
year = {2024},
isbn = {9798400709562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665348.3665370},
doi = {10.1145/3665348.3665370},
abstract = {As personalized recommendation techniques continue to evolve and be applied, recommendation systems face a plethora of malicious attacks. In order to defend against potential malicious attacks, enhance the robustness of recommendation systems, and strengthen their ability to withstand attacks, it is necessary to propose a method based on Variational Graph Auto-encoders (VGAE) for generating shilling attacks. This method improves the VGAE model, models user profiles, and generates reconstructed user profiles that conform to the original rating patterns. By utilizing spectral clustering, users are selected from the original dataset as templates in a dispersed manner according to a certain attack scale. These templates are then matched with the most similar fake users in the reconstructed user profiles. Within these fake user profiles, ratings for the most popular items in each category and target item ratings are inserted. Finally, fake user profiles are generated and injected into the recommendation system to broadly promote target items to users of the system. Experimental results on the MovieLens 100k and 1M datasets demonstrate that this new method exhibits more stable attack performance and stronger detection evasion capabilities compared to traditional attack strategies, thereby better exposing existing issues within recommendation systems.},
booktitle = {Proceedings of the 2024 International Conference on Generative Artificial Intelligence and Information Security},
pages = {120–126},
numpages = {7},
location = {Kuala Lumpur, Malaysia},
series = {GAIIS '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3745238.3745459,
author = {Huang, Zhenxiong},
title = {Application of AIGC in multilingual teaching in higher education},
year = {2025},
isbn = {9798400712791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3745238.3745459},
doi = {10.1145/3745238.3745459},
abstract = {This study systematically evaluates the technological realization path and social benefits of generative artificial intelligence (AIGC) in multilingual teaching and learning in higher education.  Based on current advanced multilingual model architectures and cross-modal content generation technologies, an automatic generation system for teaching resources supporting 12 languages is constructed.  Experimental data showed that the system led to a 41.2\% increase in learning efficiency in a Tamil course at the Indian Institute of Technology (IIT) (p&lt;0.01, n=320), while a test of teaching Chinese as a second language at the Beijing Language and Culture University (BLCU) showed that AIGC-generated personalized exercises reduced the learner error rate by 33.7\%.  The study further revealed that (i) the cost of generating instructional materials for low-resource languages (e.g., Kiswahili) decreased to 18.5\% of the traditional approach;  and (ii) through an authoritative equity assessment framework, it was confirmed that the technological solution could narrow the digital education divide between developing and developed countries by up to 27.3 percentage points.  This provides actionable technological support for the equity goals of the UN's Education 2030 Agenda.},
booktitle = {Proceedings of the 2nd Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {1414–1418},
numpages = {5},
keywords = {AIGC, Digital Transformation, Educational equity, Multilingual education},
location = {
},
series = {DEAI '25}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3633083.3633099,
author = {Stone, Irene},
title = {Exploring the Research Gap: Generative AI and Learning of Python Programming among Post-Primary Students},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633099},
doi = {10.1145/3633083.3633099},
abstract = {The introduction of Leaving Certificate Computer Science (LCCS) in Ireland in 2018 signifies a notable advancement in post-primary education. Moreover, developments in generative Artificial Intelligence (GAI) in education, are gaining prominence, yet we do not understand its value or how best to implement it in post-primary educational settings. Despite a growing international body of research in this area, my scoping review highlights that many aspects of these topics have yet to be explored, particularly in the context of post-primary students in Ireland. My study will begin to bridge this gap by exploring how a purposeful sample of LCCS post-primary students in Ireland engage with GAI tools, such as ChatGPT, during their initial experiences learning Python programming. These findings, when approached through the lens of Human-Centred Artificial Intelligence (HCAI), can help enhance pedagogical strategies and lead to improved learning experiences for students.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {51},
numpages = {1},
location = {Dublin, Ireland},
series = {HCAIep '23}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3679318.3685370,
author = {Park, Hyerim and Eirich, Joscha and Luckow, Andre and Sedlmair, Michael},
title = {"We Are Visual Thinkers, Not Verbal Thinkers!": A Thematic Analysis of How Professional Designers Use Generative AI Image Generation Tools},
year = {2024},
isbn = {9798400709661},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3679318.3685370},
doi = {10.1145/3679318.3685370},
abstract = {Generative artificial intelligence (GenAI) has become increasingly popular, influencing various creative domains. However, while broader societal perspectives have been analyzed, specific examinations of how practitioners utilize GenAI tools to enhance their current workflows remain limited. To address this gap, we conducted a qualitative study involving 16 professional designers from the automotive industry. We aimed to identify their challenges with existing GenAI image generation tools in daily design practices. Thematic analysis revealed four key themes: (1) the need for visual input-centric multi-modal interfaces that extend beyond textual prompts, (2) the lack of support for the iterative nature of design processes in GenAI tools, (3) difficulties in controlling prompts to achieve desired outputs, and (4) the significance of incorporating human experiences and emotions into design. Based on our findings, we propose and discuss potential design considerations for enhancing future GenAI image generation tool interfaces.},
booktitle = {Proceedings of the 13th Nordic Conference on Human-Computer Interaction},
articleno = {35},
numpages = {14},
keywords = {creativity support tools, generative AI, human-AI interaction, qualitative research},
location = {Uppsala, Sweden},
series = {NordiCHI '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3613905.3636294,
author = {Muller, Michael and Kantosalo, Anna and Maher, Mary Lou and Martin, Charles Patrick and Walsh, Greg},
title = {GenAICHI 2024: Generative AI and HCI at CHI 2024},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636294},
doi = {10.1145/3613905.3636294},
abstract = {This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI), and - among other approaches - particularly to Large Language Models (LLMs) and Foundation Models (FMs). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together. Following successful workshops in 2022 and 2023, we convene the interdisciplinary research domain of generative AI and HCI. Participation in this invitational workshop is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {470},
numpages = {7},
keywords = {Bias, Design, Generative AI, Uncertainty.},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3616961.3616978,
author = {Oppenlaender, Jonas and Silvennoinen, Johanna and Paananen, Ville and Visuri, Aku},
title = {Perceptions and Realities of Text-to-Image Generation},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616978},
doi = {10.1145/3616961.3616978},
abstract = {Generative artificial intelligence (AI) is a widely popular technology that will have a profound impact on society and individuals. Less than a decade ago, it was thought that creative work would be among the last to be automated&nbsp;– yet today, we see AI encroaching on many creative domains. In this paper, we present the findings of a survey study on people’s perceptions of text-to-image generation. We touch on participants’ technical understanding of the emerging technology, their fears and concerns, and thoughts about risks and dangers of text-to-image generation to the individual and society. We find that while participants were aware of the risks and dangers associated with the technology, only few participants considered the technology to be a personal risk. The risks for others were more easy to recognize for participants. Artists were particularly seen at risk. Interestingly, participants who had tried the technology rated its future importance lower than those who had not tried it. This result shows that many people are still oblivious of the potential personal risks of generative artificial intelligence and the impending societal changes associated with this technology.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {279–288},
numpages = {10},
keywords = {text-to-image generation, generative AI},
location = {Tampere, Finland},
series = {Mindtrek '23}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3641554.3701917,
author = {Wang, Kevin Shukang and Lawrence, Ramon},
title = {Quantitative Evaluation of Using Large Language Models and Retrieval-Augmented Generation in Computer Science Education},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701917},
doi = {10.1145/3641554.3701917},
abstract = {Generative artificial intelligence (GenAI) is transforming Computer Science education, and every instructor is reflecting on how AI will impact their courses. Instructors must determine how students may use AI for course activities and what AI systems they will support and encourage students to use. This task is challenging with the proliferation of large language models (LLMs) and related AI systems. The contribution of this work is an experimental evaluation of the performance of multiple open-source and commercial LLMs utilizing retrieval-augmented generation in answering questions for computer science courses and a cost-benefit analysis for instructors when determining what systems to use. A key factor is the time an instructor has to maintain their supported AI systems and the most effective activities for improving their performance. The paper offers recommendations for deploying, using, and enhancing AI in educational settings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1183–1189},
numpages = {7},
keywords = {artificial intelligence, human-in-the-loop, large language model, question answering, retrieval-augmented generation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inbook{10.1145/3713043.3731498,
author = {Dangol, Aayushi and Wolfe, Robert and Yoo, Daeun and Thiruvillakkat, Arya and Chickadel, Ben and Kientz, Julie A.},
title = {If anybody finds out you are in BIG TROUBLE”: Understanding Children’s Hopes, Fears, and Evaluations of Generative AI},
year = {2025},
isbn = {9798400714733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713043.3731498},
abstract = {As generative artificial intelligence (genAI) increasingly mediates how children learn, communicate, and engage with digital content, understanding children’s hopes and fears about this emerging technology is crucial. In a pilot study with 37 fifth-graders, we explored how children (ages 9–10) envision genAI and the roles they believe it should play in their daily life. Our findings reveal three key ways children envision genAI: as a companion providing guidance, a collaborator working alongside them, and a task automator that offloads responsibilities. However, alongside these hopeful views, children expressed fears about overreliance, particularly in academic settings, linking it to fears of diminished learning, disciplinary consequences, and long-term failure. This study highlights the need for child-centric AI design that balances these tensions, empowering children with the skills to critically engage with and navigate their evolving relationships with digital technologies.},
booktitle = {Proceedings of the 24th Interaction Design and Children},
pages = {872–877},
numpages = {6}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3665348.3665357,
author = {Wu, Junying and Lu, Yanyan and Li, Zixin and Peng, Jiao and Xu, Xing and Song, Hui},
title = {Word-Phrase Fusion Encoding Model for Natural Language Understanding in the Electric Power Field},
year = {2024},
isbn = {9798400709562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665348.3665357},
doi = {10.1145/3665348.3665357},
abstract = {Intelligent question-answering systems have been widely applied in the field of electric power. However, with the complexity of terms in the electric power field, the generic word-based encoding approach of natural language understanding model fails to identify those domain phrases even if they appear in the training samples. To improve the semantic accuracy of special content labeling, this paper proposes a words-phrase fusion encoding NLU model with the help of domain corpus. We pre-train a phrase-level Bert model in the electric power field which is involved during the model encoding step to accurately capture the semantics of domain terms and perceive the boundary of phrases. Additionally, continuous consistency loss of sequences is added to the model to reduce the to reduce the misclassification of individual words in the phrases. Experiment with real dataset in power QA system demonstrates that our model helps improve semantic parsing accuracy on both training and untrained items, alleviates the complete dependency of the phrase encoding model on word segmentation results.},
booktitle = {Proceedings of the 2024 International Conference on Generative Artificial Intelligence and Information Security},
pages = {43–49},
numpages = {7},
location = {Kuala Lumpur, Malaysia},
series = {GAIIS '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3704217.3704224,
author = {Qi, Linyi and Zhu, Jiangqin},
title = {Visualizing Research Trends on the Use of Generative AI in Assessment in the WOS database from 2019 to 2024 via Vosviewer and CiteSpace},
year = {2025},
isbn = {9798400707094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704217.3704224},
doi = {10.1145/3704217.3704224},
abstract = {The first typical generative Artificial Intelligence (Gen AI) model ChatGpt 1 was introduced in 2018, but has not drawn much attention until the release of ChatGpt 3 in 2022. Since then, researchers and educators have been experimenting with Gen AI tools to explore their possibilities in various fields. In education, the use of Gen AI in assessment is a research focus. To reveal the research patterns in this field, the study employed Vosviewer and CiteSpace to analyze 816 papers in the Web of Science (WOS) database published between 2019 and 2024. The annual publications surged during the period of 2023-2024 due to the release of higher versions of Gen AI tools such as ChatGpt 3. Researchers in the United States, United Kingdom and China engage most actively in the field. American and Hong Kong universities are particularly productive. However, the collaboration between institutions and authors still needs to be enhanced. Highly influential journals such as Nature and famous medical journals such as JMIR Medical Education and Cureus Journal of Medical sciences are most frequently cited. The analysis of co-occurrence keywords and keyword clusters identified two research areas: responding to the academic integrity issue with the use of Gen AI in assessment and exploring the valuable use of Gen AI in assessments in higher education especially medical education. Future research could explore the design of innovative or alternative assessments and the use of Gen AI tools in interactive and game-based assessment creation, marking and feedback giving.},
booktitle = {Proceedings of the 2024 8th International Conference on E-Society, E-Education and E-Technology},
pages = {28–35},
numpages = {8},
keywords = {Academic integrity, Assessment, Education, Generative AI},
location = {
},
series = {ESET '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3665348.3665374,
author = {Zhang, Zongnan and Li, Meng and An, Xiaoxin and Li, Zhen and Ma, Zhe},
title = {Side-Channel Analysis of Curve-25519 Based on Deep Learning},
year = {2024},
isbn = {9798400709562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665348.3665374},
doi = {10.1145/3665348.3665374},
abstract = {This paper explores the integration of deep learning technology with Side-Channel Analysis (SCA) methods to effectively analyze the Curve-25519 algorithm implemented on an MCU chip. The Curve-25519 algorithm, protected by the security features of elliptical curve algorithms and constant-time operations, presents a challenge for low-cost, non-invasive SCA methods due to its robustness. This work focuses on the leakage of conditional judgment operations that occur before each point addition and point doubling operation. By identifying these information leakage points through SCA, electromagnetic radiation and power consumption information are collected and labeled. We conduct a dataset and transformed 1-dimensional signals into a 2D image for training. The trained model is subsequently used for testing. Experiments demonstrate that this method can effectively analyze leakage points in the Curve-25519 algorithm and help to improve the robustness of the algorithm.},
booktitle = {Proceedings of the 2024 International Conference on Generative Artificial Intelligence and Information Security},
pages = {144–149},
numpages = {6},
location = {Kuala Lumpur, Malaysia},
series = {GAIIS '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3607822.3618018,
author = {Hu, Yongquan and Zhang, Dawen and Quigley, Aaron},
title = {GenAIR: Exploring Design Factor of Employing Generative AI for Augmented Reality},
year = {2023},
isbn = {9798400702815},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607822.3618018},
doi = {10.1145/3607822.3618018},
abstract = {Generative Artificial Intelligence (GenAI) has emerged as a fundamental component of intelligent interactive systems, enabling the automatic generation of multimodal media content. The continuous enhancement in the quality of Artificial Intelligence-Generated Content (AIGC), including but not limited to images and text, is forging new paradigms for its application, particularly within the domain of Augmented Reality (AR). Nevertheless, the application of GenAI within the AR design process remains opaque. This paper aims to articulate a design space encapsulating a series of criteria and a prototypical process to aid practitioners in assessing the aptness of adopting pertinent technologies. The proposed model has been formulated based on a synthesis of design insights garnered from ten experts, obtained through focus group interviews. Leveraging these initial insights, we delineate potential applications of GenAI in AR.},
booktitle = {Proceedings of the 2023 ACM Symposium on Spatial User Interaction},
articleno = {47},
numpages = {3},
keywords = {Design Factor, Generative AI, Spatial Augmented Reality},
location = {Sydney, NSW, Australia},
series = {SUI '23}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3706599.3721208,
author = {Wang, Amy and Ruparel, Roma and Iurchenko, Anna and Jhun, Paul and S\'{e}guin, Julie Anne and Strachan, Patricia and Wong, Renee and Karthikesalingam, Alan and Matias, Yossi and Hassidim, Avinatan and Webster, Dale and Semturs, Christopher and Krause, Jonathan and Schaekermann, Mike},
title = {Generative AI for medical education: Insights from a case study with medical students and an AI tutor for clinical reasoning},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3721208},
doi = {10.1145/3706599.3721208},
abstract = {Generative Artificial Intelligence (AI), particularly Large Language Models (LLMs), have demonstrated significant potential in clinical reasoning skills such as history-taking and differential diagnosis generation—critical aspects of medical education. This work explores how LLMs can augment medical curricula through interactive learning. We conducted a participatory design process with medical students, residents and medical education experts to co-create an AI-powered tutor prototype for clinical reasoning. As part of the co-design process, we conducted a qualitative user study, investigating learning needs and practices via interviews, and conducting concept evaluations through interactions with the prototype. Findings highlight the challenges learners face in transitioning from theoretical knowledge to practical application, and how an AI tutor can provide personalized practice and feedback. We conclude with design considerations, emphasizing the importance of context-specific knowledge and emulating positive preceptor traits, to guide the development of AI tools for medical education.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {303},
numpages = {8},
keywords = {Education, Medicine, Generative AI, Large Language Models},
location = {
},
series = {CHI EA '25}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3641032.3641055,
author = {Faccia, Alessio and Ridon, Manjeet and Beebeejaun, Zeenat and Mosteanu, Narcisa Mosteanu Roxana},
title = {Advancements and Challenges of Generative AI in Higher Educational Content Creation A Technical Perspective},
year = {2024},
isbn = {9798400709173},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641032.3641055},
doi = {10.1145/3641032.3641055},
abstract = {Generative Artificial Intelligence (AI) has witnessed remarkable advancements, igniting interest in various domains, including Higher Education. This research paper explores the impacts and challenges of integrating Generative AI in content creation within Higher Education. We utilise a literature review and case study approach to gain insights into the potential benefits and complexities of implementing Generative AI in educational settings. Specific research questions are formulated to investigate the influence of Generative AI on content creation efficiency, productivity, quality, and adaptability. The paper also highlights ethical considerations and the evolving role of educators in the AI-driven educational landscape. Furthermore, the research paper examines the practical applications of Generative AI tools such as OpenAI GPT, GPT-Neo, Hugging Face's Transformers Library, Cognii, MosaChat-AI, TeacherMatic, and OpenAI Codex in Higher Education content creation. This comprehensive analysis aims to provide educators, instructional designers, and policymakers with valuable insights and concrete examples of how Generative AI can be leveraged to create personalised learning materials, improve assessment strategies, and enhance the overall educational experience for students pursuing advanced technical subjects. The culmination of this research presents a vision for a future where Generative AI, thoughtfully implemented and ethically managed, empowers educational institutions to meet the diverse and evolving needs of learners in the digital era.},
booktitle = {Proceedings of the 2023 8th International Conference on Information Systems Engineering},
pages = {48–54},
numpages = {7},
keywords = {Applications, Chat GPT, Generative AI, Higher Education},
location = {Bangkok, Thailand},
series = {ICISE '23}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3658549.3658561,
author = {Ke, Chih-Kun and Wu, Mei-Yu and Chung, Bor-Lin},
title = {Automation, Trustworthy, Intelligent Prenatal Examinations - I Do!!},
year = {2024},
isbn = {9798400709180},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658549.3658561},
doi = {10.1145/3658549.3658561},
abstract = {Medical institutions are looking forward to importing innovative information services to reduce the burden on medical staff. For example, medical staff repeatedly process the contextual data in each stage of the prenatal examinations, which is labor-intensive and time-consuming. If a dispute happens, the data will become the evidence to support whether the prenatal examinations were handled appropriately. Therefore, if the prenatal examination data is not accurately recorded and properly preserved, it will become a source of pressure for medical staff to face disputes in the future. This research takes the prenatal examinations of pregnant as a use case. We apply robotic process automation technology to assist in the automation of prenatal examinations and blockchain technology to establish trustworthy prenatal examinations. Besides, we also use generative artificial intelligence technology to provide intelligent user-assisted consultation in open-domain question answering. The contribution of this work is to build an automated reliable prenatal examination information service to provide good care for pregnant.},
booktitle = {Proceedings of the 2024 International Conference on Information Technology, Data Science, and Optimization},
pages = {42–47},
numpages = {6},
location = {Taipei, Taiwan},
series = {I-DO '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3613904.3642800,
author = {Jin, Yucheng and Cai, Wanling and Chen, Li and Zhang, Yizhe and Doherty, Gavin and Jiang, Tonglin},
title = {Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642800},
doi = {10.1145/3613904.3642800},
abstract = {Music-based reminiscence has the potential to positively impact the psychological well-being of older adults. However, the aging process and physiological changes, such as memory decline and limited verbal communication, may impede the ability of older adults to recall their memories and life experiences. Given the advanced capabilities of generative artificial intelligence (AI) systems, such as generated conversations and images, and their potential to facilitate the reminiscing process, this study aims to explore the design of generative AI to support music-based reminiscence in older adults. This study follows a user-centered design approach incorporating various stages, including detailed interviews with two social workers and two design workshops (involving ten older adults). Our work contributes to an in-depth understanding of older adults’ attitudes toward utilizing generative AI for supporting music-based reminiscence and identifies concrete design considerations for the future design of generative AI to enhance the reminiscence experience of older adults.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1012},
numpages = {17},
keywords = {Generative AI, Human-AI Interaction, Music-based Reminiscence, Older Adults, Reminiscence},
location = {Honolulu, HI, USA},
series = {CHI '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@article{10.5555/3711988.3711989,
author = {Tham, Jason},
title = {Teaching UX: Amid the Hype of Generative AI},
year = {2025},
issue_date = {November 2024},
publisher = {Usability Professionals' Association},
address = {Bloomingdale, IL},
volume = {20},
number = {1},
issn = {1931-3357},
abstract = {I am a faculty member in a technical communication program at a comprehensive research university. Recently, I have been inundated with questions, concerns, and critiques about the rise of augmentation technologies in writing and design processes, particularly generative artificial intelligence (AI) tools that support chat-based text generation and text-to-image production. I'm sure many UX researchers and designers face similar issues in their work. It remains unclear how generative AI should fit into existing workflow or design processes. Common questions include these:• How does AI work? What can it do? Is it free?• Is it cheating if I use AI to produce content?• Who is responsible for the quality of AI-generated content?• To what extent can I outsource my routine work to AI? In other words, what's an acceptable threshold for using AI before it is considered too much?Specific to UX is the value (cost and labor versus gains and effects) of generative AI in the research and design of user-centered products. Students in my UX courses are increasingly worried about the presence of AI and, consequently, the relevance of their developing skill sets in UX. Educators are growing wary about the presence of AI in the context of teaching and learning; many form partially informed decisions on academic policies for AI usage.},
journal = {J. User Exper.},
month = feb,
pages = {1–8},
numpages = {8}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3614419.3644014,
author = {Wu, Chuhao and Wang, Xinyu and Carroll, John and Rajtmajer, Sarah},
title = {Reacting to Generative AI: Insights from Student and Faculty Discussions on Reddit},
year = {2024},
isbn = {9798400703348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614419.3644014},
doi = {10.1145/3614419.3644014},
abstract = {Generative Artificial intelligence (GenAI) such as ChatGPT has elicited strong reactions from almost all stakeholders across the education system. Education-oriented and academic social media communities provide an important venue for these stakeholders to share experiences and exchange ideas about GenAI, which is constructive for developing human-centered policies. This study examines early user reactions to GenAI, consisting of 725 Reddit threads between 06/2022 and 05/2023. Through natural language processing (NLP) and content analysis, we observe an increasingly negative sentiment in the discussion and identify six main categories of student and faculty experiences of GenAI in education. These experiences reflect concerns about academic integrity and AI’s negative impact on the values of traditional education. Our analysis also highlights the tension and burden imposed by new technologies. Our findings suggest that dialogue between stakeholders in the education community is critical and can mitigate sources of tension between students and faculty.},
booktitle = {Proceedings of the 16th ACM Web Science Conference},
pages = {103–113},
numpages = {11},
keywords = {Generative AI, Higher Education, Social Media, Topic Modeling},
location = {Stuttgart, Germany},
series = {WEBSCI '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3706599.3720249,
author = {Reinhard, Philipp and Li, Mahei Manhai and Fina, Matteo and Leimeister, Jan Marco},
title = {Fact or Fiction? Exploring Explanations to Identify Factual Confabulations in RAG-Based LLM Systems},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720249},
doi = {10.1145/3706599.3720249},
abstract = {The adoption of generative artificial intelligence (GenAI) and large language models (LLMs) in society and business is growing rapidly. While these systems often generate convincing and coherent responses, they risk producing incorrect or non-factual information, known as confabulations or hallucinations. Consequently, users must critically assess the reliability of these outputs when interacting with LLM-based agents. Although advancements such as retrieval-augmented generation (RAG) have improved the technical performance of these systems, there is a lack of empirical models that explain how humans detect confabulations. Building on the explainable AI (XAI) literature, we examine the role of reasoning-based explanations in helping users identify confabulations in LLM systems. An online experiment (n = 97) reveals that analogical and factual explanations improve detection accuracy but require more time and cognitive effort than the no explanation baseline.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {274},
numpages = {13},
keywords = {Generative AI, Explainable AI, XAI, RAG, LLM, Confabulations, Hallucinations, GenXAI},
location = {
},
series = {CHI EA '25}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3625468.3652912,
author = {Artioli, Emanuele},
title = {Generative AI for HTTP Adaptive Streaming},
year = {2024},
isbn = {9798400704123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625468.3652912},
doi = {10.1145/3625468.3652912},
abstract = {Video streaming stands as the cornerstone of telecommunication networks, constituting over 60\% of mobile data traffic as of June 2023. The paramount challenge faced by video streaming service providers is ensuring high Quality of Experience (QoE) for users. In HTTP Adaptive Streaming (HAS), including DASH and HLS, video content is encoded at multiple quality versions, with an Adaptive Bitrate (ABR) algorithm dynamically selecting versions based on network conditions. Concurrently, Artificial Intelligence (AI) is revolutionizing the industry, particularly in content recommendation and personalization. Leveraging user data and advanced algorithms, AI enhances user engagement, satisfaction, and video quality through super-resolution and denoising techniques.However, challenges persist, such as real-time processing on resource-constrained devices, the need for diverse training datasets, privacy concerns, and model interpretability. Despite these hurdles, the promise of Generative Artificial Intelligence emerges as a transformative force. Generative AI, capable of synthesizing new data based on learned patterns, holds vast potential in the video streaming landscape. In the context of video streaming, it can create realistic and immersive content, adapt in real time to individual preferences, and optimize video compression for seamless streaming in low-bandwidth conditions.This research proposal outlines a comprehensive exploration at the intersection of advanced AI algorithms and digital entertainment, focusing on the potential of generative AI to elevate video quality, user interactivity, and the overall streaming experience. The objective is to integrate generative models into video streaming pipelines, unraveling novel avenues that promise a future of dynamic, personalized, and visually captivating streaming experiences for viewers.},
booktitle = {Proceedings of the 15th ACM Multimedia Systems Conference},
pages = {516–519},
numpages = {4},
keywords = {Generative AI, Video Streaming},
location = {Bari, Italy},
series = {MMSys '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3613904.3641951,
author = {Mim, Nusrat Jahan and Nandi, Dipannita and Khan, Sadaf Sumyia and Dey, Arundhuti and Ahmed, Syed Ishtiaque},
title = {In-Between Visuals and Visible: The Impacts of Text-to-Image Generative AI Tools on Digital Image-making Practices in the Global South},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641951},
doi = {10.1145/3613904.3641951},
abstract = {This paper joins the growing body of HCI work on critical AI studies and focuses on the impact of Generative Artificial Intelligence (GAI) tools in Bangladesh. While the West has started to examine the limitations and risks associated with these tools, their impacts on the Global South have remained understudied. Based on our interviews, focus group discussions (FGD), and social media-based qualitative study, this paper reports how popular text-to-image GAI tools (ex., DALL-E, Midjourney, Stable Diffusion, Firefly) are affecting various image-related local creative fields. We report how these tools limit the creative explorations of marginal artists, struggle to understand linguistic nuances, fail to generate local forms of art and architecture, and misrepresent the diversity among citizens in the image production process. Drawing from a rich body of work on critical image theory, postcolonial computing, and design politics, we explain how our findings are pertinent to HCI’s broader interest in social justice, decolonization, and global development.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {474},
numpages = {18},
keywords = {Architecture, Art, Artificial Intelligence, Generative AI, Image, Urban Design},
location = {Honolulu, HI, USA},
series = {CHI '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3656650.3660544,
author = {Inkpen, Kori},
title = {Achievement Unlocked: The Future of Human-AI Experiences},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3660544},
doi = {10.1145/3656650.3660544},
abstract = {We are currently witnessing the rapid evolution of Generative Artificial Intelligence (Gen-AI), marking the beginning of a transformative era. Gen-AI is not only revolutionizing what we can achieve with computing but also redefining how we engage with this new medium. Much like the printing press, which unlocked immense potential as a tool, its true value was fully realized when paired with human creativity. Similarly, the true magic of AI lies in the experiences it will empower when combined with human ingenuity. This talk will explore new research directions in Human-Computer Interaction that enable us to leverage the power of Gen-AI, shaping the experiences we create to empower individuals in the future.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {2},
numpages = {1},
keywords = {Generative User Interfaces, Human-AI Experiences, Human-Centered AI, Human-Computer Interaction},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3637528.3671883,
author = {Oosterhuis, Harrie and Jagerman, Rolf and Qin, Zhen and Wang, Xuanhui and Bendersky, Michael},
title = {Reliable Confidence Intervals for Information Retrieval Evaluation Using Generative A.I.},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671883},
doi = {10.1145/3637528.3671883},
abstract = {The traditional evaluation of information retrieval (IR) systems is generally very costly as it requires manual relevance annotation from human experts. Recent advancements in generative artificial intelligence -specifically large language models (LLMs)- can generate relevance annotations at an enormous scale with relatively small computational costs. Potentially, this could alleviate the costs traditionally associated with IR evaluation and make it applicable to numerous low-resource applications. However, generated relevance annotations are not immune to (systematic) errors, and as a result, directly using them for evaluation produces unreliable results.In this work, we propose two methods based on prediction-powered inference and conformal risk control that utilize computer-generated relevance annotations to place reliable confidence intervals (CIs) around IR evaluation metrics. Our proposed methods require a small number of reliable annotations from which the methods can statistically analyze the errors in the generated annotations. Using this information, we can place CIs around evaluation metrics with strong theoretical guarantees. Unlike existing approaches, our conformal risk control method is specifically designed for ranking metrics and can vary its CIs per query and document. Our experimental results show that our CIs accurately capture both the variance and bias in evaluation based on LLM annotations, better than the typical empirical bootstrapping estimates. We hope our contributions bring reliable evaluation to the many IR applications where this was traditionally infeasible.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2307–2317},
numpages = {11},
keywords = {confidence intervals, conformal prediction, generative A.I., information retrieval evaluation, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3675812.3675874,
author = {Liu, Liyuan and Mendoza, Ruben A. and Martin, Thomas R. and Miori, Virginia M.},
title = {Generative AI-Powered Educational Alignment: A Framework for Matching Syllabus Course Topics with Web Description},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675874},
doi = {10.1145/3675812.3675874},
abstract = {The application of generative artificial intelligence (GAI) in the educational sector is increasingly gaining attention from researchers. This study explores the congruence between online course descriptions and actual course syllabi to improve course preparation and consistency for instructors. Alignment between course catalog descriptions and actual course content as detailed in the syllabus can lead to learning improvements, student satisfaction, and academic alignment in a program. Our research introduces a novel framework utilizing GAI to systematically evaluates and identifies mismatches and suggests content to close the gap between online course descriptions and syllabus content. We used OpenAI’s ChatGPT to extract key topics from course syllabi and assessed the congruence between results and course description content with embedding methods such as BERT, GPT-2, RoBERTa, and DistilBERT, coupled with cosine similarity metrics. Our framework also integrates an outlier detection algorithm to identify courses with significant misalignments and use GAI applications to refine and enhance course catalog descriptions. This approach helps higher education institutions update course offerings with cutting-edge technology and contributes to curriculum development, helping improve student learning efficiency and course design.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {340–346},
numpages = {7},
keywords = {AI in education, ChatGPT, Curriculum alignment, Curriculum development, Generative AI, Syllabus analysis},
location = {Guangzhou, China},
series = {ICDEL '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3715336.3735805,
author = {Sandhaus, Hauke and Gu, Qiuquan and Parreira, Maria Teresa and Ju, Wendy},
title = {Co-Designing with Transformers: Unpacking the Complex Role of GenAI in Interactive System Design Education},
year = {2025},
isbn = {9798400714856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715336.3735805},
doi = {10.1145/3715336.3735805},
abstract = {Generative Artificial Intelligence (GenAI) is transforming Human-Computer Interaction (HCI) education and technology design, yet its impact remains poorly understood. This study explores how graduate students in an applied HCI course used GenAI tools during interactive device design. Despite no encouragement, all groups integrated GenAI into their workflows. Through 12 post-class group interviews, we identified how GenAI co-design behaviors present both benefits—such as enhanced creativity and faster design iterations—and risks, including shallow learning and reflection. Benefits were most evident during the execution phases, while the discovery and reflection phases showed limited gains. A taxonomy of usage patterns revealed that students’ outcomes depended more on how they used GenAI than the specific tasks performed. These findings highlight the need for HCI education to adapt to GenAI’s role and offer recommendations for curricula to better prepare future designers for effective creative co-design.},
booktitle = {Proceedings of the 2025 ACM Designing Interactive Systems Conference},
pages = {1228–1243},
numpages = {16},
keywords = {LLMs, GenAI, education, prototyping, user-centered design, ethics},
location = {
},
series = {DIS '25}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3610542.3626142,
author = {Wu, Yaokun and Kouta, Minamizawa and Yun Suen, Pai},
title = {OwnDiffusion: A Design Pipeline Using Design Generative AI to preserve Sense Of Ownership},
year = {2023},
isbn = {9798400703133},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610542.3626142},
doi = {10.1145/3610542.3626142},
abstract = {Generative Artificial Intelligence (AI) has been a fast-growing technology, well known for generating high-quality design drawings and images in seconds with a simple text input. However, users often feel uncertain about whether generative art should be considered created by AI or by themselves. Losing the sense of ownership of the outcome might impact the learning process and confidence of novice designers and design learners who seek to benefit from using Generative Design Tools. In this context, we propose OwnDiffusion, a design pipeline that utilizes Generative AI to assist in the physical prototype ideation process for novice product designers and industrial design learners while preserving their sense of ownership. The pipeline incorporates a prompt weight assessing tool, allowing designers to fine-tune the AI’s input based on their sense of ownership. We envision this method as a solution for AI-assisted design, enabling designers to maintain confidence in their creativity and ownership of a design.},
booktitle = {SIGGRAPH Asia 2023 Posters},
articleno = {28},
numpages = {2},
keywords = {Avatar, Emotion Regulation, Empathy, Journaling, Mood, Reflection, Virtual Reality},
location = {Sydney, NSW, Australia},
series = {SA '23}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3581961.3609828,
author = {Choe, Mungyeong and Bosch, Esther and Dong, Jiayuan and Alvarez, Ignacio and Oehl, Michael and Jallais, Christophe and Alsaid, Areen and Nadri, Chihab and Jeon, Myounghoon},
title = {Emotion GaRage Vol. IV: Creating Empathic In-Vehicle Interfaces with Generative AIs for Automated Vehicle Contexts},
year = {2023},
isbn = {9798400701122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581961.3609828},
doi = {10.1145/3581961.3609828},
abstract = {This workshop aims to design advanced empathic user interfaces for in-vehicle displays, particularly for high-level automated vehicles (SAE level 3 or higher). Incorporating model-based approaches for understanding human emotion regulation, it seeks to enhance the user-vehicle interaction. A unique aspect of this workshop is the integration of generative artificial intelligence (AI) tools in the design process. The workshop will explore generative AI’s potential in crafting contextual responses and its impact on user experience and interface design. The agenda includes brainstorming on various driving scenarios, developing emotion-oriented intervention methods, and rapid prototyping with AI tools. The anticipated outcome includes practical prototypes of affective user interfaces and insights on the role of AI in designing human-machine interactions. Through this workshop, we hope to contribute to making automated driving more accessible and enjoyable.},
booktitle = {Adjunct Proceedings of the 15th International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
pages = {234–236},
numpages = {3},
keywords = {ChatGPT, affective computing, emotions, empathic vehicles, interaction design},
location = {Ingolstadt, Germany},
series = {AutomotiveUI '23 Adjunct}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3644116.3644221,
author = {Zhao, Shifan and Chen, Mingkai},
title = {Psychological Healing in the Digital Age: A Study of Personalized Collaborative Models Empowered by GAI},
year = {2024},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644116.3644221},
doi = {10.1145/3644116.3644221},
abstract = {AI has shown promise in enhancing psychological healing. This research delves into using AI, specifically human-computer interaction and generative artificial intelligence (GAI), for precise mental health assessments and personalized treatment designs. Emotional tools like sentiment analysis and healing digitized journey discern minor mood shifts, precisely pinpointing user needs and offering user mental healing experience. As the design industry prioritizes psychological healing, AI aids in psychotherapy, facilitating tailored treatments, co-created plans, and suggesting future healing directions.},
booktitle = {Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
pages = {637–641},
numpages = {5},
location = {Chengdu, China},
series = {ISAIMS '23}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3686038.3686063,
author = {Clos, Jeremie and Chen, Yoke Yie},
title = {Investigating the Impact of Generative AI on Students and Educators: Evidence and Insights from the Literature},
year = {2024},
isbn = {9798400709890},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686038.3686063},
doi = {10.1145/3686038.3686063},
abstract = {Generative artificial intelligence (AI) has become one of the main concerns of knowledge workers due to its ability to mimic realistic human reasoning and creativity. However, this integration raises critical concerns about trust and ethics, which are crucial in shaping both the acceptance and effective utilisation of these technologies. There are many reports, articles and papers currently exploring the opportunities and challenges of LLMs in higher education from the perspective of students and educators. However, these papers often focus on specific contexts like in the UK, US or a particular institutions. In this paper, we examine the problems of generative AI in higher education from educator and student perspectives using scientometrics and text analysis to provide an overview of the research landscape, followed by a narrative review and thematic analysis of selected literature. Some findings of this work are: (1) Students and educators found different ways to use generative AI. Students focus more on using it as an assistant (revising and preparing for lectures, helping with homework) and educators as a content production assistant (writing lecture notes, personalising content). Commonalities are that both students and educators use generative AI as an accessibility aid, e.g., to rephrase sentences or explain concepts. (2) The main concerns of higher education regarding generative AI are equity in access, clarity of rules regarding usage, and job displacement.},
booktitle = {Proceedings of the Second International Symposium on Trustworthy Autonomous Systems},
articleno = {25},
numpages = {6},
location = {Austin, TX, USA},
series = {TAS '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3641555.3705235,
author = {Gonzalez, Elias and Chan, Joel and Weintrop, David},
title = {Quack! Configuring Large Language Models to Serve as Rubber Duck Coding Assistants},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705235},
doi = {10.1145/3641555.3705235},
abstract = {The emergence of Generative Artificial Intelligence (GenAI) tools broadly, and Large Language Models (LLMs) specifically, are equipping introductory programming instructors with a whole new class of pedagogical tools. While GenAI certainly poses threats to time-honored instructional techniques, it also provides opportunities for new forms of instructional support. In this work, we introduce our strategy for configuring an LLM to serve as a ''rubber duck debugging'' coding assistant to help novice programmers when they encounter difficulties in programming assignments. The key contribution of this work is not in the idea of using LLMs for debugging itself (which has already been demonstrated elsewhere, e.g., [3]) but to demonstrate the ease, flexibility, and pedagogical potential of the strategy. In particular, through carefully crafted prompts and easily accessible platforms, rubber duck LLMs can assist learners with specific questions while also situating those questions alongside larger computer science concepts and computational thinking practices. This work contributes an easily replicated and model-agnostic instructional strategy that productively and responsibly leverages the power of LLMs to assist novice programmers in developing foundational programming skills.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1463–1464},
numpages = {2},
keywords = {computer science education, generative ai, introductory programming, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3702163.3702182,
author = {Yaqub, Irfan and Chen, Zhiyuan and Liao, Iman Yi and Maul, Tomas and Seow, Hsin-Vonn and Chandesa, Tissa},
title = {A Novel Framework using Large Language Models to Automate Coursework Feedback for Computer Science modules},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702182},
doi = {10.1145/3702163.3702182},
abstract = {Prompt and sufficient feedback is essential for students' academic learning since it enables them to review their learning techniques and improve their areas of weakness. Nevertheless, delivering personalised feedback to every student continues to be difficult&nbsp;for teachers due to its demanding and time-intensive nature. While automated feedback systems are available, their primary focus is providing feedback on a single subject, and most of them utilise statistical analysis or traditional machine learning techniques to provide feedback. Moreover, no feedback model utilises the same criteria to generate text-based feedback for more than one subject. Generative artificial intelligence (GEN AI) has recently made incredible progress, and large language models (LLMs) can retain the context from the vast amount of text. Hence, this research presents a framework that employs an innovative technique to offer text-based feedback to students in different fields of study. This framework employs two LLMs, one for generating the feedback and another for categorising it into separate subjects using suitable headings for structural organising. Consequently, the output produced by this technology corresponds to the original tone of the teacher.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {130–137},
numpages = {8},
keywords = {Deep Learning Artificial Intelligence, Generative Artificial Intelligence, Large Language Model},
location = {
},
series = {ICETC '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3706599.3719804,
author = {Pammer-Schindler, Viktoria and Liut, Michael and Ley, Tobias},
title = {What if (Everyday) Technologies were Designed for Learning? Towards "Support for Learning" as a Design Goal for Every(day) Technology},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719804},
doi = {10.1145/3706599.3719804},
abstract = {What if everyday technologies were designed for productivity and learning? This is critical in the era of generative artificial intelligence and pervasive digital technologies, where technology design substantially shapes what and how humans are learning. This paper introduces “support for learning” as an explicit design goal for everyday technologies. To provide background, we first differentiate four relationships between learning and technology: (1) learning to use technology, (2) learning about technology, (3) learning as a primary design goal, and (4) learning through technology. Designers can intentionally facilitate the latter (a) by following established design principles for usability and user experience, but need to go beyond such known ground by (b) identifying potential learning goals, and (c) connecting to high-quality learning resources and technology designed from within the system. A future research agenda should investigate the relationships between patterns of technology design, patterns of technology use, and learning.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {595},
numpages = {7},
keywords = {HCI design goals, design goals, technology evaluation, human-centered design, human-centered computing, human-centered AI, humanistic design, lifelong learning},
location = {
},
series = {CHI EA '25}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3709022.3736542,
author = {Hacmon, Yaniv and Gorelik, Keren and Mirsky, Yisroel},
title = {The Threat of Deepfake Fingerprints},
year = {2025},
isbn = {9798400714191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709022.3736542},
doi = {10.1145/3709022.3736542},
abstract = {Fingerprint biometrics are extensively used for identification and security, from border control to consumer electronics. The permanence of fingerprints means security breaches can have lasting impacts. Traditionally, organizations store only fingerprint templates to mitigate the risks associated with stolen fingerprint images. However, advances in generative artificial intelligence (GenAI), particularly deepfake technologies, now enable adversaries to generate fingerprints from stolen templates, increasing the threat of data breaches.In this paper, we demonstrate and validate a previously theorized threat by evaluating an end-to-end attack in the physical world. Our approach involves: (1) generating fingerprint images from unseen templates, (2) fabricating silicone replicas of these deepfake fingerprints using a 3D resin printer, and (3) successfully deceiving fingerprint scanners with the replicas. The entire lab setup cost only $440 USD and only 7 cents to replicate each fingerprint thereafter, highlighting the attack's practicality.To support reproducibility and encourage the development of defenses, we publicly release our deepfake fingerprint pipeline.},
booktitle = {Proceedings of the 4th Workshop on Security Implications of Deepfakes and Cheapfakes},
pages = {1–8},
numpages = {8},
keywords = {Biometrics, Deepfake, Fingerprint Spoofing, Generative AI},
location = {Hanoi, Vietnam},
series = {WDC '25}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3702386.3702394,
author = {Qi, Yunlong and Fu, Fangxiang and Tian, Jianchi and Sun, Yan},
title = {Can AI Be Environmentally Responsible? A Comparative Study on the Pro-Environmental Portrait of ChatGPT and Chinese Respondents},
year = {2025},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702386.3702394},
doi = {10.1145/3702386.3702394},
abstract = {ChatGPT, a representative of the new generation of generative artificial intelligence (AI), has garnered widespread attention due to its extraordinary natural language processing capabilities. This study examined ChatGPT's environmental value orientations and ecological worldview within the Value-Belief-Norm (VBN) theory framework and compared these findings with the perceptions and self-assessments of 300 Chinese respondents. The results indicate that ChatGPT exhibits a significant pro-environmental orientation, although differences exist between its orientations and individual predictions of its environmental stance. The study provides theoretical support for the application of next-generation AI in environmental education and advocacy, contributes new evidence to the discourse on human-machine value alignment, and offers insights into human-AI collaboration in environmental protection.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
pages = {43–49},
numpages = {7},
keywords = {ChatGPT, alignment, pro-environmental orientation, “Value-Belief-Norm” theory},
location = {
},
series = {ICAITE '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3706599.3719957,
author = {Benner, Dennis and Rauch, Jannik and Janson, Andreas and Leimeister, Jan Marco},
title = {An Explorative Diary Study of AI-Generated Podcasts in University Education: Benefits, Challenges, and Future Directions},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719957},
doi = {10.1145/3706599.3719957},
abstract = {In this study, we explore the potential of AI-generated podcasts as an educational tool in the evolving landscape of learning media. Podcasts have grown increasingly relevant in education due to their accessibility and ability to integrate learning into everyday life. With the advent of generative artificial intelligence (AI), there is a unique opportunity for scalable and adaptable creation of learning media. However, with novel technology, there also come new challenges. Thus, we developed fine-tuned AI-generated podcasts using Google NotebookLM, our course materials, and a custom prompt. We conducted a one-month explorative evaluation in the field using a qualitative diary study. Our study reveals that students find the podcasts beneficial for flexible everyday learning but also point toward challenges like a lack of emotional engagement and technical non-English language issues. In sum, our study highlights the current benefits and challenges of AI-generated podcasts and presents an agenda for future research.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {70},
numpages = {8},
keywords = {AI-Generated Podcasts, NotebookLM, Diary Study, Explorative Study, Field Study, Digital Education, University Education, Research Agenda},
location = {
},
series = {CHI EA '25}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3702653.3744328,
author = {Roy, Nimisha and Horielko, Oleksandr and Omojokun, Olufisayo},
title = {Benchmarking of Generative AI Tools in Software Engineering Education: Formative Insights for Curriculum Integration},
year = {2025},
isbn = {9798400713415},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702653.3744328},
doi = {10.1145/3702653.3744328},
abstract = {Generative Artificial Intelligence (Gen-AI) has revolutionized software engineering (SE) by automating tasks across design, coding, and testing [1] [2]. Tools like ChatGPT and GitHub Copilot streamline code generation, architectural modeling, debugging, and test-case creation [3] [4]. Despite their rapid adoption in industry, the pedagogical implications of these tools in computing education have not been systematically examined. This study solves the existing gap by conducting a comprehensive benchmarking study of Gen-AI tools across four core SE phases— design documentation, feature implementation, debugging support, and testing — to address two research questions:RQ1: What strengths and limitations do Gen-AI tools exhibit in each phase?RQ2: How can insights from benchmarking inform effective integration of Gen-AI into SE curricula?To answer these questions, a diverse set of Gen-AI tools is evaluated, ranging from design-focused assistants such as Lucidchart, Mermaid.js and UIzard; implementation-oriented systems including GitHub Copilot, TabNine, Codeium and Supermaven; debugging supports like GPT-4 and Claude 3.5 Sonnet; and testing frameworks such as Testim, Mabl and Applitools—while also surveying emerging platforms (as of summer 2024) like Replit, Postman, Visily, Gemini, Eraser.io and others. For each tool and development phase, we applied phase-specific metrics: in design documentation, we assessed diagram accuracy, completeness, user effort, and IDE integration; in feature implementation, we measured pattern-based code generation quality, code-completion effectiveness, refactoring robustness, and UI/UX scaffolding; in debugging, we evaluated error-detection accuracy, hallucination rates, and clarity of explanatory feedback; and in testing, we examined test-case relevance and defect-detection coverage. Across all phases, we tracked prompt engineering complexity as a key mediating factor influencing tool performance.Our evaluation reveals speed-fidelity trade-offs: Code-completion assistants accelerate boilerplate generation but demand manual oversight to ensure cross-file consistency and manage higher-order abstractions; diagramming tools can produce precise UML models with minimal effort— but at the cost of iterative prompt refinement for complex cases; LLM debuggers deliver context-sensitive fixes yet suffer from nontrivial hallucination rates; testing generators exhibit wide variance in edge-case coverage. On average, tools needed 2.4 prompt iterations for usable diagrams and 1.5 prompts for bug fixes, underscoring the human effort in guiding AI.We recommend a scaffolded framework for integrating Gen-AI into SE education by: embedding AI tools into hands-on assignments, to explore tasks in a controlled context; by structuring small team projects in which one subgroup uses AI assistants while the other completes the same tasks manually (covering design, implementation, debugging and testing) to surface contrasts in workflow, tool strengths, and human reasoning; by requiring students to maintain a reflective journal documenting their AI usage and prompt-engineering strategies, fostering metacognitive insight into how tool inputs shape outputs; and by equipping learners with decision making criteria, teaching them to evaluate AI assistants according to task fit- preparing them to leverage AI responsibly across SE phases in its evolving landscape.},
booktitle = {Proceedings of the 2025 ACM Conference on International Computing Education Research V.2},
pages = {3},
numpages = {1},
keywords = {Generative AI, Software Engineering Education, Benchmarking, Prompt Engineering, Hallucination, Productivity},
location = {
},
series = {ICER '25}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3712255.3734261,
author = {Frapp\'{e} - - Vialatoux, C\^{o}me and Parrend, Pierre},
title = {Introducing H-Leading-Ones as a Mixed-Category Benchmark Problem for Evolutionary Algorithms},
year = {2025},
isbn = {9798400714641},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712255.3734261},
doi = {10.1145/3712255.3734261},
abstract = {In the wake of generative artificial intelligence and the exponential growth in the volume of data generated, the associated increase in data complexity in the sense of the quantity of different data types present in a single system poses a challenge to evolutionary algorithms. To allow for the development and testing of new algorithms adapted to this new data landscape, test problems are necessary as a way to both evaluate and compare algorithms performances. However, while recent advances extended known test problems such as the r-Leading-Ones marking the transition from binary to multi-valued variables, having different data-types coexisting in the search space is still an open question. We propose the h-Leading-Ones as an extension of the r-Leading-Ones to evaluate the ability of an algorithm to solve problems on a search space composed of multi-valued and real-valued data types. Its design with dependency between the different data-types and its continuity with the r-Leading-Ones provides a convenient new environment for benchmark and runtime analysis for mixed-category search spaces.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {97–98},
numpages = {2},
keywords = {evolutionary algorithms, problem, data-types},
location = {NH Malaga Hotel, Malaga, Spain},
series = {GECCO '25 Companion}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3690712.3690717,
author = {Wang, Yadi and Fussell, Susan R.},
title = {They May Have Seen My ChatGPT Tab: Exploring Social Perceptions of AI-Assisted Writing for ESL Students},
year = {2024},
isbn = {9798400710315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690712.3690717},
doi = {10.1145/3690712.3690717},
abstract = {Many English as a Second Language (ESL) students have begun to use generative artificial intelligence (AI) tools to improve their writing artifacts. In this process, however, ESL students are also facing scrutiny due to the social expectation of independent language acquisition. Therefore, we propose a study design consisting of diary studies and interviews to investigate the ways ESL students perceive and navigate the nuanced social dynamics around using generative AI in their writing. Through this study, we aim to gain a deeper understanding of the social-technical implication of AI usage in second language acquisition, and to offer suggestions to ESL learners and educators on ways to incorporate AI into their educational journey.},
booktitle = {Proceedings of the Third Workshop on Intelligent and Interactive Writing Assistants},
pages = {13–15},
numpages = {3},
location = {Honolulu, HI, USA},
series = {In2Writing '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3733155.3737910,
author = {Leporini, Barbara and Buzzi, Marina and Della Penna, Giuseppe},
title = {A Preliminary Evaluation of Generative AI Tools for Blind Users: Usability and Screen Reader Interaction},
year = {2025},
isbn = {9798400714023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3733155.3737910},
doi = {10.1145/3733155.3737910},
abstract = {The increasing use of Generative Artificial Intelligence (GAI) tools such as ChatGPT, Copilot, Perplexity and Gemini opens up new possible scenarios for supporting work and everyday activities. For people who are blind, the usability of such tools through screen readers is crucial to ensure their use of such AI-based technologies. In this study, we explore the accessibility and usability of the interfaces of four popular AI-based tools via screen readers through a combination of semi-automated evaluations and inspections conducted by both sighted and blind accessibility experts and screen readers with more than 20 years of experience. Navigation, labeling of control elements, feedback mechanisms, and prompt handling were considered in the study. The results point to usability difficulties in all tools, particularly in navigation structure, clarity of feedback and interactive elements. Although this work empirically explores the accessibility of AI-based tools it brings out the first critical issues that deserve further investigation. However, they are based on a small group of experts and thus should be considered preliminary and useful for future studies.},
booktitle = {Proceedings of the 18th ACM International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {562–568},
numpages = {7},
keywords = {Accessibility, Blind users, ChatGPT, Copilot, Gemini, Generative AI, Perplexity, screen reader interaction},
location = {
},
series = {PETRA '25}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3597503.3649400,
author = {Smith, Carol},
title = {Trustworthy by Design},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3649400},
doi = {10.1145/3597503.3649400},
abstract = {The relatively recent public release of generative artificial intelligence (AI) systems has ignited a significant leap in awareness of the capabilities of AI. In parallel, there has been a recognition of AI system limitations and the bias inherent in systems created by humans. Expectations are rising for more trustworthy, human-centered, and responsible software connecting humans to powerful systems that augment their abilities. There are decades of practice designing systems that work with, and for humans, that we can build upon to face the new challenges and opportunities brought by dynamic AI systems.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {3},
numpages = {4},
keywords = {keynote, ethics, trust, emerging technology, AI},
location = {Lisbon, Portugal},
series = {ICSE '24}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3596454.3597176,
author = {Schmidt, Albrecht},
title = {Speeding Up the Engineering of Interactive Systems with Generative AI},
year = {2023},
isbn = {9798400702068},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3596454.3597176},
doi = {10.1145/3596454.3597176},
abstract = {This keynote discusses the opportunities and challenges of using Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) as tools for developing interactive systems. We will look at different stages in the development lifecycle of interactive systems and assess the value of AI support. We explore how GenAI and LLMs can potentially speed-up the ideation, requirements elicitation, architecture development, prototyping, implementation, and testing of interactive systems. The talk will outline emerging practices, such as the use of prompts for code and system generation, to facilitate prototyping and accelerate implementation. We will outline fundamental challenges and suggest emerging research directions, and pose research questions. What will software development tools look like in the future? How can we efficiently use AI to develop interactive systems without compromising quality? We also speculate about the implications of these developments for researchers, practitioners, and society. We believe that it will massively accelerate the digital transformation. Interactive AI-based tools for systems and software development will become a major research direction.},
booktitle = {Companion Proceedings of the 2023 ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
pages = {7–8},
numpages = {2},
keywords = {Software and System Development, Large Language Models, Interactive Systems, Engineering, ChatGPT, Automation},
location = {Swansea, United Kingdom},
series = {EICS '23 Companion}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3573382.3616033,
author = {Huang, Yuxuan},
title = {The Future of Generative AI: How GenAI Would Change Human-Computer Co-creation in the Next 10 to 15 Years},
year = {2023},
isbn = {9798400700293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573382.3616033},
doi = {10.1145/3573382.3616033},
abstract = {The past few years have witnessed a remarkable advancement in the field of Generative Artificial Intelligence (GenAI), a technology capable of generating new content based on input prompts and existing knowledge. This technology has the potential to revolutionize the way of human-computer co-creation. However, existing research on GenAI has primarily focused on technical aspects, and more research is needed from a design perspective, mainly through speculative and critical design. Therefore, this study aims to explore how GenAI would transform human-computer co-creation in the next 10 to 15 years by means of design fiction and playful critical design. The study will involve (co-)speculative workshops utilizing design fiction, followed by focus groups to gather insights. In addition, this research will examine the user experience issues of interacting with functional GenAI prototypes through playful critical design.},
booktitle = {Companion Proceedings of the Annual Symposium on Computer-Human Interaction in Play},
pages = {322–325},
numpages = {4},
keywords = {AI-generated content, design fiction, generative AI, playful critical design, speculative design},
location = {Stratford, ON, Canada},
series = {CHI PLAY Companion '23}
}</div>
  </div>
<div class="csl-entry"><div class="csl-right-inline">@inproceedings{10.1145/3613904.3642160,
author = {Sun, Yuan and Jang, Eunchae and Ma, Fenglong and Wang, Ting},
title = {Generative AI in the Wild: Prospects, Challenges, and Strategies},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642160},
doi = {10.1145/3613904.3642160},
abstract = {Propelled by their remarkable capabilities to generate novel and engaging content, Generative Artificial Intelligence (GenAI) technologies are disrupting traditional workflows in many industries. While prior research has examined GenAI from a techno-centric perspective, there is still a lack of understanding about how users perceive and utilize GenAI in real-world scenarios. To bridge this gap, we conducted semi-structured interviews with (N = 18) GenAI users in creative industries, investigating the human-GenAI co-creation process within a holistic LUA (Learning, Using and Assessing) framework. Our study uncovered an intriguingly complex landscape: Prospects – GenAI greatly fosters the co-creation between human expertise and GenAI capabilities, profoundly transforming creative workflows; Challenges – Meanwhile, users face substantial uncertainties and complexities arising from resource availability, tool usability, and regulatory compliance; Strategies – In response, users actively devise various strategies to overcome many of such challenges. Our study reveals key implications for the design of future GenAI tools.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {747},
numpages = {16},
keywords = {Generative AI, Human-AI Collaboration, Transparency, User Agency},
location = {Honolulu, HI, USA},
series = {CHI '24}
}</div>
  </div>
</pre><div id="export-warning"></div><div class="pull-right"><ul role="menu" class="rlist--inline separator"><li style="cursor: pointer;"><a href="javascript:void(0)" role="menuitem" title="Download citation" class="download__btn"><label class="visibility-hidden">Download citation</label><i aria-hidden="true" class="icon-Icon_Download"></i></a></li><li style="cursor: pointer;"><input type="hidden" id="doisLimitNumber" value="1000"><a href="javascript:void(0)" role="menuitem" title="Copy citation" class="copy__btn"><label class="visibility-hidden">Copy citation</label><i aria-hidden="true" class="icon-pages"></i></a></li></ul></div></div></li></ul></form></div></div></div></div>